{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"Official implementation of Conflict-Free Inverse Gradients Method [ICLR2025 Spotlight] Towards Conflict-free Training for Everything and Everyone! <p>   [ \ud83d\udcc4 Research Paper ]\u2022[  GitHub Repository ] </p>"},{"location":"#news","title":"News","text":"<p>Recently, the ConFIG method has also been applied to train physics-constrained generative models:</p> <ul> <li> <p>Flow Matching Meets PDEs: A Unified Framework for Physics-Constrained Generation, Giacomo Baldan, Qiang Liu, Alberto Guardone, Nils Thuerey, https://arxiv.org/abs/2506.08604</p> </li> <li> <p>Guiding diffusion models to reconstruct flow fields from sparse data, Marc Amor\u00f3s-Trepat, Luis Medrano-Navarro, Qiang Liu, Luca Guastoni, Nils Thuerey, https://arxiv.org/abs/2506.11908</p> </li> </ul>"},{"location":"#about","title":"About","text":"<ul> <li>What is the ConFIG method?</li> </ul> <p>\u200b   The conFIG method is a generic method for optimization problems involving multiple loss terms (e.g., Multi-task Learning, Continuous Learning, and Physics Informed Neural Networks). It prevents the optimization from getting stuck into a local minimum of a specific loss term due to the conflict between losses. On the contrary, it leads the optimization to the shared minimum of all losses by providing a conflict-free update direction.</p> <p> </p> <ul> <li>How does the ConFIG work?</li> </ul> <p>\u200b   The ConFIG method obtains the conflict-free direction by calculating the inverse of the loss-specific gradients matrix:</p> \\[ \\mathbf{g}_{ConFIG}=\\left(\\sum_{i=1}^{m} \\mathbf{g}_{i}^\\top\\mathbf{g}_{u}\\right)\\mathbf{g}_u, \\] \\[ \\mathbf{g}_u = \\mathcal{U}\\left[ [\\mathcal{U}(\\mathbf{g}_1),\\mathcal{U}(\\mathbf{g}_2),\\cdots, \\mathcal{U}(\\mathbf{g}_m)]^{-\\top} \\mathbf{1}_m\\right]. \\] <p>Then the dot product between \\(\\mathbf{g}_{ConFIG}\\) and each loss-specific gradient is always positive and equal, i.e., \\(\\mathbf{g}_{i}^{\\top}\\mathbf{g}_{ConFIG}=\\mathbf{g}_{j}^{\\top}\\mathbf{g}_{ConFIG} &gt; 0 \\quad \\forall i,j \\in [1,m]\\)\u200b.</p> <ul> <li>Is the ConFIG computationally expensive?</li> </ul> <p>\u200b   Like many other gradient-based methods, ConFIG needs to calculate each loss's gradient in every optimization iteration, which could be computationally expensive when the number of losses increases. However, we also introduce a momentum-based method where we can reduce the computational cost close to or even lower than a standard optimization procedure with a slight degeneration in accuracy. This momentum-based method is also applicable to other gradient-based methods.</p>"},{"location":"#paper-info","title":"Paper Info","text":"ConFIG: Towards Conflict-free Training of Physics Informed Neural Networks Qiang Liu,  Mengyu Chu, and  Nils Thuerey  Technical University of Munich      Peking University  <p>Abstract: The loss functions of many learning problems contain multiple additive terms that can disagree and yield conflicting update directions. For Physics-Informed Neural Networks (PINNs), loss terms on initial/boundary conditions and physics equations are particularly interesting as they are well-established as highly difficult tasks. To improve learning the challenging multi-objective task posed by PINNs, we propose the ConFIG method, which provides conflict-free updates by ensuring a positive dot product between the final update and each loss-specific gradient. It also maintains consistent optimization rates for all loss terms and dynamically adjusts gradient magnitudes based on conflict levels. We additionally leverage momentum to accelerate optimizations by alternating the back-propagation of different loss terms. The proposed method is evaluated across a range of challenging PINN scenarios, consistently showing superior performance and runtime compared to baseline methods. We also test the proposed method in a classic multi-task benchmark, where the ConFIG method likewise exhibits a highly promising performance. </p> <p>Read from: [Arxiv]</p> <p>Cite as: </p> <pre><code>@inproceedings{Liu2024ConFIG,\n  author = {Qiang Liu and Mengyu Chu and Nils Thuerey},\n  title = {ConFIG: Towards Conflict-free Training of Physics Informed Neural Networks},\n  booktitle = {The Thirteenth International Conference on Learning Representations},\n  year={2024},\n  url={https://arxiv.org/abs/2408.11104},\n}\n</code></pre>"},{"location":"#additional-info","title":"Additional Info","text":"<p>This project is part of the physics-based deep learning topic in Physics-based Simulation group at TUM.</p>"},{"location":"api/grad_operator/","title":"4.1. Gradient Operator","text":"<p>The <code>grad_operator</code> module contains the main operators of ConFIG algorithm. You can use these operators to perform the ConFIG update step for your optimization problem.</p>"},{"location":"api/grad_operator/#operation-functions","title":"Operation Functions","text":""},{"location":"api/grad_operator/#conflictfree.grad_operator.ConFIG_update","title":"conflictfree.grad_operator.ConFIG_update","text":"<pre><code>ConFIG_update(\n    grads: Union[Tensor, Sequence[Tensor]],\n    weight_model: WeightModel = EqualWeight(),\n    length_model: LengthModel = ProjectionLength(),\n    use_least_square: bool = True,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Performs the standard ConFIG update step.</p> <p>Parameters:</p> Name Type Description Default <code>grads</code> <code>Union[Tensor, Sequence[Tensor]]</code> <p>The gradients to update. It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.</p> required <code>weight_model</code> <code>WeightModel</code> <p>The weight model for calculating the direction weights. Defaults to EqualWeight(), which will make the final update gradient not biased towards any gradient.</p> <code>EqualWeight()</code> <code>length_model</code> <code>LengthModel</code> <p>The length model for rescaling the length of the final gradient. Defaults to ProjectionLength(), which will project each gradient vector onto the final gradient vector to get the final length.</p> <code>ProjectionLength()</code> <code>use_least_square</code> <code>bool</code> <p>Whether to use the least square method for calculating the best direction. If set to False, we will directly calculate the pseudo-inverse of the gradient matrix. See <code>torch.linalg.pinv</code> and <code>torch.linalg.lstsq</code> for more details. Recommended to set to True. Defaults to True.</p> <code>True</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses associated with the gradients. The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information, you can set this value as None. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The final update gradient.</p> <p>Examples:</p> <pre><code>from conflictfree.grad_operator import ConFIG_update\nfrom conflictfree.utils import get_gradient_vector,apply_gradient_vector\noptimizer=torch.Adam(network.parameters(),lr=1e-3)\nfor input_i in dataset:\n    grads=[] # we record gradients rather than losses\n    for loss_fn in loss_fns:\n        optimizer.zero_grad()\n        loss_i=loss_fn(input_i)\n        loss_i.backward()\n        grads.append(get_gradient_vector(network)) #get loss-specfic gradient\n    g_config=ConFIG_update(grads) # calculate the conflict-free direction\n    apply_gradient_vector(network,g_config) # set the conflict-free direction to the network\n    optimizer.step()\n</code></pre> Source code in <code>conflictfree/grad_operator.py</code> <pre><code>def ConFIG_update(\n    grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n    weight_model: WeightModel = EqualWeight(),\n    length_model: LengthModel = ProjectionLength(),\n    use_least_square: bool = True,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Performs the standard ConFIG update step.\n\n    Args:\n        grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n            It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n        weight_model (WeightModel, optional): The weight model for calculating the direction weights.\n            Defaults to EqualWeight(), which will make the final update gradient not biased towards any gradient.\n        length_model (LengthModel, optional): The length model for rescaling the length of the final gradient.\n            Defaults to ProjectionLength(), which will project each gradient vector onto the final gradient vector to get the final length.\n        use_least_square (bool, optional): Whether to use the least square method for calculating the best direction.\n            If set to False, we will directly calculate the pseudo-inverse of the gradient matrix. See `torch.linalg.pinv` and `torch.linalg.lstsq` for more details.\n            Recommended to set to True. Defaults to True.\n        losses (Optional[Sequence], optional): The losses associated with the gradients.\n            The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information,\n            you can set this value as None. Defaults to None.\n\n    Returns:\n        torch.Tensor: The final update gradient.\n\n    Examples:\n        ```python\n        from conflictfree.grad_operator import ConFIG_update\n        from conflictfree.utils import get_gradient_vector,apply_gradient_vector\n        optimizer=torch.Adam(network.parameters(),lr=1e-3)\n        for input_i in dataset:\n            grads=[] # we record gradients rather than losses\n            for loss_fn in loss_fns:\n                optimizer.zero_grad()\n                loss_i=loss_fn(input_i)\n                loss_i.backward()\n                grads.append(get_gradient_vector(network)) #get loss-specfic gradient\n            g_config=ConFIG_update(grads) # calculate the conflict-free direction\n            apply_gradient_vector(network,g_config) # set the conflict-free direction to the network\n            optimizer.step()\n        ```\n    \"\"\"\n    if not isinstance(grads, torch.Tensor):\n        grads = torch.stack(grads)\n    with torch.no_grad():\n        weights = weight_model.get_weights(\n            gradients=grads, losses=losses, device=grads.device\n        )\n        units = torch.nan_to_num((grads / (grads.norm(dim=1)).unsqueeze(1)), 0)\n        if use_least_square:\n            best_direction = torch.linalg.lstsq(units, weights).solution\n        else:\n            best_direction = torch.linalg.pinv(units) @ weights\n        return length_model.rescale_length(\n            target_vector=best_direction,\n            gradients=grads,\n            losses=losses,\n        )\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.ConFIG_update_double","title":"conflictfree.grad_operator.ConFIG_update_double","text":"<pre><code>ConFIG_update_double(\n    grad_1: Tensor,\n    grad_2: Tensor,\n    weight_model: WeightModel = EqualWeight(),\n    length_model: LengthModel = ProjectionLength(),\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>ConFIG update for two gradients where no inverse calculation is needed.</p> <p>Parameters:</p> Name Type Description Default <code>grad_1</code> <code>Tensor</code> <p>The first gradient.</p> required <code>grad_2</code> <code>Tensor</code> <p>The second gradient.</p> required <code>weight_model</code> <code>WeightModel</code> <p>The weight model for calculating the direction weights. Defaults to EqualWeight(), which will make the final update gradient not biased towards any gradient.</p> <code>EqualWeight()</code> <code>length_model</code> <code>LengthModel</code> <p>The length model for rescaling the length of the final gradient. Defaults to ProjectionLength(), which will project each gradient vector onto the final gradient vector to get the final length.</p> <code>ProjectionLength()</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses associated with the gradients. The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information, you can set this value as None. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The final update gradient.</p> <p>Examples:</p> <pre><code>from conflictfree.grad_operator import ConFIG_update_double\nfrom conflictfree.utils import get_gradient_vector,apply_gradient_vector\noptimizer=torch.Adam(network.parameters(),lr=1e-3)\nfor input_i in dataset:\n    grads=[] # we record gradients rather than losses\n    for loss_fn in [loss_fn1, loss_fn2]:\n        optimizer.zero_grad()\n        loss_i=loss_fn(input_i)\n        loss_i.backward()\n        grads.append(get_gradient_vector(network)) #get loss-specfic gradient\n    g_config=ConFIG_update_double(grads) # calculate the conflict-free direction\n    apply_gradient_vector(network,g_config) # set the conflict-free direction to the network\n    optimizer.step()\n</code></pre> Source code in <code>conflictfree/grad_operator.py</code> <pre><code>def ConFIG_update_double(\n    grad_1: torch.Tensor,\n    grad_2: torch.Tensor,\n    weight_model: WeightModel = EqualWeight(),\n    length_model: LengthModel = ProjectionLength(),\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    ConFIG update for two gradients where no inverse calculation is needed.\n\n    Args:\n        grad_1 (torch.Tensor): The first gradient.\n        grad_2 (torch.Tensor): The second gradient.\n        weight_model (WeightModel, optional): The weight model for calculating the direction weights.\n            Defaults to EqualWeight(), which will make the final update gradient not biased towards any gradient.\n        length_model (LengthModel, optional): The length model for rescaling the length of the final gradient.\n            Defaults to ProjectionLength(), which will project each gradient vector onto the final gradient vector to get the final length.\n        losses (Optional[Sequence], optional): The losses associated with the gradients.\n            The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information,\n            you can set this value as None. Defaults to None.\n\n    Returns:\n        torch.Tensor: The final update gradient.\n\n    Examples:\n        ```python\n        from conflictfree.grad_operator import ConFIG_update_double\n        from conflictfree.utils import get_gradient_vector,apply_gradient_vector\n        optimizer=torch.Adam(network.parameters(),lr=1e-3)\n        for input_i in dataset:\n            grads=[] # we record gradients rather than losses\n            for loss_fn in [loss_fn1, loss_fn2]:\n                optimizer.zero_grad()\n                loss_i=loss_fn(input_i)\n                loss_i.backward()\n                grads.append(get_gradient_vector(network)) #get loss-specfic gradient\n            g_config=ConFIG_update_double(grads) # calculate the conflict-free direction\n            apply_gradient_vector(network,g_config) # set the conflict-free direction to the network\n            optimizer.step()\n        ```\n\n    \"\"\"\n    with torch.no_grad():\n        norm_1 = grad_1.norm()\n        norm_2 = grad_2.norm()\n        unit_1 = grad_1 / norm_1\n        unit_2 = grad_2 / norm_2\n        cos_angle = get_cos_similarity(grad_1, grad_2)\n        or_2 = grad_1 - norm_1 * cos_angle * unit_2\n        or_1 = grad_2 - norm_2 * cos_angle * unit_1\n        unit_or1 = unit_vector(or_1)\n        unit_or2 = unit_vector(or_2)\n        coef_1, coef_2 = transfer_coef_double(\n            weight_model.get_weights(\n                gradients=torch.stack([grad_1, grad_2]),\n                losses=losses,\n                device=grad_1.device,\n            ),\n            unit_1,\n            unit_2,\n            unit_or1,\n            unit_or2,\n        )\n        best_direction = coef_1 * unit_or1 + coef_2 * unit_or2\n        return length_model.rescale_length(\n            target_vector=best_direction,\n            gradients=torch.stack([grad_1, grad_2]),\n            losses=losses,\n        )\n</code></pre>"},{"location":"api/grad_operator/#operator-classes","title":"Operator Classes","text":""},{"location":"api/grad_operator/#conflictfree.grad_operator.ConFIGOperator","title":"conflictfree.grad_operator.ConFIGOperator","text":"<p>               Bases: <code>GradientOperator</code></p> <p>Operator for the ConFIG algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>weight_model</code> <code>WeightModel</code> <p>The weight model for calculating the direction weights. Defaults to EqualWeight(), which will make the final update gradient not biased towards any gradient.</p> <code>EqualWeight()</code> <code>length_model</code> <code>LengthModel</code> <p>The length model for rescaling the length of the final gradient. Defaults to ProjectionLength(), which will project each gradient vector onto the final gradient vector to get the final length.</p> <code>ProjectionLength()</code> <code>allow_simplified_model</code> <code>bool</code> <p>Whether to allow simplified model for calculating the gradient. If set to True, will use simplified form of ConFIG method when there are only two losses (ConFIG_update_double). Defaults to True.</p> <code>True</code> <code>use_least_square</code> <code>bool</code> <p>Whether to use the least square method for calculating the best direction. If set to False, we will directly calculate the pseudo-inverse of the gradient matrix. See <code>torch.linalg.pinv</code> and <code>torch.linalg.lstsq</code> for more details. Recommended to set to True. Defaults to True.</p> <code>True</code> <p>Examples:</p> <pre><code>from conflictfree.grad_operator import ConFIGOperator\nfrom conflictfree.utils import get_gradient_vector,apply_gradient_vector\noptimizer=torch.Adam(network.parameters(),lr=1e-3)\noperator=ConFIGOperator() # initialize operator\nfor input_i in dataset:\n    grads=[]\n    for loss_fn in loss_fns:\n        optimizer.zero_grad()\n        loss_i=loss_fn(input_i)\n        loss_i.backward()\n        grads.append(get_gradient_vector(network))\n    g_config=operator.calculate_gradient(grads) # calculate the conflict-free direction\n    apply_gradient_vector(network,g_config) # or simply use `operator.update_gradient(network,grads)` to calculate and set the conflict-free direction to the network\n    optimizer.step()\n</code></pre> Source code in <code>conflictfree/grad_operator.py</code> <pre><code>class ConFIGOperator(GradientOperator):\n    \"\"\"\n    Operator for the ConFIG algorithm.\n\n    Args:\n        weight_model (WeightModel, optional): The weight model for calculating the direction weights.\n            Defaults to EqualWeight(), which will make the final update gradient not biased towards any gradient.\n        length_model (LengthModel, optional): The length model for rescaling the length of the final gradient.\n            Defaults to ProjectionLength(), which will project each gradient vector onto the final gradient vector to get the final length.\n        allow_simplified_model (bool, optional): Whether to allow simplified model for calculating the gradient.\n            If set to True, will use simplified form of ConFIG method when there are only two losses (ConFIG_update_double). Defaults to True.\n        use_least_square (bool, optional): Whether to use the least square method for calculating the best direction.\n            If set to False, we will directly calculate the pseudo-inverse of the gradient matrix. See `torch.linalg.pinv` and `torch.linalg.lstsq` for more details.\n            Recommended to set to True. Defaults to True.\n\n    Examples:\n        ```python\n        from conflictfree.grad_operator import ConFIGOperator\n        from conflictfree.utils import get_gradient_vector,apply_gradient_vector\n        optimizer=torch.Adam(network.parameters(),lr=1e-3)\n        operator=ConFIGOperator() # initialize operator\n        for input_i in dataset:\n            grads=[]\n            for loss_fn in loss_fns:\n                optimizer.zero_grad()\n                loss_i=loss_fn(input_i)\n                loss_i.backward()\n                grads.append(get_gradient_vector(network))\n            g_config=operator.calculate_gradient(grads) # calculate the conflict-free direction\n            apply_gradient_vector(network,g_config) # or simply use `operator.update_gradient(network,grads)` to calculate and set the conflict-free direction to the network\n            optimizer.step()\n        ```\n\n    \"\"\"\n\n    def __init__(\n        self,\n        weight_model: WeightModel = EqualWeight(),\n        length_model: LengthModel = ProjectionLength(),\n        allow_simplified_model: bool = True,\n        use_least_square: bool = True,\n    ):\n        super().__init__()\n        self.weight_model = weight_model\n        self.length_model = length_model\n        self.allow_simplified_model = allow_simplified_model\n        self.use_least_square = use_least_square\n\n    def calculate_gradient(\n        self,\n        grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n        losses: Optional[Sequence] = None,\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Calculates the gradient using the ConFIG algorithm.\n\n        Args:\n            grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n                It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n            losses (Optional[Sequence], optional): The losses associated with the gradients.\n                The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information,\n                you can set this value as None. Defaults to None.\n\n        Returns:\n            torch.Tensor: The calculated gradient.\n        \"\"\"\n        if not isinstance(grads, torch.Tensor):\n            grads = torch.stack(grads)\n        if grads.shape[0] == 2 and self.allow_simplified_model:\n            return ConFIG_update_double(\n                grads[0],\n                grads[1],\n                weight_model=self.weight_model,\n                length_model=self.length_model,\n                losses=losses,\n            )\n        else:\n            return ConFIG_update(\n                grads,\n                weight_model=self.weight_model,\n                length_model=self.length_model,\n                use_least_square=self.use_least_square,\n                losses=losses,\n            )\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.ConFIGOperator.weight_model","title":"weight_model  <code>instance-attribute</code>","text":"<pre><code>weight_model = weight_model\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.ConFIGOperator.length_model","title":"length_model  <code>instance-attribute</code>","text":"<pre><code>length_model = length_model\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.ConFIGOperator.allow_simplified_model","title":"allow_simplified_model  <code>instance-attribute</code>","text":"<pre><code>allow_simplified_model = allow_simplified_model\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.ConFIGOperator.use_least_square","title":"use_least_square  <code>instance-attribute</code>","text":"<pre><code>use_least_square = use_least_square\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.ConFIGOperator.__init__","title":"__init__","text":"<pre><code>__init__(\n    weight_model: WeightModel = EqualWeight(),\n    length_model: LengthModel = ProjectionLength(),\n    allow_simplified_model: bool = True,\n    use_least_square: bool = True,\n)\n</code></pre> Source code in <code>conflictfree/grad_operator.py</code> <pre><code>def __init__(\n    self,\n    weight_model: WeightModel = EqualWeight(),\n    length_model: LengthModel = ProjectionLength(),\n    allow_simplified_model: bool = True,\n    use_least_square: bool = True,\n):\n    super().__init__()\n    self.weight_model = weight_model\n    self.length_model = length_model\n    self.allow_simplified_model = allow_simplified_model\n    self.use_least_square = use_least_square\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.ConFIGOperator.calculate_gradient","title":"calculate_gradient","text":"<pre><code>calculate_gradient(\n    grads: Union[Tensor, Sequence[Tensor]],\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Calculates the gradient using the ConFIG algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>grads</code> <code>Union[Tensor, Sequence[Tensor]]</code> <p>The gradients to update. It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.</p> required <code>losses</code> <code>Optional[Sequence]</code> <p>The losses associated with the gradients. The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information, you can set this value as None. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The calculated gradient.</p> Source code in <code>conflictfree/grad_operator.py</code> <pre><code>def calculate_gradient(\n    self,\n    grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculates the gradient using the ConFIG algorithm.\n\n    Args:\n        grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n            It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n        losses (Optional[Sequence], optional): The losses associated with the gradients.\n            The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information,\n            you can set this value as None. Defaults to None.\n\n    Returns:\n        torch.Tensor: The calculated gradient.\n    \"\"\"\n    if not isinstance(grads, torch.Tensor):\n        grads = torch.stack(grads)\n    if grads.shape[0] == 2 and self.allow_simplified_model:\n        return ConFIG_update_double(\n            grads[0],\n            grads[1],\n            weight_model=self.weight_model,\n            length_model=self.length_model,\n            losses=losses,\n        )\n    else:\n        return ConFIG_update(\n            grads,\n            weight_model=self.weight_model,\n            length_model=self.length_model,\n            use_least_square=self.use_least_square,\n            losses=losses,\n        )\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.ConFIGOperator.update_gradient","title":"update_gradient","text":"<pre><code>update_gradient(\n    network: Module,\n    grads: Union[Tensor, Sequence[Tensor]],\n    losses: Optional[Sequence] = None,\n) -&gt; None\n</code></pre> <p>Calculate the gradient and apply the gradient to the network.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>Module</code> <p>The target network.</p> required <code>grads</code> <code>Union[Tensor, Sequence[Tensor]]</code> <p>The gradients to update. It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.</p> required <code>losses</code> <code>Optional[Sequence]</code> <p>The losses associated with the gradients. The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information, you can set this value as None. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>conflictfree/grad_operator.py</code> <pre><code>def update_gradient(\n    self,\n    network: torch.nn.Module,\n    grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n    losses: Optional[Sequence] = None,\n) -&gt; None:\n    \"\"\"\n    Calculate the gradient and apply the gradient to the network.\n\n    Args:\n        network (torch.nn.Module): The target network.\n        grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n            It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n        losses (Optional[Sequence], optional): The losses associated with the gradients.\n            The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information,\n            you can set this value as None. Defaults to None.\n\n    Returns:\n        None\n\n    \"\"\"\n    apply_gradient_vector(network, self.calculate_gradient(grads, losses))\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.PCGradOperator","title":"conflictfree.grad_operator.PCGradOperator","text":"<p>               Bases: <code>GradientOperator</code></p> <p>PCGradOperator class represents a gradient operator for PCGrad algorithm.</p> <p>@inproceedings{yu2020gradient, title={Gradient surgery for multi-task learning}, author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea}, booktitle={34<sup>th</sup> International Conference on Neural Information Processing Systems}, year={2020}, url={https://dl.acm.org/doi/abs/10.5555/3495724.3496213} }</p> Source code in <code>conflictfree/grad_operator.py</code> <pre><code>class PCGradOperator(GradientOperator):\n    \"\"\"\n    PCGradOperator class represents a gradient operator for PCGrad algorithm.\n\n    @inproceedings{yu2020gradient,\n    title={Gradient surgery for multi-task learning},\n    author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},\n    booktitle={34th International Conference on Neural Information Processing Systems},\n    year={2020},\n    url={https://dl.acm.org/doi/abs/10.5555/3495724.3496213}\n    }\n\n    \"\"\"\n\n    def calculate_gradient(\n        self,\n        grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n        losses: Optional[Sequence] = None,\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Calculates the gradient using the PCGrad algorithm.\n\n        Args:\n            grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n                It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n            losses (Optional[Sequence], optional): This parameter should not be set for current operator. Defaults to None.\n\n        Returns:\n            torch.Tensor: The calculated gradient using PCGrad method.\n        \"\"\"\n        if not isinstance(grads, torch.Tensor):\n            grads = torch.stack(grads)\n        with torch.no_grad():\n            grads_pc = torch.clone(grads)\n            length = grads.shape[0]\n            for i in range(length):\n                for j in range(length):\n                    if j != i:\n                        dot = grads_pc[i].dot(grads[j])\n                        if dot &lt; 0:\n                            grads_pc[i] -= dot * grads[j] / ((grads[j].norm()) ** 2)\n            return torch.sum(grads_pc, dim=0)\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.PCGradOperator.calculate_gradient","title":"calculate_gradient","text":"<pre><code>calculate_gradient(\n    grads: Union[Tensor, Sequence[Tensor]],\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Calculates the gradient using the PCGrad algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>grads</code> <code>Union[Tensor, Sequence[Tensor]]</code> <p>The gradients to update. It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.</p> required <code>losses</code> <code>Optional[Sequence]</code> <p>This parameter should not be set for current operator. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The calculated gradient using PCGrad method.</p> Source code in <code>conflictfree/grad_operator.py</code> <pre><code>def calculate_gradient(\n    self,\n    grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculates the gradient using the PCGrad algorithm.\n\n    Args:\n        grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n            It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n        losses (Optional[Sequence], optional): This parameter should not be set for current operator. Defaults to None.\n\n    Returns:\n        torch.Tensor: The calculated gradient using PCGrad method.\n    \"\"\"\n    if not isinstance(grads, torch.Tensor):\n        grads = torch.stack(grads)\n    with torch.no_grad():\n        grads_pc = torch.clone(grads)\n        length = grads.shape[0]\n        for i in range(length):\n            for j in range(length):\n                if j != i:\n                    dot = grads_pc[i].dot(grads[j])\n                    if dot &lt; 0:\n                        grads_pc[i] -= dot * grads[j] / ((grads[j].norm()) ** 2)\n        return torch.sum(grads_pc, dim=0)\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.PCGradOperator.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> Source code in <code>conflictfree/grad_operator.py</code> <pre><code>def __init__(self):\n    pass\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.PCGradOperator.update_gradient","title":"update_gradient","text":"<pre><code>update_gradient(\n    network: Module,\n    grads: Union[Tensor, Sequence[Tensor]],\n    losses: Optional[Sequence] = None,\n) -&gt; None\n</code></pre> <p>Calculate the gradient and apply the gradient to the network.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>Module</code> <p>The target network.</p> required <code>grads</code> <code>Union[Tensor, Sequence[Tensor]]</code> <p>The gradients to update. It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.</p> required <code>losses</code> <code>Optional[Sequence]</code> <p>The losses associated with the gradients. The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information, you can set this value as None. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>conflictfree/grad_operator.py</code> <pre><code>def update_gradient(\n    self,\n    network: torch.nn.Module,\n    grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n    losses: Optional[Sequence] = None,\n) -&gt; None:\n    \"\"\"\n    Calculate the gradient and apply the gradient to the network.\n\n    Args:\n        network (torch.nn.Module): The target network.\n        grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n            It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n        losses (Optional[Sequence], optional): The losses associated with the gradients.\n            The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information,\n            you can set this value as None. Defaults to None.\n\n    Returns:\n        None\n\n    \"\"\"\n    apply_gradient_vector(network, self.calculate_gradient(grads, losses))\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.IMTLGOperator","title":"conflictfree.grad_operator.IMTLGOperator","text":"<p>               Bases: <code>GradientOperator</code></p> <p>PCGradOperator class represents a gradient operator for IMTL-G algorithm.</p> <p>@inproceedings{ liu2021towards, title={Towards Impartial Multi-task Learning}, author={Liyang Liu and Yi Li and Zhanghui Kuang and Jing-Hao Xue and Yimin Chen and Wenming Yang and Qingmin Liao and Wayne Zhang}, booktitle={International Conference on Learning Representations}, year={2021}, url={https://openreview.net/forum?id=IMPnRXEWpvr} }</p> Source code in <code>conflictfree/grad_operator.py</code> <pre><code>class IMTLGOperator(GradientOperator):\n    \"\"\"\n    PCGradOperator class represents a gradient operator for IMTL-G algorithm.\n\n    @inproceedings{\n    liu2021towards,\n    title={Towards Impartial Multi-task Learning},\n    author={Liyang Liu and Yi Li and Zhanghui Kuang and Jing-Hao Xue and Yimin Chen and Wenming Yang and Qingmin Liao and Wayne Zhang},\n    booktitle={International Conference on Learning Representations},\n    year={2021},\n    url={https://openreview.net/forum?id=IMPnRXEWpvr}\n    }\n\n    \"\"\"\n\n    def calculate_gradient(\n        self,\n        grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n        losses: Optional[Sequence] = None,\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Calculates the gradient using the IMTL-G algorithm.\n\n        Args:\n            grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n                It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n            losses (Optional[Sequence], optional): This parameter should not be set for current operator. Defaults to None.\n\n        Returns:\n            torch.Tensor: The calculated gradient using IMTL-G method.\n        \"\"\"\n        if not isinstance(grads, torch.Tensor):\n            grads = torch.stack(grads)\n        with torch.no_grad():\n            ut_norm = grads / grads.norm(dim=1).unsqueeze(1)\n            ut_norm = torch.nan_to_num(ut_norm, 0)\n            ut = torch.stack(\n                [ut_norm[0] - ut_norm[i + 1] for i in range(grads.shape[0] - 1)], dim=0\n            ).T\n            d = torch.stack(\n                [grads[0] - grads[i + 1] for i in range(grads.shape[0] - 1)], dim=0\n            )\n            at = grads[0] @ ut @ torch.linalg.pinv(d @ ut)\n            return (1 - torch.sum(at)) * grads[0] + torch.sum(\n                at.unsqueeze(1) * grads[1:], dim=0\n            )\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.IMTLGOperator.calculate_gradient","title":"calculate_gradient","text":"<pre><code>calculate_gradient(\n    grads: Union[Tensor, Sequence[Tensor]],\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Calculates the gradient using the IMTL-G algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>grads</code> <code>Union[Tensor, Sequence[Tensor]]</code> <p>The gradients to update. It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.</p> required <code>losses</code> <code>Optional[Sequence]</code> <p>This parameter should not be set for current operator. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The calculated gradient using IMTL-G method.</p> Source code in <code>conflictfree/grad_operator.py</code> <pre><code>def calculate_gradient(\n    self,\n    grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculates the gradient using the IMTL-G algorithm.\n\n    Args:\n        grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n            It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n        losses (Optional[Sequence], optional): This parameter should not be set for current operator. Defaults to None.\n\n    Returns:\n        torch.Tensor: The calculated gradient using IMTL-G method.\n    \"\"\"\n    if not isinstance(grads, torch.Tensor):\n        grads = torch.stack(grads)\n    with torch.no_grad():\n        ut_norm = grads / grads.norm(dim=1).unsqueeze(1)\n        ut_norm = torch.nan_to_num(ut_norm, 0)\n        ut = torch.stack(\n            [ut_norm[0] - ut_norm[i + 1] for i in range(grads.shape[0] - 1)], dim=0\n        ).T\n        d = torch.stack(\n            [grads[0] - grads[i + 1] for i in range(grads.shape[0] - 1)], dim=0\n        )\n        at = grads[0] @ ut @ torch.linalg.pinv(d @ ut)\n        return (1 - torch.sum(at)) * grads[0] + torch.sum(\n            at.unsqueeze(1) * grads[1:], dim=0\n        )\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.IMTLGOperator.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> Source code in <code>conflictfree/grad_operator.py</code> <pre><code>def __init__(self):\n    pass\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.IMTLGOperator.update_gradient","title":"update_gradient","text":"<pre><code>update_gradient(\n    network: Module,\n    grads: Union[Tensor, Sequence[Tensor]],\n    losses: Optional[Sequence] = None,\n) -&gt; None\n</code></pre> <p>Calculate the gradient and apply the gradient to the network.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>Module</code> <p>The target network.</p> required <code>grads</code> <code>Union[Tensor, Sequence[Tensor]]</code> <p>The gradients to update. It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.</p> required <code>losses</code> <code>Optional[Sequence]</code> <p>The losses associated with the gradients. The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information, you can set this value as None. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>conflictfree/grad_operator.py</code> <pre><code>def update_gradient(\n    self,\n    network: torch.nn.Module,\n    grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n    losses: Optional[Sequence] = None,\n) -&gt; None:\n    \"\"\"\n    Calculate the gradient and apply the gradient to the network.\n\n    Args:\n        network (torch.nn.Module): The target network.\n        grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n            It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n        losses (Optional[Sequence], optional): The losses associated with the gradients.\n            The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information,\n            you can set this value as None. Defaults to None.\n\n    Returns:\n        None\n\n    \"\"\"\n    apply_gradient_vector(network, self.calculate_gradient(grads, losses))\n</code></pre>"},{"location":"api/grad_operator/#base-class-of-operators","title":"Base Class of Operators","text":""},{"location":"api/grad_operator/#conflictfree.grad_operator.GradientOperator","title":"conflictfree.grad_operator.GradientOperator","text":"<p>A base class that represents a gradient operator.</p> <p>Methods:</p> Name Description <code>calculate_gradient</code> <p>Calculates the gradient based on the given gradients and losses.</p> <code>update_gradient</code> <p>Updates the gradient of the network based on the calculated gradient.</p> Source code in <code>conflictfree/grad_operator.py</code> <pre><code>class GradientOperator:\n    \"\"\"\n    A base class that represents a gradient operator.\n\n    Methods:\n        calculate_gradient: Calculates the gradient based on the given gradients and losses.\n        update_gradient: Updates the gradient of the network based on the calculated gradient.\n\n    \"\"\"\n\n    def __init__(self):\n        pass\n\n    def calculate_gradient(\n        self,\n        grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n        losses: Optional[Sequence] = None,\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Calculates the gradient based on the given gradients and losses.\n\n        Args:\n            grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n                It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n            losses (Optional[Sequence], optional): The losses associated with the gradients.\n                The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information,\n                you can set this value as None. Defaults to None.\n\n        Returns:\n            torch.Tensor: The calculated gradient.\n\n        Raises:\n            NotImplementedError: If the method is not implemented.\n\n        \"\"\"\n        raise NotImplementedError(\"calculate_gradient method must be implemented\")\n\n    def update_gradient(\n        self,\n        network: torch.nn.Module,\n        grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n        losses: Optional[Sequence] = None,\n    ) -&gt; None:\n        \"\"\"\n        Calculate the gradient and apply the gradient to the network.\n\n        Args:\n            network (torch.nn.Module): The target network.\n            grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n                It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n            losses (Optional[Sequence], optional): The losses associated with the gradients.\n                The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information,\n                you can set this value as None. Defaults to None.\n\n        Returns:\n            None\n\n        \"\"\"\n        apply_gradient_vector(network, self.calculate_gradient(grads, losses))\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.GradientOperator.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> Source code in <code>conflictfree/grad_operator.py</code> <pre><code>def __init__(self):\n    pass\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.GradientOperator.calculate_gradient","title":"calculate_gradient","text":"<pre><code>calculate_gradient(\n    grads: Union[Tensor, Sequence[Tensor]],\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Calculates the gradient based on the given gradients and losses.</p> <p>Parameters:</p> Name Type Description Default <code>grads</code> <code>Union[Tensor, Sequence[Tensor]]</code> <p>The gradients to update. It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.</p> required <code>losses</code> <code>Optional[Sequence]</code> <p>The losses associated with the gradients. The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information, you can set this value as None. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The calculated gradient.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the method is not implemented.</p> Source code in <code>conflictfree/grad_operator.py</code> <pre><code>def calculate_gradient(\n    self,\n    grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculates the gradient based on the given gradients and losses.\n\n    Args:\n        grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n            It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n        losses (Optional[Sequence], optional): The losses associated with the gradients.\n            The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information,\n            you can set this value as None. Defaults to None.\n\n    Returns:\n        torch.Tensor: The calculated gradient.\n\n    Raises:\n        NotImplementedError: If the method is not implemented.\n\n    \"\"\"\n    raise NotImplementedError(\"calculate_gradient method must be implemented\")\n</code></pre>"},{"location":"api/grad_operator/#conflictfree.grad_operator.GradientOperator.update_gradient","title":"update_gradient","text":"<pre><code>update_gradient(\n    network: Module,\n    grads: Union[Tensor, Sequence[Tensor]],\n    losses: Optional[Sequence] = None,\n) -&gt; None\n</code></pre> <p>Calculate the gradient and apply the gradient to the network.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>Module</code> <p>The target network.</p> required <code>grads</code> <code>Union[Tensor, Sequence[Tensor]]</code> <p>The gradients to update. It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.</p> required <code>losses</code> <code>Optional[Sequence]</code> <p>The losses associated with the gradients. The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information, you can set this value as None. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>conflictfree/grad_operator.py</code> <pre><code>def update_gradient(\n    self,\n    network: torch.nn.Module,\n    grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n    losses: Optional[Sequence] = None,\n) -&gt; None:\n    \"\"\"\n    Calculate the gradient and apply the gradient to the network.\n\n    Args:\n        network (torch.nn.Module): The target network.\n        grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n            It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n        losses (Optional[Sequence], optional): The losses associated with the gradients.\n            The losses will be passed to the weight and length model. If your weight/length model doesn't require loss information,\n            you can set this value as None. Defaults to None.\n\n    Returns:\n        None\n\n    \"\"\"\n    apply_gradient_vector(network, self.calculate_gradient(grads, losses))\n</code></pre>"},{"location":"api/length_model/","title":"4.4. Length Model","text":"<p>The <code>length_model</code> module contains classes for rescaling the magnitude of the final gradient vector. The <code>ProjectionLength</code> class is the default length model for the ConFIG algorithm. You can create a custom length model by inheriting from the <code>LengthModel</code> class.</p>"},{"location":"api/length_model/#length-model","title":"Length Model","text":""},{"location":"api/length_model/#conflictfree.length_model.ProjectionLength","title":"conflictfree.length_model.ProjectionLength","text":"<p>               Bases: <code>LengthModel</code></p> <p>Rescale the length of the target vector based on the projection of the gradients on the target vector:</p> \\[ |\\mathbf{g}_c|=\\sum_{i=1}^m|\\mathbf{g}_i|\\mathcal{S}_c(\\mathbf{g}_i,\\mathbf{g}_c) \\] Source code in <code>conflictfree/length_model.py</code> <pre><code>class ProjectionLength(LengthModel):\n    \"\"\"\n    Rescale the length of the target vector based on the projection of the gradients on the target vector:\n\n    $$\n    |\\mathbf{g}_c|=\\sum_{i=1}^m|\\mathbf{g}_i|\\mathcal{S}_c(\\mathbf{g}_i,\\mathbf{g}_c)\n    $$\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def get_length(\n        self,\n        target_vector: Optional[torch.Tensor] = None,\n        unit_target_vector: Optional[torch.Tensor] = None,\n        gradients: Optional[torch.Tensor] = None,\n        losses: Optional[Sequence] = None,\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Calculates the length based on the given parameters. Not all parameters are required.\n\n        Args:\n            target_vector (Optional[torch.Tensor]): The final update gradient vector.\n                One of the `target_vector` or `unit_target_vector` parameter need to be provided.\n            unit_target_vector (Optional[torch.Tensor]): The unit vector of the target vector.\n                One of the `target_vector` or `unit_target_vector` parameter need to be provided.\n            gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n            losses (Optional[Sequence]): The losses. Not used in this model.\n\n        Returns:\n            Union[torch.Tensor, float]: The calculated length.\n        \"\"\"\n        assert gradients is not None, \"The ProjectionLength model requires gradients information.\"\n        if unit_target_vector is None:\n            unit_target_vector = unit_vector(target_vector)\n        return torch.sum(\n            torch.stack([torch.dot(grad_i, unit_target_vector)\n                        for grad_i in gradients])\n        )\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.ProjectionLength.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> Source code in <code>conflictfree/length_model.py</code> <pre><code>def __init__(self):\n    super().__init__()\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.ProjectionLength.get_length","title":"get_length","text":"<pre><code>get_length(\n    target_vector: Optional[Tensor] = None,\n    unit_target_vector: Optional[Tensor] = None,\n    gradients: Optional[Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Calculates the length based on the given parameters. Not all parameters are required.</p> <p>Parameters:</p> Name Type Description Default <code>target_vector</code> <code>Optional[Tensor]</code> <p>The final update gradient vector. One of the <code>target_vector</code> or <code>unit_target_vector</code> parameter need to be provided.</p> <code>None</code> <code>unit_target_vector</code> <code>Optional[Tensor]</code> <p>The unit vector of the target vector. One of the <code>target_vector</code> or <code>unit_target_vector</code> parameter need to be provided.</p> <code>None</code> <code>gradients</code> <code>Optional[Tensor]</code> <p>The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.</p> <code>None</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses. Not used in this model.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Union[torch.Tensor, float]: The calculated length.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>def get_length(\n    self,\n    target_vector: Optional[torch.Tensor] = None,\n    unit_target_vector: Optional[torch.Tensor] = None,\n    gradients: Optional[torch.Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculates the length based on the given parameters. Not all parameters are required.\n\n    Args:\n        target_vector (Optional[torch.Tensor]): The final update gradient vector.\n            One of the `target_vector` or `unit_target_vector` parameter need to be provided.\n        unit_target_vector (Optional[torch.Tensor]): The unit vector of the target vector.\n            One of the `target_vector` or `unit_target_vector` parameter need to be provided.\n        gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n        losses (Optional[Sequence]): The losses. Not used in this model.\n\n    Returns:\n        Union[torch.Tensor, float]: The calculated length.\n    \"\"\"\n    assert gradients is not None, \"The ProjectionLength model requires gradients information.\"\n    if unit_target_vector is None:\n        unit_target_vector = unit_vector(target_vector)\n    return torch.sum(\n        torch.stack([torch.dot(grad_i, unit_target_vector)\n                    for grad_i in gradients])\n    )\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.ProjectionLength.rescale_length","title":"rescale_length","text":"<pre><code>rescale_length(\n    target_vector: Tensor,\n    gradients: Optional[Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Rescales the length of the target vector based on the given parameters. It calls the get_length method to calculate the length and then rescales the target vector.</p> <p>Parameters:</p> Name Type Description Default <code>target_vector</code> <code>Tensor</code> <p>The final update gradient vector.</p> required <code>gradients</code> <code>Optional[Tensor]</code> <p>The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.</p> <code>None</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The rescaled target vector.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>def rescale_length(\n    self,\n    target_vector: torch.Tensor,\n    gradients: Optional[torch.Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Rescales the length of the target vector based on the given parameters.\n    It calls the get_length method to calculate the length and then rescales the target vector.\n\n    Args:\n        target_vector (torch.Tensor): The final update gradient vector.\n        gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n        losses (Optional[Sequence]): The losses.\n\n    Returns:\n        torch.Tensor: The rescaled target vector.\n    \"\"\"\n    unit_target_vector = unit_vector(target_vector)\n    return (\n        self.get_length(\n            target_vector=target_vector,\n            unit_target_vector=unit_target_vector,\n            gradients=gradients,\n            losses=losses,\n        )\n        * unit_target_vector\n    )\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackMinimum","title":"conflictfree.length_model.TrackMinimum","text":"<p>               Bases: <code>_FlexibleTrackProjectionLength</code></p> <p>Rescale the length of the target vector based on the projection of the gradients on the target vector. All the gradients will be rescaled to the same length as the minimum gradient before projection, i.e., the minimum gradient will be the same length as the target vector.</p> \\[ |\\mathbf{g}_c|=\\sum_{i=1}^m|\\mathbf{g}_{min}|\\mathcal{S}_c(\\mathbf{g}_i,\\mathbf{g}_c) \\] Source code in <code>conflictfree/length_model.py</code> <pre><code>class TrackMinimum(_FlexibleTrackProjectionLength):\n    \"\"\"\n    Rescale the length of the target vector based on the projection of the gradients on the target vector.\n    All the gradients will be rescaled to the same length as the minimum gradient before projection, i.e., the minimum gradient will be the same length as the target vector.\n\n    $$\n    |\\mathbf{g}_c|=\\sum_{i=1}^m|\\mathbf{g}_{min}|\\mathcal{S}_c(\\mathbf{g}_i,\\mathbf{g}_c)\n    $$\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def _tracked_value(self, grad_norms: Tensor) -&gt; Tensor:\n        return grad_norms.min()\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackMinimum.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> Source code in <code>conflictfree/length_model.py</code> <pre><code>def __init__(self):\n    super().__init__()\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackMinimum.get_length","title":"get_length","text":"<pre><code>get_length(\n    target_vector: Optional[Tensor] = None,\n    unit_target_vector: Optional[Tensor] = None,\n    gradients: Optional[Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Calculates the length based on the given parameters. Not all parameters are required.</p> <p>Parameters:</p> Name Type Description Default <code>target_vector</code> <code>Optional[Tensor]</code> <p>The final update gradient vector. One of the <code>target_vector</code> or <code>unit_target_vector</code> parameter need to be provided.</p> <code>None</code> <code>unit_target_vector</code> <code>Optional[Tensor]</code> <p>The unit vector of the target vector. One of the <code>target_vector</code> or <code>unit_target_vector</code> parameter need to be provided.</p> <code>None</code> <code>gradients</code> <code>Optional[Tensor]</code> <p>The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.</p> <code>None</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses. Not used in this model.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Union[torch.Tensor, float]: The calculated length.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>def get_length(\n    self,\n    target_vector: Optional[torch.Tensor] = None,\n    unit_target_vector: Optional[torch.Tensor] = None,\n    gradients: Optional[torch.Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculates the length based on the given parameters. Not all parameters are required.\n\n    Args:\n        target_vector (Optional[torch.Tensor]): The final update gradient vector.\n            One of the `target_vector` or `unit_target_vector` parameter need to be provided.\n        unit_target_vector (Optional[torch.Tensor]): The unit vector of the target vector.\n            One of the `target_vector` or `unit_target_vector` parameter need to be provided.\n        gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n        losses (Optional[Sequence]): The losses. Not used in this model.\n\n    Returns:\n        Union[torch.Tensor, float]: The calculated length.\n    \"\"\"\n    assert gradients is not None, \"The ProjectLength model requires gradients information.\"\n    if unit_target_vector is None:\n        unit_target_vector = unit_vector(target_vector)\n    norms = torch.norm(gradients, dim=1)\n    tracked_value = self._tracked_value(norms)\n    return sum(\n        [\n            torch.dot(grad_i / norm_i, unit_target_vector) * tracked_value\n            for grad_i, norm_i in zip(gradients, norms)\n        ]\n    )\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackMinimum.rescale_length","title":"rescale_length","text":"<pre><code>rescale_length(\n    target_vector: Tensor,\n    gradients: Optional[Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Rescales the length of the target vector based on the given parameters. It calls the get_length method to calculate the length and then rescales the target vector.</p> <p>Parameters:</p> Name Type Description Default <code>target_vector</code> <code>Tensor</code> <p>The final update gradient vector.</p> required <code>gradients</code> <code>Optional[Tensor]</code> <p>The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.</p> <code>None</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The rescaled target vector.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>def rescale_length(\n    self,\n    target_vector: torch.Tensor,\n    gradients: Optional[torch.Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Rescales the length of the target vector based on the given parameters.\n    It calls the get_length method to calculate the length and then rescales the target vector.\n\n    Args:\n        target_vector (torch.Tensor): The final update gradient vector.\n        gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n        losses (Optional[Sequence]): The losses.\n\n    Returns:\n        torch.Tensor: The rescaled target vector.\n    \"\"\"\n    unit_target_vector = unit_vector(target_vector)\n    return (\n        self.get_length(\n            target_vector=target_vector,\n            unit_target_vector=unit_target_vector,\n            gradients=gradients,\n            losses=losses,\n        )\n        * unit_target_vector\n    )\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackMaximum","title":"conflictfree.length_model.TrackMaximum","text":"<p>               Bases: <code>_FlexibleTrackProjectionLength</code></p> <p>Rescale the length of the target vector based on the projection of the gradients on the target vector. All the gradients will be rescaled to the same length as the maximum gradient before projection, i.e., the maximum gradient will be the same length as the target vector.</p> \\[ |\\mathbf{g}_c|=\\sum_{i=1}^m|\\mathbf{g}_{max}|\\mathcal{S}_c(\\mathbf{g}_i,\\mathbf{g}_c) \\] Source code in <code>conflictfree/length_model.py</code> <pre><code>class TrackMaximum(_FlexibleTrackProjectionLength):\n    \"\"\"\n    Rescale the length of the target vector based on the projection of the gradients on the target vector.\n    All the gradients will be rescaled to the same length as the maximum gradient before projection, i.e., the maximum gradient will be the same length as the target vector.\n\n    $$\n    |\\mathbf{g}_c|=\\sum_{i=1}^m|\\mathbf{g}_{max}|\\mathcal{S}_c(\\mathbf{g}_i,\\mathbf{g}_c)\n    $$\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def _tracked_value(self, grad_norms: Tensor) -&gt; Tensor:\n        return grad_norms.max()\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackMaximum.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> Source code in <code>conflictfree/length_model.py</code> <pre><code>def __init__(self):\n    super().__init__()\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackMaximum.get_length","title":"get_length","text":"<pre><code>get_length(\n    target_vector: Optional[Tensor] = None,\n    unit_target_vector: Optional[Tensor] = None,\n    gradients: Optional[Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Calculates the length based on the given parameters. Not all parameters are required.</p> <p>Parameters:</p> Name Type Description Default <code>target_vector</code> <code>Optional[Tensor]</code> <p>The final update gradient vector. One of the <code>target_vector</code> or <code>unit_target_vector</code> parameter need to be provided.</p> <code>None</code> <code>unit_target_vector</code> <code>Optional[Tensor]</code> <p>The unit vector of the target vector. One of the <code>target_vector</code> or <code>unit_target_vector</code> parameter need to be provided.</p> <code>None</code> <code>gradients</code> <code>Optional[Tensor]</code> <p>The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.</p> <code>None</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses. Not used in this model.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Union[torch.Tensor, float]: The calculated length.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>def get_length(\n    self,\n    target_vector: Optional[torch.Tensor] = None,\n    unit_target_vector: Optional[torch.Tensor] = None,\n    gradients: Optional[torch.Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculates the length based on the given parameters. Not all parameters are required.\n\n    Args:\n        target_vector (Optional[torch.Tensor]): The final update gradient vector.\n            One of the `target_vector` or `unit_target_vector` parameter need to be provided.\n        unit_target_vector (Optional[torch.Tensor]): The unit vector of the target vector.\n            One of the `target_vector` or `unit_target_vector` parameter need to be provided.\n        gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n        losses (Optional[Sequence]): The losses. Not used in this model.\n\n    Returns:\n        Union[torch.Tensor, float]: The calculated length.\n    \"\"\"\n    assert gradients is not None, \"The ProjectLength model requires gradients information.\"\n    if unit_target_vector is None:\n        unit_target_vector = unit_vector(target_vector)\n    norms = torch.norm(gradients, dim=1)\n    tracked_value = self._tracked_value(norms)\n    return sum(\n        [\n            torch.dot(grad_i / norm_i, unit_target_vector) * tracked_value\n            for grad_i, norm_i in zip(gradients, norms)\n        ]\n    )\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackMaximum.rescale_length","title":"rescale_length","text":"<pre><code>rescale_length(\n    target_vector: Tensor,\n    gradients: Optional[Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Rescales the length of the target vector based on the given parameters. It calls the get_length method to calculate the length and then rescales the target vector.</p> <p>Parameters:</p> Name Type Description Default <code>target_vector</code> <code>Tensor</code> <p>The final update gradient vector.</p> required <code>gradients</code> <code>Optional[Tensor]</code> <p>The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.</p> <code>None</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The rescaled target vector.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>def rescale_length(\n    self,\n    target_vector: torch.Tensor,\n    gradients: Optional[torch.Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Rescales the length of the target vector based on the given parameters.\n    It calls the get_length method to calculate the length and then rescales the target vector.\n\n    Args:\n        target_vector (torch.Tensor): The final update gradient vector.\n        gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n        losses (Optional[Sequence]): The losses.\n\n    Returns:\n        torch.Tensor: The rescaled target vector.\n    \"\"\"\n    unit_target_vector = unit_vector(target_vector)\n    return (\n        self.get_length(\n            target_vector=target_vector,\n            unit_target_vector=unit_target_vector,\n            gradients=gradients,\n            losses=losses,\n        )\n        * unit_target_vector\n    )\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackHarmonicAverage","title":"conflictfree.length_model.TrackHarmonicAverage","text":"<p>               Bases: <code>_FlexibleTrackProjectionLength</code></p> <p>Rescale the length of the target vector based on the projection of the gradients on the target vector. All the gradients will be rescaled to the harmonic average of the lengths of all gradients before projection, i.e., the minimum gradient will be the same length as the target vector.</p> \\[ |\\mathbf{g}_c|=\\sum_{i=1}^m\\overline{|\\mathbf{g}|}_{harm}\\mathcal{S}_c(\\mathbf{g}_i,\\mathbf{g}_c) \\] <p>where</p> \\[ \\overline{|\\mathbf{g}|}_{harm}=\frac{m}{\\sum_{i=1}^m \frac{1}{|\\mathbf{g}_i|}} \\] <p>The harmonic average can be used to avoid the influence of the large gradients.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>class TrackHarmonicAverage(_FlexibleTrackProjectionLength):\n    \"\"\"\n    Rescale the length of the target vector based on the projection of the gradients on the target vector.\n    All the gradients will be rescaled to the harmonic average of the lengths of all gradients before projection, i.e., the minimum gradient will be the same length as the target vector.\n\n    $$\n    |\\mathbf{g}_c|=\\sum_{i=1}^m\\overline{|\\mathbf{g}|}_{harm}\\mathcal{S}_c(\\mathbf{g}_i,\\mathbf{g}_c)\n    $$\n\n    where\n\n    $$\n    \\overline{|\\mathbf{g}|}_{harm}=\\frac{m}{\\sum_{i=1}^m \\frac{1}{|\\mathbf{g}_i|}}\n    $$\n\n    The harmonic average can be used to avoid the influence of the large gradients.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def _tracked_value(self, grad_norms: Tensor) -&gt; Tensor:\n        return grad_norms.shape[0] / torch.sum(1 / grad_norms)\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackHarmonicAverage.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> Source code in <code>conflictfree/length_model.py</code> <pre><code>def __init__(self):\n    super().__init__()\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackHarmonicAverage.get_length","title":"get_length","text":"<pre><code>get_length(\n    target_vector: Optional[Tensor] = None,\n    unit_target_vector: Optional[Tensor] = None,\n    gradients: Optional[Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Calculates the length based on the given parameters. Not all parameters are required.</p> <p>Parameters:</p> Name Type Description Default <code>target_vector</code> <code>Optional[Tensor]</code> <p>The final update gradient vector. One of the <code>target_vector</code> or <code>unit_target_vector</code> parameter need to be provided.</p> <code>None</code> <code>unit_target_vector</code> <code>Optional[Tensor]</code> <p>The unit vector of the target vector. One of the <code>target_vector</code> or <code>unit_target_vector</code> parameter need to be provided.</p> <code>None</code> <code>gradients</code> <code>Optional[Tensor]</code> <p>The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.</p> <code>None</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses. Not used in this model.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Union[torch.Tensor, float]: The calculated length.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>def get_length(\n    self,\n    target_vector: Optional[torch.Tensor] = None,\n    unit_target_vector: Optional[torch.Tensor] = None,\n    gradients: Optional[torch.Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculates the length based on the given parameters. Not all parameters are required.\n\n    Args:\n        target_vector (Optional[torch.Tensor]): The final update gradient vector.\n            One of the `target_vector` or `unit_target_vector` parameter need to be provided.\n        unit_target_vector (Optional[torch.Tensor]): The unit vector of the target vector.\n            One of the `target_vector` or `unit_target_vector` parameter need to be provided.\n        gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n        losses (Optional[Sequence]): The losses. Not used in this model.\n\n    Returns:\n        Union[torch.Tensor, float]: The calculated length.\n    \"\"\"\n    assert gradients is not None, \"The ProjectLength model requires gradients information.\"\n    if unit_target_vector is None:\n        unit_target_vector = unit_vector(target_vector)\n    norms = torch.norm(gradients, dim=1)\n    tracked_value = self._tracked_value(norms)\n    return sum(\n        [\n            torch.dot(grad_i / norm_i, unit_target_vector) * tracked_value\n            for grad_i, norm_i in zip(gradients, norms)\n        ]\n    )\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackHarmonicAverage.rescale_length","title":"rescale_length","text":"<pre><code>rescale_length(\n    target_vector: Tensor,\n    gradients: Optional[Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Rescales the length of the target vector based on the given parameters. It calls the get_length method to calculate the length and then rescales the target vector.</p> <p>Parameters:</p> Name Type Description Default <code>target_vector</code> <code>Tensor</code> <p>The final update gradient vector.</p> required <code>gradients</code> <code>Optional[Tensor]</code> <p>The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.</p> <code>None</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The rescaled target vector.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>def rescale_length(\n    self,\n    target_vector: torch.Tensor,\n    gradients: Optional[torch.Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Rescales the length of the target vector based on the given parameters.\n    It calls the get_length method to calculate the length and then rescales the target vector.\n\n    Args:\n        target_vector (torch.Tensor): The final update gradient vector.\n        gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n        losses (Optional[Sequence]): The losses.\n\n    Returns:\n        torch.Tensor: The rescaled target vector.\n    \"\"\"\n    unit_target_vector = unit_vector(target_vector)\n    return (\n        self.get_length(\n            target_vector=target_vector,\n            unit_target_vector=unit_target_vector,\n            gradients=gradients,\n            losses=losses,\n        )\n        * unit_target_vector\n    )\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackArithmeticAverage","title":"conflictfree.length_model.TrackArithmeticAverage","text":"<p>               Bases: <code>_FlexibleTrackProjectionLength</code></p> <p>Rescale the length of the target vector based on the projection of the gradients on the target vector. All the gradients will be rescaled to the arithmetic average of the lengths of all gradients before projection, i.e., the minimum gradient will be the same length as the target vector.</p> \\[ |\\mathbf{g}_c|=\\sum_{i=1}^m\\overline{|\\mathbf{g}|}_{arith}\\mathcal{S}_c(\\mathbf{g}_i,\\mathbf{g}_c) \\] <p>where</p> \\[ \\overline{|\\mathbf{g}|}_{arith}=\frac{1}{m}\\sum_{i=1}^m |\\mathbf{g}_i| \\] Source code in <code>conflictfree/length_model.py</code> <pre><code>class TrackArithmeticAverage(_FlexibleTrackProjectionLength):\n    \"\"\"\n    Rescale the length of the target vector based on the projection of the gradients on the target vector.\n    All the gradients will be rescaled to the arithmetic average of the lengths of all gradients before projection, i.e., the minimum gradient will be the same length as the target vector.\n\n    $$\n    |\\mathbf{g}_c|=\\sum_{i=1}^m\\overline{|\\mathbf{g}|}_{arith}\\mathcal{S}_c(\\mathbf{g}_i,\\mathbf{g}_c)\n    $$\n\n    where\n\n    $$\n    \\overline{|\\mathbf{g}|}_{arith}=\\frac{1}{m}\\sum_{i=1}^m |\\mathbf{g}_i|\n    $$\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def _tracked_value(self, grad_norms: Tensor) -&gt; Tensor:\n        return grad_norms.mean()\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackArithmeticAverage.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> Source code in <code>conflictfree/length_model.py</code> <pre><code>def __init__(self):\n    super().__init__()\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackArithmeticAverage.get_length","title":"get_length","text":"<pre><code>get_length(\n    target_vector: Optional[Tensor] = None,\n    unit_target_vector: Optional[Tensor] = None,\n    gradients: Optional[Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Calculates the length based on the given parameters. Not all parameters are required.</p> <p>Parameters:</p> Name Type Description Default <code>target_vector</code> <code>Optional[Tensor]</code> <p>The final update gradient vector. One of the <code>target_vector</code> or <code>unit_target_vector</code> parameter need to be provided.</p> <code>None</code> <code>unit_target_vector</code> <code>Optional[Tensor]</code> <p>The unit vector of the target vector. One of the <code>target_vector</code> or <code>unit_target_vector</code> parameter need to be provided.</p> <code>None</code> <code>gradients</code> <code>Optional[Tensor]</code> <p>The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.</p> <code>None</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses. Not used in this model.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Union[torch.Tensor, float]: The calculated length.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>def get_length(\n    self,\n    target_vector: Optional[torch.Tensor] = None,\n    unit_target_vector: Optional[torch.Tensor] = None,\n    gradients: Optional[torch.Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculates the length based on the given parameters. Not all parameters are required.\n\n    Args:\n        target_vector (Optional[torch.Tensor]): The final update gradient vector.\n            One of the `target_vector` or `unit_target_vector` parameter need to be provided.\n        unit_target_vector (Optional[torch.Tensor]): The unit vector of the target vector.\n            One of the `target_vector` or `unit_target_vector` parameter need to be provided.\n        gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n        losses (Optional[Sequence]): The losses. Not used in this model.\n\n    Returns:\n        Union[torch.Tensor, float]: The calculated length.\n    \"\"\"\n    assert gradients is not None, \"The ProjectLength model requires gradients information.\"\n    if unit_target_vector is None:\n        unit_target_vector = unit_vector(target_vector)\n    norms = torch.norm(gradients, dim=1)\n    tracked_value = self._tracked_value(norms)\n    return sum(\n        [\n            torch.dot(grad_i / norm_i, unit_target_vector) * tracked_value\n            for grad_i, norm_i in zip(gradients, norms)\n        ]\n    )\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackArithmeticAverage.rescale_length","title":"rescale_length","text":"<pre><code>rescale_length(\n    target_vector: Tensor,\n    gradients: Optional[Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Rescales the length of the target vector based on the given parameters. It calls the get_length method to calculate the length and then rescales the target vector.</p> <p>Parameters:</p> Name Type Description Default <code>target_vector</code> <code>Tensor</code> <p>The final update gradient vector.</p> required <code>gradients</code> <code>Optional[Tensor]</code> <p>The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.</p> <code>None</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The rescaled target vector.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>def rescale_length(\n    self,\n    target_vector: torch.Tensor,\n    gradients: Optional[torch.Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Rescales the length of the target vector based on the given parameters.\n    It calls the get_length method to calculate the length and then rescales the target vector.\n\n    Args:\n        target_vector (torch.Tensor): The final update gradient vector.\n        gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n        losses (Optional[Sequence]): The losses.\n\n    Returns:\n        torch.Tensor: The rescaled target vector.\n    \"\"\"\n    unit_target_vector = unit_vector(target_vector)\n    return (\n        self.get_length(\n            target_vector=target_vector,\n            unit_target_vector=unit_target_vector,\n            gradients=gradients,\n            losses=losses,\n        )\n        * unit_target_vector\n    )\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackGeometricAverage","title":"conflictfree.length_model.TrackGeometricAverage","text":"<p>               Bases: <code>_FlexibleTrackProjectionLength</code></p> <p>Rescale the length of the target vector based on the projection of the gradients on the target vector. All the gradients will be rescaled to the geometric average of the lengths of all gradients before projection, i.e., the minimum gradient will be the same length as the target vector.</p> \\[ |\\mathbf{g}_c|=\\sum_{i=1}^m\\overline{|\\mathbf{g}|}_{geom}\\mathcal{S}_c(\\mathbf{g}_i,\\mathbf{g}_c) \\] <p>where</p> \\[ \\overline{|\\mathbf{g}|}_{geom}=\\left(\\prod_{i=1}^m |\\mathbf{g}_i| ight)^{\frac{1}{m}} \\] <p>The geometric average can be used to avoid the influence of the large gradients.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>class TrackGeometricAverage(_FlexibleTrackProjectionLength):\n    \"\"\"\n    Rescale the length of the target vector based on the projection of the gradients on the target vector.\n    All the gradients will be rescaled to the geometric average of the lengths of all gradients before projection, i.e., the minimum gradient will be the same length as the target vector.\n\n    $$\n    |\\mathbf{g}_c|=\\sum_{i=1}^m\\overline{|\\mathbf{g}|}_{geom}\\mathcal{S}_c(\\mathbf{g}_i,\\mathbf{g}_c)\n    $$\n\n    where\n\n    $$\n    \\overline{|\\mathbf{g}|}_{geom}=\\left(\\prod_{i=1}^m |\\mathbf{g}_i|\\right)^{\\frac{1}{m}}\n    $$\n\n    The geometric average can be used to avoid the influence of the large gradients.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def _tracked_value(self, grad_norms: Tensor) -&gt; Tensor:\n        return torch.prod(grad_norms) ** (1 / grad_norms.shape[0])\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackGeometricAverage.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> Source code in <code>conflictfree/length_model.py</code> <pre><code>def __init__(self):\n    super().__init__()\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackGeometricAverage.get_length","title":"get_length","text":"<pre><code>get_length(\n    target_vector: Optional[Tensor] = None,\n    unit_target_vector: Optional[Tensor] = None,\n    gradients: Optional[Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Calculates the length based on the given parameters. Not all parameters are required.</p> <p>Parameters:</p> Name Type Description Default <code>target_vector</code> <code>Optional[Tensor]</code> <p>The final update gradient vector. One of the <code>target_vector</code> or <code>unit_target_vector</code> parameter need to be provided.</p> <code>None</code> <code>unit_target_vector</code> <code>Optional[Tensor]</code> <p>The unit vector of the target vector. One of the <code>target_vector</code> or <code>unit_target_vector</code> parameter need to be provided.</p> <code>None</code> <code>gradients</code> <code>Optional[Tensor]</code> <p>The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.</p> <code>None</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses. Not used in this model.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Union[torch.Tensor, float]: The calculated length.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>def get_length(\n    self,\n    target_vector: Optional[torch.Tensor] = None,\n    unit_target_vector: Optional[torch.Tensor] = None,\n    gradients: Optional[torch.Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculates the length based on the given parameters. Not all parameters are required.\n\n    Args:\n        target_vector (Optional[torch.Tensor]): The final update gradient vector.\n            One of the `target_vector` or `unit_target_vector` parameter need to be provided.\n        unit_target_vector (Optional[torch.Tensor]): The unit vector of the target vector.\n            One of the `target_vector` or `unit_target_vector` parameter need to be provided.\n        gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n        losses (Optional[Sequence]): The losses. Not used in this model.\n\n    Returns:\n        Union[torch.Tensor, float]: The calculated length.\n    \"\"\"\n    assert gradients is not None, \"The ProjectLength model requires gradients information.\"\n    if unit_target_vector is None:\n        unit_target_vector = unit_vector(target_vector)\n    norms = torch.norm(gradients, dim=1)\n    tracked_value = self._tracked_value(norms)\n    return sum(\n        [\n            torch.dot(grad_i / norm_i, unit_target_vector) * tracked_value\n            for grad_i, norm_i in zip(gradients, norms)\n        ]\n    )\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackGeometricAverage.rescale_length","title":"rescale_length","text":"<pre><code>rescale_length(\n    target_vector: Tensor,\n    gradients: Optional[Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Rescales the length of the target vector based on the given parameters. It calls the get_length method to calculate the length and then rescales the target vector.</p> <p>Parameters:</p> Name Type Description Default <code>target_vector</code> <code>Tensor</code> <p>The final update gradient vector.</p> required <code>gradients</code> <code>Optional[Tensor]</code> <p>The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.</p> <code>None</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The rescaled target vector.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>def rescale_length(\n    self,\n    target_vector: torch.Tensor,\n    gradients: Optional[torch.Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Rescales the length of the target vector based on the given parameters.\n    It calls the get_length method to calculate the length and then rescales the target vector.\n\n    Args:\n        target_vector (torch.Tensor): The final update gradient vector.\n        gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n        losses (Optional[Sequence]): The losses.\n\n    Returns:\n        torch.Tensor: The rescaled target vector.\n    \"\"\"\n    unit_target_vector = unit_vector(target_vector)\n    return (\n        self.get_length(\n            target_vector=target_vector,\n            unit_target_vector=unit_target_vector,\n            gradients=gradients,\n            losses=losses,\n        )\n        * unit_target_vector\n    )\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackSpecific","title":"conflictfree.length_model.TrackSpecific","text":"<p>               Bases: <code>_FlexibleTrackProjectionLength</code></p> <p>Rescale the length of the target vector based on the projection of the gradients on the target vector. All the gradients will be rescaled to the same length as the specific gradient before projection. E.g., if the track_id is 2, then all the gradients will be rescaled to the same length as the third gradient before projection.</p> \\[ |\\mathbf{g}_c|=\\sum_{i=1}^m\\overline{|\\mathbf{g}|}_{track_id}\\mathcal{S}_c(\\mathbf{g}_i,\\mathbf{g}_c) \\] Source code in <code>conflictfree/length_model.py</code> <pre><code>class TrackSpecific(_FlexibleTrackProjectionLength):\n    \"\"\"\n    Rescale the length of the target vector based on the projection of the gradients on the target vector.\n    All the gradients will be rescaled to the same length as the specific gradient before projection.\n    E.g., if the track_id is 2, then all the gradients will be rescaled to the same length as the third gradient before projection.\n\n    $$\n    |\\mathbf{g}_c|=\\sum_{i=1}^m\\overline{|\\mathbf{g}|}_{track_id}\\mathcal{S}_c(\\mathbf{g}_i,\\mathbf{g}_c)\n    $$\n\n    \"\"\"\n\n    def __init__(self, track_id: int):\n        super().__init__()\n        self.track_id = track_id\n\n    def _tracked_value(self, grad_norms: Tensor) -&gt; Tensor:\n        return grad_norms[self.track_id]\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackSpecific.track_id","title":"track_id  <code>instance-attribute</code>","text":"<pre><code>track_id = track_id\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackSpecific.__init__","title":"__init__","text":"<pre><code>__init__(track_id: int)\n</code></pre> Source code in <code>conflictfree/length_model.py</code> <pre><code>def __init__(self, track_id: int):\n    super().__init__()\n    self.track_id = track_id\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackSpecific.get_length","title":"get_length","text":"<pre><code>get_length(\n    target_vector: Optional[Tensor] = None,\n    unit_target_vector: Optional[Tensor] = None,\n    gradients: Optional[Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Calculates the length based on the given parameters. Not all parameters are required.</p> <p>Parameters:</p> Name Type Description Default <code>target_vector</code> <code>Optional[Tensor]</code> <p>The final update gradient vector. One of the <code>target_vector</code> or <code>unit_target_vector</code> parameter need to be provided.</p> <code>None</code> <code>unit_target_vector</code> <code>Optional[Tensor]</code> <p>The unit vector of the target vector. One of the <code>target_vector</code> or <code>unit_target_vector</code> parameter need to be provided.</p> <code>None</code> <code>gradients</code> <code>Optional[Tensor]</code> <p>The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.</p> <code>None</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses. Not used in this model.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Union[torch.Tensor, float]: The calculated length.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>def get_length(\n    self,\n    target_vector: Optional[torch.Tensor] = None,\n    unit_target_vector: Optional[torch.Tensor] = None,\n    gradients: Optional[torch.Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculates the length based on the given parameters. Not all parameters are required.\n\n    Args:\n        target_vector (Optional[torch.Tensor]): The final update gradient vector.\n            One of the `target_vector` or `unit_target_vector` parameter need to be provided.\n        unit_target_vector (Optional[torch.Tensor]): The unit vector of the target vector.\n            One of the `target_vector` or `unit_target_vector` parameter need to be provided.\n        gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n        losses (Optional[Sequence]): The losses. Not used in this model.\n\n    Returns:\n        Union[torch.Tensor, float]: The calculated length.\n    \"\"\"\n    assert gradients is not None, \"The ProjectLength model requires gradients information.\"\n    if unit_target_vector is None:\n        unit_target_vector = unit_vector(target_vector)\n    norms = torch.norm(gradients, dim=1)\n    tracked_value = self._tracked_value(norms)\n    return sum(\n        [\n            torch.dot(grad_i / norm_i, unit_target_vector) * tracked_value\n            for grad_i, norm_i in zip(gradients, norms)\n        ]\n    )\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.TrackSpecific.rescale_length","title":"rescale_length","text":"<pre><code>rescale_length(\n    target_vector: Tensor,\n    gradients: Optional[Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Rescales the length of the target vector based on the given parameters. It calls the get_length method to calculate the length and then rescales the target vector.</p> <p>Parameters:</p> Name Type Description Default <code>target_vector</code> <code>Tensor</code> <p>The final update gradient vector.</p> required <code>gradients</code> <code>Optional[Tensor]</code> <p>The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.</p> <code>None</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The rescaled target vector.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>def rescale_length(\n    self,\n    target_vector: torch.Tensor,\n    gradients: Optional[torch.Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Rescales the length of the target vector based on the given parameters.\n    It calls the get_length method to calculate the length and then rescales the target vector.\n\n    Args:\n        target_vector (torch.Tensor): The final update gradient vector.\n        gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n        losses (Optional[Sequence]): The losses.\n\n    Returns:\n        torch.Tensor: The rescaled target vector.\n    \"\"\"\n    unit_target_vector = unit_vector(target_vector)\n    return (\n        self.get_length(\n            target_vector=target_vector,\n            unit_target_vector=unit_target_vector,\n            gradients=gradients,\n            losses=losses,\n        )\n        * unit_target_vector\n    )\n</code></pre>"},{"location":"api/length_model/#base-class-of-length-model","title":"Base Class of Length Model","text":""},{"location":"api/length_model/#conflictfree.length_model.LengthModel","title":"conflictfree.length_model.LengthModel","text":"<p>The base class for length model.</p> <p>Methods:</p> Name Description <code>get_length</code> <p>Calculates the length based on the given parameters.</p> <code>rescale_length</code> <p>Rescales the length of the target vector based on the given parameters.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>class LengthModel:\n    \"\"\"\n    The base class for length model.\n\n    Methods:\n        get_length: Calculates the length based on the given parameters.\n        rescale_length: Rescales the length of the target vector based on the given parameters.\n    \"\"\"\n\n    def __init__(self):\n        pass\n\n    def get_length(\n        self,\n        target_vector: Optional[torch.Tensor] = None,\n        unit_target_vector: Optional[torch.Tensor] = None,\n        gradients: Optional[torch.Tensor] = None,\n        losses: Optional[Sequence] = None,\n    ) -&gt; Union[torch.Tensor, float]:\n        \"\"\"\n        Calculates the length based on the given parameters. Not all parameters are required.\n\n        Args:\n            target_vector (Optional[torch.Tensor]): The final update gradient vector.\n            unit_target_vector (Optional[torch.Tensor]): The unit vector of the target vector.\n            gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n            losses (Optional[Sequence]): The losses.\n\n        Returns:\n            Union[torch.Tensor, float]: The calculated length.\n        \"\"\"\n        raise NotImplementedError(\n            \"This method must be implemented by the subclass.\")\n\n    def rescale_length(\n        self,\n        target_vector: torch.Tensor,\n        gradients: Optional[torch.Tensor] = None,\n        losses: Optional[Sequence] = None,\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Rescales the length of the target vector based on the given parameters.\n        It calls the get_length method to calculate the length and then rescales the target vector.\n\n        Args:\n            target_vector (torch.Tensor): The final update gradient vector.\n            gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n            losses (Optional[Sequence]): The losses.\n\n        Returns:\n            torch.Tensor: The rescaled target vector.\n        \"\"\"\n        unit_target_vector = unit_vector(target_vector)\n        return (\n            self.get_length(\n                target_vector=target_vector,\n                unit_target_vector=unit_target_vector,\n                gradients=gradients,\n                losses=losses,\n            )\n            * unit_target_vector\n        )\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.LengthModel.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> Source code in <code>conflictfree/length_model.py</code> <pre><code>def __init__(self):\n    pass\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.LengthModel.get_length","title":"get_length","text":"<pre><code>get_length(\n    target_vector: Optional[Tensor] = None,\n    unit_target_vector: Optional[Tensor] = None,\n    gradients: Optional[Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; Union[torch.Tensor, float]\n</code></pre> <p>Calculates the length based on the given parameters. Not all parameters are required.</p> <p>Parameters:</p> Name Type Description Default <code>target_vector</code> <code>Optional[Tensor]</code> <p>The final update gradient vector.</p> <code>None</code> <code>unit_target_vector</code> <code>Optional[Tensor]</code> <p>The unit vector of the target vector.</p> <code>None</code> <code>gradients</code> <code>Optional[Tensor]</code> <p>The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.</p> <code>None</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[Tensor, float]</code> <p>Union[torch.Tensor, float]: The calculated length.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>def get_length(\n    self,\n    target_vector: Optional[torch.Tensor] = None,\n    unit_target_vector: Optional[torch.Tensor] = None,\n    gradients: Optional[torch.Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; Union[torch.Tensor, float]:\n    \"\"\"\n    Calculates the length based on the given parameters. Not all parameters are required.\n\n    Args:\n        target_vector (Optional[torch.Tensor]): The final update gradient vector.\n        unit_target_vector (Optional[torch.Tensor]): The unit vector of the target vector.\n        gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n        losses (Optional[Sequence]): The losses.\n\n    Returns:\n        Union[torch.Tensor, float]: The calculated length.\n    \"\"\"\n    raise NotImplementedError(\n        \"This method must be implemented by the subclass.\")\n</code></pre>"},{"location":"api/length_model/#conflictfree.length_model.LengthModel.rescale_length","title":"rescale_length","text":"<pre><code>rescale_length(\n    target_vector: Tensor,\n    gradients: Optional[Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Rescales the length of the target vector based on the given parameters. It calls the get_length method to calculate the length and then rescales the target vector.</p> <p>Parameters:</p> Name Type Description Default <code>target_vector</code> <code>Tensor</code> <p>The final update gradient vector.</p> required <code>gradients</code> <code>Optional[Tensor]</code> <p>The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.</p> <code>None</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The rescaled target vector.</p> Source code in <code>conflictfree/length_model.py</code> <pre><code>def rescale_length(\n    self,\n    target_vector: torch.Tensor,\n    gradients: Optional[torch.Tensor] = None,\n    losses: Optional[Sequence] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Rescales the length of the target vector based on the given parameters.\n    It calls the get_length method to calculate the length and then rescales the target vector.\n\n    Args:\n        target_vector (torch.Tensor): The final update gradient vector.\n        gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n        losses (Optional[Sequence]): The losses.\n\n    Returns:\n        torch.Tensor: The rescaled target vector.\n    \"\"\"\n    unit_target_vector = unit_vector(target_vector)\n    return (\n        self.get_length(\n            target_vector=target_vector,\n            unit_target_vector=unit_target_vector,\n            gradients=gradients,\n            losses=losses,\n        )\n        * unit_target_vector\n    )\n</code></pre>"},{"location":"api/loss_recorder/","title":"4.5. Loss Recorder","text":"<p>The <code>loss_recorder</code> module contains classes for recording the loss values during the optimization process. It is used in the momentum version of the ConFIG algorithm to record the loss values. Not every loss is calculated in a single iteration with the momentum version of the ConFIG algorithm. However, sometimes we need to know the information of all the loss values, e.g., logging and calculating length/weight model. You can create a custom loss recorder by inheriting from the <code>LossRecorder</code> class.</p>"},{"location":"api/loss_recorder/#loss-recorder","title":"Loss Recorder","text":""},{"location":"api/loss_recorder/#conflictfree.loss_recorder.LatestLossRecorder","title":"conflictfree.loss_recorder.LatestLossRecorder","text":"<p>               Bases: <code>LossRecorder</code></p> <p>A loss recorder return the latest losses.</p> <p>Parameters:</p> Name Type Description Default <code>num_losses</code> <code>int</code> <p>The number of losses to record</p> required Source code in <code>conflictfree/loss_recorder.py</code> <pre><code>class LatestLossRecorder(LossRecorder):\n    \"\"\"\n    A loss recorder return the latest losses.\n\n    Args:\n        num_losses (int): The number of losses to record\n    \"\"\"\n\n    def __init__(self, num_losses: int) -&gt; None:\n        super().__init__(num_losses)\n\n    def record_loss(\n        self, losses_indexes: Union[int, Sequence[int]], losses: Union[float, Sequence]\n    ) -&gt; list:\n        \"\"\"\n        Records the given loss and returns the recorded loss.\n\n        Args:\n            losses_indexes: The index of the loss.\n            losses (torch.Tensor): The loss to record.\n\n        Returns:\n            list: The recorded loss.\n\n        \"\"\"\n        losses_indexes, losses = self._preprocess_losses(losses_indexes, losses)\n        for i in losses_indexes:\n            self.current_losses[i] = losses[losses_indexes.index(i)]\n        return self.current_losses\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.LatestLossRecorder.num_losses","title":"num_losses  <code>instance-attribute</code>","text":"<pre><code>num_losses = num_losses\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.LatestLossRecorder.current_losses","title":"current_losses  <code>instance-attribute</code>","text":"<pre><code>current_losses = [0.0 for i in (range(num_losses))]\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.LatestLossRecorder.__init__","title":"__init__","text":"<pre><code>__init__(num_losses: int) -&gt; None\n</code></pre> Source code in <code>conflictfree/loss_recorder.py</code> <pre><code>def __init__(self, num_losses: int) -&gt; None:\n    super().__init__(num_losses)\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.LatestLossRecorder.record_loss","title":"record_loss","text":"<pre><code>record_loss(\n    losses_indexes: Union[int, Sequence[int]],\n    losses: Union[float, Sequence],\n) -&gt; list\n</code></pre> <p>Records the given loss and returns the recorded loss.</p> <p>Parameters:</p> Name Type Description Default <code>losses_indexes</code> <code>Union[int, Sequence[int]]</code> <p>The index of the loss.</p> required <code>losses</code> <code>Tensor</code> <p>The loss to record.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>The recorded loss.</p> Source code in <code>conflictfree/loss_recorder.py</code> <pre><code>def record_loss(\n    self, losses_indexes: Union[int, Sequence[int]], losses: Union[float, Sequence]\n) -&gt; list:\n    \"\"\"\n    Records the given loss and returns the recorded loss.\n\n    Args:\n        losses_indexes: The index of the loss.\n        losses (torch.Tensor): The loss to record.\n\n    Returns:\n        list: The recorded loss.\n\n    \"\"\"\n    losses_indexes, losses = self._preprocess_losses(losses_indexes, losses)\n    for i in losses_indexes:\n        self.current_losses[i] = losses[losses_indexes.index(i)]\n    return self.current_losses\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.LatestLossRecorder.record_all_losses","title":"record_all_losses","text":"<pre><code>record_all_losses(losses: Sequence) -&gt; list\n</code></pre> <p>Records all the losses and returns the recorded losses.</p> <p>Parameters:</p> Name Type Description Default <code>losses</code> <code>Tensor</code> <p>The losses to record.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>The recorded losses.</p> Source code in <code>conflictfree/loss_recorder.py</code> <pre><code>def record_all_losses(self, losses: Sequence) -&gt; list:\n    \"\"\"\n    Records all the losses and returns the recorded losses.\n\n    Args:\n        losses (torch.Tensor): The losses to record.\n\n    Returns:\n        list: The recorded losses.\n\n    \"\"\"\n    assert len(losses) == self.num_losses, \"The number of losses does not match the number of losses to be recorded.\"\n    return self.record_loss([i for i in range(self.num_losses)], losses)\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.MomentumLossRecorder","title":"conflictfree.loss_recorder.MomentumLossRecorder","text":"<p>               Bases: <code>LossRecorder</code></p> <p>A loss recorder that records the momentum of the loss.</p> <p>Parameters:</p> Name Type Description Default <code>num_losses</code> <code>int</code> <p>The number of losses to record</p> required <code>betas</code> <code>Union[float, Sequence[float]]</code> <p>The moving average constant.</p> <code>0.9</code> Source code in <code>conflictfree/loss_recorder.py</code> <pre><code>class MomentumLossRecorder(LossRecorder):\n    \"\"\"\n    A loss recorder that records the momentum of the loss.\n\n    Args:\n        num_losses (int): The number of losses to record\n        betas (Union[float, Sequence[float]]): The moving average constant.\n    \"\"\"\n\n    def __init__(self, num_losses: int, betas: Union[float, Sequence[float]] = 0.9):\n        super().__init__(num_losses)\n        if isinstance(betas, float):\n            self.betas = [betas] * num_losses\n        self.m = [0.0 for i in range(num_losses)]\n        self.t = [0 for i in range(num_losses)]\n\n    def record_loss(\n        self, losses_indexes: Union[int, Sequence[int]], losses: Union[float, Sequence]\n    ) -&gt; list:\n        \"\"\"\n        Records the given loss and returns the recorded loss.\n\n        Args:\n            losses_indexes: The index of the loss.\n            losses (torch.Tensor): The loss to record.\n\n        Returns:\n            list: The recorded loss.\n\n        \"\"\"\n        losses_indexes, losses = self._preprocess_losses(losses_indexes, losses)\n        for index in losses_indexes:\n            self.t[index] += 1\n            self.m[index] = (\n                self.betas * self.m[index]\n                + (1 - self.betas[index]) * losses[losses_indexes.index(index)]\n            )\n        self.current_losses = [\n            self.m[index] / (1 - self.betas[index] ** self.t[index])\n            for index in len(self.m)\n        ]\n        return self.current_losses\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.MomentumLossRecorder.betas","title":"betas  <code>instance-attribute</code>","text":"<pre><code>betas = [betas] * num_losses\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.MomentumLossRecorder.m","title":"m  <code>instance-attribute</code>","text":"<pre><code>m = [0.0 for i in (range(num_losses))]\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.MomentumLossRecorder.t","title":"t  <code>instance-attribute</code>","text":"<pre><code>t = [0 for i in (range(num_losses))]\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.MomentumLossRecorder.num_losses","title":"num_losses  <code>instance-attribute</code>","text":"<pre><code>num_losses = num_losses\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.MomentumLossRecorder.current_losses","title":"current_losses  <code>instance-attribute</code>","text":"<pre><code>current_losses = [0.0 for i in (range(num_losses))]\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.MomentumLossRecorder.__init__","title":"__init__","text":"<pre><code>__init__(\n    num_losses: int,\n    betas: Union[float, Sequence[float]] = 0.9,\n)\n</code></pre> Source code in <code>conflictfree/loss_recorder.py</code> <pre><code>def __init__(self, num_losses: int, betas: Union[float, Sequence[float]] = 0.9):\n    super().__init__(num_losses)\n    if isinstance(betas, float):\n        self.betas = [betas] * num_losses\n    self.m = [0.0 for i in range(num_losses)]\n    self.t = [0 for i in range(num_losses)]\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.MomentumLossRecorder.record_loss","title":"record_loss","text":"<pre><code>record_loss(\n    losses_indexes: Union[int, Sequence[int]],\n    losses: Union[float, Sequence],\n) -&gt; list\n</code></pre> <p>Records the given loss and returns the recorded loss.</p> <p>Parameters:</p> Name Type Description Default <code>losses_indexes</code> <code>Union[int, Sequence[int]]</code> <p>The index of the loss.</p> required <code>losses</code> <code>Tensor</code> <p>The loss to record.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>The recorded loss.</p> Source code in <code>conflictfree/loss_recorder.py</code> <pre><code>def record_loss(\n    self, losses_indexes: Union[int, Sequence[int]], losses: Union[float, Sequence]\n) -&gt; list:\n    \"\"\"\n    Records the given loss and returns the recorded loss.\n\n    Args:\n        losses_indexes: The index of the loss.\n        losses (torch.Tensor): The loss to record.\n\n    Returns:\n        list: The recorded loss.\n\n    \"\"\"\n    losses_indexes, losses = self._preprocess_losses(losses_indexes, losses)\n    for index in losses_indexes:\n        self.t[index] += 1\n        self.m[index] = (\n            self.betas * self.m[index]\n            + (1 - self.betas[index]) * losses[losses_indexes.index(index)]\n        )\n    self.current_losses = [\n        self.m[index] / (1 - self.betas[index] ** self.t[index])\n        for index in len(self.m)\n    ]\n    return self.current_losses\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.MomentumLossRecorder.record_all_losses","title":"record_all_losses","text":"<pre><code>record_all_losses(losses: Sequence) -&gt; list\n</code></pre> <p>Records all the losses and returns the recorded losses.</p> <p>Parameters:</p> Name Type Description Default <code>losses</code> <code>Tensor</code> <p>The losses to record.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>The recorded losses.</p> Source code in <code>conflictfree/loss_recorder.py</code> <pre><code>def record_all_losses(self, losses: Sequence) -&gt; list:\n    \"\"\"\n    Records all the losses and returns the recorded losses.\n\n    Args:\n        losses (torch.Tensor): The losses to record.\n\n    Returns:\n        list: The recorded losses.\n\n    \"\"\"\n    assert len(losses) == self.num_losses, \"The number of losses does not match the number of losses to be recorded.\"\n    return self.record_loss([i for i in range(self.num_losses)], losses)\n</code></pre>"},{"location":"api/loss_recorder/#base-class-of-loss-recorder","title":"Base Class of Loss Recorder","text":""},{"location":"api/loss_recorder/#conflictfree.loss_recorder.LossRecorder","title":"conflictfree.loss_recorder.LossRecorder","text":"<p>Base class for loss recorders.</p> <p>Parameters:</p> Name Type Description Default <code>num_losses</code> <code>int</code> <p>The number of losses to record</p> required Source code in <code>conflictfree/loss_recorder.py</code> <pre><code>class LossRecorder:\n    \"\"\"\n    Base class for loss recorders.\n\n    Args:\n        num_losses (int): The number of losses to record\n    \"\"\"\n\n    def __init__(self, num_losses: int) -&gt; None:\n        self.num_losses = num_losses\n        self.current_losses = [0.0 for i in range(num_losses)]\n\n    def record_loss(\n        self, losses_indexes: Union[int, Sequence[int]], losses: Union[float, Sequence]\n    ) -&gt; list:\n        \"\"\"\n        Records the given loss and returns the recorded losses.\n\n        Args:\n            losses_indexes: The index of the loss.\n            losses (torch.Tensor): The loss to record.\n\n        Returns:\n            list: The recorded losses.\n\n        Raises:\n            NotImplementedError: If the method is not implemented.\n\n        \"\"\"\n        raise NotImplementedError(\"record_loss method must be implemented\")\n\n    def record_all_losses(self, losses: Sequence) -&gt; list:\n        \"\"\"\n        Records all the losses and returns the recorded losses.\n\n        Args:\n            losses (torch.Tensor): The losses to record.\n\n        Returns:\n            list: The recorded losses.\n\n        \"\"\"\n        assert len(losses) == self.num_losses, \"The number of losses does not match the number of losses to be recorded.\"\n        return self.record_loss([i for i in range(self.num_losses)], losses)\n\n    def _preprocess_losses(\n        self, losses_indexes: Union[int, Sequence[int]], losses: Union[float, Sequence]\n    ) -&gt; Tuple[Sequence[int], Sequence]:\n        \"\"\"\n        Preprocesses the losses and their indexes. Recommended to be used in the `record_loss` method.\n\n        Args:\n            losses_indexes (Union[int, Sequence[int]]): The indexes of the losses.\n            losses (Union[float, Sequence]): The losses.\n\n        Returns:\n            Tuple[Sequence[int], Sequence]: A tuple containing the preprocessed losses indexes and losses.\n        \"\"\"\n        if isinstance(losses_indexes, int):\n            losses_indexes = [losses_indexes]\n        if isinstance(losses, float):\n            losses = [losses]\n        return losses_indexes, losses\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.LossRecorder.num_losses","title":"num_losses  <code>instance-attribute</code>","text":"<pre><code>num_losses = num_losses\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.LossRecorder.current_losses","title":"current_losses  <code>instance-attribute</code>","text":"<pre><code>current_losses = [0.0 for i in (range(num_losses))]\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.LossRecorder.__init__","title":"__init__","text":"<pre><code>__init__(num_losses: int) -&gt; None\n</code></pre> Source code in <code>conflictfree/loss_recorder.py</code> <pre><code>def __init__(self, num_losses: int) -&gt; None:\n    self.num_losses = num_losses\n    self.current_losses = [0.0 for i in range(num_losses)]\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.LossRecorder.record_loss","title":"record_loss","text":"<pre><code>record_loss(\n    losses_indexes: Union[int, Sequence[int]],\n    losses: Union[float, Sequence],\n) -&gt; list\n</code></pre> <p>Records the given loss and returns the recorded losses.</p> <p>Parameters:</p> Name Type Description Default <code>losses_indexes</code> <code>Union[int, Sequence[int]]</code> <p>The index of the loss.</p> required <code>losses</code> <code>Tensor</code> <p>The loss to record.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>The recorded losses.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the method is not implemented.</p> Source code in <code>conflictfree/loss_recorder.py</code> <pre><code>def record_loss(\n    self, losses_indexes: Union[int, Sequence[int]], losses: Union[float, Sequence]\n) -&gt; list:\n    \"\"\"\n    Records the given loss and returns the recorded losses.\n\n    Args:\n        losses_indexes: The index of the loss.\n        losses (torch.Tensor): The loss to record.\n\n    Returns:\n        list: The recorded losses.\n\n    Raises:\n        NotImplementedError: If the method is not implemented.\n\n    \"\"\"\n    raise NotImplementedError(\"record_loss method must be implemented\")\n</code></pre>"},{"location":"api/loss_recorder/#conflictfree.loss_recorder.LossRecorder.record_all_losses","title":"record_all_losses","text":"<pre><code>record_all_losses(losses: Sequence) -&gt; list\n</code></pre> <p>Records all the losses and returns the recorded losses.</p> <p>Parameters:</p> Name Type Description Default <code>losses</code> <code>Tensor</code> <p>The losses to record.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>The recorded losses.</p> Source code in <code>conflictfree/loss_recorder.py</code> <pre><code>def record_all_losses(self, losses: Sequence) -&gt; list:\n    \"\"\"\n    Records all the losses and returns the recorded losses.\n\n    Args:\n        losses (torch.Tensor): The losses to record.\n\n    Returns:\n        list: The recorded losses.\n\n    \"\"\"\n    assert len(losses) == self.num_losses, \"The number of losses does not match the number of losses to be recorded.\"\n    return self.record_loss([i for i in range(self.num_losses)], losses)\n</code></pre>"},{"location":"api/momentum_operator/","title":"4.2. Momentum Operator","text":"<p>The <code>momentum_operator</code> module contains the main operators for the momentum version ConFIG algorithm.</p>"},{"location":"api/momentum_operator/#operator-classes","title":"Operator Classes","text":""},{"location":"api/momentum_operator/#conflictfree.momentum_operator.PseudoMomentumOperator","title":"conflictfree.momentum_operator.PseudoMomentumOperator","text":"<p>               Bases: <code>MomentumOperator</code></p> <p>The major momentum version. In this operator, the second momentum is estimated by a pseudo gradient based on the result of the gradient operator. NOTE: The momentum-based operator, e.g., Adam, is not recommend when using this operator. Please consider using SGD optimizer.</p> <p>Parameters:</p> Name Type Description Default <code>num_vectors</code> <code>int</code> <p>The number of gradient vectors.</p> required <code>beta_1</code> <code>float</code> <p>The moving average constant for the first momentum.</p> <code>0.9</code> <code>beta_2</code> <code>float</code> <p>The moving average constant for the second momentum.</p> <code>0.999</code> <code>gradient_operator</code> <code>GradientOperator</code> <p>The base gradient operator. Defaults to ConFIGOperator().</p> <code>ConFIGOperator()</code> <code>loss_recorder</code> <code>LossRecorder</code> <p>The loss recorder object. If you want to pass loss information to \"update_gradient\" method or \"apply_gradient\" method, you need to specify a loss recorder. Defaults to None.</p> <code>None</code> <p>Methods:</p> Name Description <code>calculate_gradient</code> <p>Calculates the gradient based on the given indexes, gradients, and losses.</p> <code>update_gradient</code> <p>Updates the gradient of the given network with the calculated gradient.</p> <p>Examples: <pre><code>from conflictfree.momentum_operator import PseudoMomentumOperator\nfrom conflictfree.utils import get_gradient_vector,apply_gradient_vector\noptimizer=torch.Adam(network.parameters(),lr=1e-3)\noperator=PseudoMomentumOperator(num_vector=len(loss_fns)) # initialize operator, the only difference here is we need to specify the number of gradient vectors.\nglobal_step=0\nfor input_i in dataset:\n    optimizer.zero_grad()\n    index=global_step % len(loss_fns)\n    loss=loss_fns[index](input_i)\n    loss.backward()\n    g_config=operator.calculate_gradient(index,get_gradient_vector(network)) # calculate the conflict-free direction\n    apply_gradient_vector(network,g_config) # or simply use `operator.update_gradient(network,grads)` to calculate and set the conflict-free direction to the network\n    optimizer.step()\n    global_step+=1\n</code></pre></p> Source code in <code>conflictfree/momentum_operator.py</code> <pre><code>class PseudoMomentumOperator(MomentumOperator):\n    \"\"\"\n    The major momentum version.\n    In this operator, the second momentum is estimated by a pseudo gradient based on the result of the gradient operator.\n    NOTE: The momentum-based operator, e.g., Adam, is not recommend when using this operator. Please consider using SGD optimizer.\n\n    Args:\n        num_vectors (int): The number of gradient vectors.\n        beta_1 (float): The moving average constant for the first momentum.\n        beta_2 (float): The moving average constant for the second momentum.\n        gradient_operator (GradientOperator, optional): The base gradient operator. Defaults to ConFIGOperator().\n        loss_recorder (LossRecorder, optional): The loss recorder object.\n            If you want to pass loss information to \"update_gradient\" method or \"apply_gradient\" method, you need to specify a loss recorder. Defaults to None.\n\n    Methods:\n        calculate_gradient(indexes, grads, losses=None):\n            Calculates the gradient based on the given indexes, gradients, and losses.\n        update_gradient(network, indexes, grads, losses=None):\n            Updates the gradient of the given network with the calculated gradient.\n\n    Examples:\n    ```python\n    from conflictfree.momentum_operator import PseudoMomentumOperator\n    from conflictfree.utils import get_gradient_vector,apply_gradient_vector\n    optimizer=torch.Adam(network.parameters(),lr=1e-3)\n    operator=PseudoMomentumOperator(num_vector=len(loss_fns)) # initialize operator, the only difference here is we need to specify the number of gradient vectors.\n    global_step=0\n    for input_i in dataset:\n        optimizer.zero_grad()\n        index=global_step % len(loss_fns)\n        loss=loss_fns[index](input_i)\n        loss.backward()\n        g_config=operator.calculate_gradient(index,get_gradient_vector(network)) # calculate the conflict-free direction\n        apply_gradient_vector(network,g_config) # or simply use `operator.update_gradient(network,grads)` to calculate and set the conflict-free direction to the network\n        optimizer.step()\n        global_step+=1\n    ```\n    \"\"\"\n\n    def __init__(\n        self,\n        num_vectors: int,\n        beta_1: float = 0.9,\n        beta_2: float = 0.999,\n        gradient_operator: GradientOperator = ConFIGOperator(),\n        loss_recorder: Optional[LossRecorder] = None,\n    ) -&gt; None:\n        super().__init__(num_vectors, beta_1, beta_2, gradient_operator, loss_recorder)\n        self.m = None\n        self.s = None\n        self.fake_m = None\n        self.t = 0\n        self.t_grads = [0] * self.num_vectors\n        self.all_initialized = False\n\n    def _preprocess_gradients_losses(\n        self,\n        indexes: Union[int, Sequence[int]],\n        grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n        losses: Optional[Union[float, Sequence]] = None,\n    ):\n        indexes, grads, losses = super()._preprocess_gradients_losses(\n            indexes, grads, losses\n        )\n        if self.m is None or self.s is None or self.fake_m is None:\n            self.m = [\n                torch.zeros(self.len_vectors, device=self.device)\n                for i in range(self.num_vectors)\n            ]\n            self.s = torch.zeros(self.len_vectors, device=self.device)\n            self.fake_m = torch.zeros(self.len_vectors, device=self.device)\n        return indexes, grads, losses\n\n    def calculate_gradient(\n        self,\n        indexes: Union[int, Sequence[int]],\n        grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n        losses: Optional[Union[float, Sequence]] = None,\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Calculates the gradient based on the given indexes, gradients, and losses.\n\n        Args:\n            indexes (Union[int,Sequence[int]]): The indexes of the gradient vectors and losses to be updated.\n                The momentum with the given indexes will be updated based on the given gradients.\n            grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n                It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n            losses (Optional[Sequence], optional): The losses associated with the gradients.\n                The losses will be passed to base gradient operator. If the base gradient operator doesn't require loss information,\n                you can set this value as None. Defaults to None.\n\n        Raises:\n            NotImplementedError: This method must be implemented in a subclass.\n\n        Returns:\n            torch.Tensor: The calculated gradient.\n        \"\"\"\n        with torch.no_grad():\n            indexes, grads, losses = self._preprocess_gradients_losses(\n                indexes, grads, losses\n            )\n            for i in range(len(indexes)):\n                self.t_grads[indexes[i]] += 1\n                self.m[indexes[i]] = (\n                    self.beta_1 * self.m[indexes[i]] + (1 - self.beta_1) * grads[i]\n                )\n            if not self.all_initialized:\n                if has_zero(self.t_grads):\n                    return torch.zeros_like(self.s)\n                else:\n                    self.all_initialized = True\n            self.t += 1\n            m_hats = torch.stack(\n                [\n                    self.m[i] / (1 - self.beta_1 ** self.t_grads[i])\n                    for i in range(self.num_vectors)\n                ],\n                dim=0,\n            )\n            final_grad = self.gradient_operator.calculate_gradient(m_hats, losses)\n            fake_m = final_grad * (1 - self.beta_1**self.t)\n            fake_grad = (fake_m - self.beta_1 * self.fake_m) / (1 - self.beta_1)\n            self.fake_m = fake_m\n            self.s = self.beta_2 * self.s + (1 - self.beta_2) * fake_grad**2\n            s_hat = self.s / (1 - self.beta_2**self.t)\n            final_grad = final_grad / (torch.sqrt(s_hat) + 1e-8)\n        return final_grad\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.PseudoMomentumOperator.m","title":"m  <code>instance-attribute</code>","text":"<pre><code>m = None\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.PseudoMomentumOperator.s","title":"s  <code>instance-attribute</code>","text":"<pre><code>s = None\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.PseudoMomentumOperator.fake_m","title":"fake_m  <code>instance-attribute</code>","text":"<pre><code>fake_m = None\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.PseudoMomentumOperator.t","title":"t  <code>instance-attribute</code>","text":"<pre><code>t = 0\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.PseudoMomentumOperator.t_grads","title":"t_grads  <code>instance-attribute</code>","text":"<pre><code>t_grads = [0] * num_vectors\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.PseudoMomentumOperator.all_initialized","title":"all_initialized  <code>instance-attribute</code>","text":"<pre><code>all_initialized = False\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.PseudoMomentumOperator.len_vectors","title":"len_vectors  <code>instance-attribute</code>","text":"<pre><code>len_vectors = None\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.PseudoMomentumOperator.device","title":"device  <code>instance-attribute</code>","text":"<pre><code>device = None\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.PseudoMomentumOperator.beta_1","title":"beta_1  <code>instance-attribute</code>","text":"<pre><code>beta_1 = beta_1\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.PseudoMomentumOperator.beta_2","title":"beta_2  <code>instance-attribute</code>","text":"<pre><code>beta_2 = beta_2\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.PseudoMomentumOperator.num_vectors","title":"num_vectors  <code>instance-attribute</code>","text":"<pre><code>num_vectors = num_vectors\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.PseudoMomentumOperator.gradient_operator","title":"gradient_operator  <code>instance-attribute</code>","text":"<pre><code>gradient_operator = gradient_operator\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.PseudoMomentumOperator.loss_recorder","title":"loss_recorder  <code>instance-attribute</code>","text":"<pre><code>loss_recorder = loss_recorder\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.PseudoMomentumOperator.__init__","title":"__init__","text":"<pre><code>__init__(\n    num_vectors: int,\n    beta_1: float = 0.9,\n    beta_2: float = 0.999,\n    gradient_operator: GradientOperator = ConFIGOperator(),\n    loss_recorder: Optional[LossRecorder] = None,\n) -&gt; None\n</code></pre> Source code in <code>conflictfree/momentum_operator.py</code> <pre><code>def __init__(\n    self,\n    num_vectors: int,\n    beta_1: float = 0.9,\n    beta_2: float = 0.999,\n    gradient_operator: GradientOperator = ConFIGOperator(),\n    loss_recorder: Optional[LossRecorder] = None,\n) -&gt; None:\n    super().__init__(num_vectors, beta_1, beta_2, gradient_operator, loss_recorder)\n    self.m = None\n    self.s = None\n    self.fake_m = None\n    self.t = 0\n    self.t_grads = [0] * self.num_vectors\n    self.all_initialized = False\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.PseudoMomentumOperator.calculate_gradient","title":"calculate_gradient","text":"<pre><code>calculate_gradient(\n    indexes: Union[int, Sequence[int]],\n    grads: Union[Tensor, Sequence[Tensor]],\n    losses: Optional[Union[float, Sequence]] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Calculates the gradient based on the given indexes, gradients, and losses.</p> <p>Parameters:</p> Name Type Description Default <code>indexes</code> <code>Union[int, Sequence[int]]</code> <p>The indexes of the gradient vectors and losses to be updated. The momentum with the given indexes will be updated based on the given gradients.</p> required <code>grads</code> <code>Union[Tensor, Sequence[Tensor]]</code> <p>The gradients to update. It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.</p> required <code>losses</code> <code>Optional[Sequence]</code> <p>The losses associated with the gradients. The losses will be passed to base gradient operator. If the base gradient operator doesn't require loss information, you can set this value as None. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This method must be implemented in a subclass.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The calculated gradient.</p> Source code in <code>conflictfree/momentum_operator.py</code> <pre><code>def calculate_gradient(\n    self,\n    indexes: Union[int, Sequence[int]],\n    grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n    losses: Optional[Union[float, Sequence]] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculates the gradient based on the given indexes, gradients, and losses.\n\n    Args:\n        indexes (Union[int,Sequence[int]]): The indexes of the gradient vectors and losses to be updated.\n            The momentum with the given indexes will be updated based on the given gradients.\n        grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n            It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n        losses (Optional[Sequence], optional): The losses associated with the gradients.\n            The losses will be passed to base gradient operator. If the base gradient operator doesn't require loss information,\n            you can set this value as None. Defaults to None.\n\n    Raises:\n        NotImplementedError: This method must be implemented in a subclass.\n\n    Returns:\n        torch.Tensor: The calculated gradient.\n    \"\"\"\n    with torch.no_grad():\n        indexes, grads, losses = self._preprocess_gradients_losses(\n            indexes, grads, losses\n        )\n        for i in range(len(indexes)):\n            self.t_grads[indexes[i]] += 1\n            self.m[indexes[i]] = (\n                self.beta_1 * self.m[indexes[i]] + (1 - self.beta_1) * grads[i]\n            )\n        if not self.all_initialized:\n            if has_zero(self.t_grads):\n                return torch.zeros_like(self.s)\n            else:\n                self.all_initialized = True\n        self.t += 1\n        m_hats = torch.stack(\n            [\n                self.m[i] / (1 - self.beta_1 ** self.t_grads[i])\n                for i in range(self.num_vectors)\n            ],\n            dim=0,\n        )\n        final_grad = self.gradient_operator.calculate_gradient(m_hats, losses)\n        fake_m = final_grad * (1 - self.beta_1**self.t)\n        fake_grad = (fake_m - self.beta_1 * self.fake_m) / (1 - self.beta_1)\n        self.fake_m = fake_m\n        self.s = self.beta_2 * self.s + (1 - self.beta_2) * fake_grad**2\n        s_hat = self.s / (1 - self.beta_2**self.t)\n        final_grad = final_grad / (torch.sqrt(s_hat) + 1e-8)\n    return final_grad\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.PseudoMomentumOperator.update_gradient","title":"update_gradient","text":"<pre><code>update_gradient(\n    network: Module,\n    indexes: Union[int, Sequence[int]],\n    grads: Union[Tensor, Sequence[Tensor]],\n    losses: Optional[Union[float, Sequence]] = None,\n) -&gt; None\n</code></pre> <p>Updates the gradient of the given network with the calculated gradient.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>Module</code> <p>The network to update the gradient.</p> required <code>indexes</code> <code>Union[int, Sequence[int]]</code> <p>The indexes of the gradient vectors and losses to be updated. The momentum with the given indexes will be updated based on the given gradients.</p> required <code>grads</code> <code>Union[Tensor, Sequence[Tensor]]</code> <p>The gradients to update. It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.</p> required <code>losses</code> <code>Optional[Sequence]</code> <p>The losses associated with the gradients. The losses will be passed to base gradient operator. If the base gradient operator doesn't require loss information, you can set this value as None. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This method must be implemented in a subclass.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>conflictfree/momentum_operator.py</code> <pre><code>def update_gradient(\n    self,\n    network: torch.nn.Module,\n    indexes: Union[int, Sequence[int]],\n    grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n    losses: Optional[Union[float, Sequence]] = None,\n) -&gt; None:\n    \"\"\"\n    Updates the gradient of the given network with the calculated gradient.\n\n    Args:\n        network (torch.nn.Module): The network to update the gradient.\n        indexes (Union[int,Sequence[int]]): The indexes of the gradient vectors and losses to be updated.\n            The momentum with the given indexes will be updated based on the given gradients.\n        grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n            It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n        losses (Optional[Sequence], optional): The losses associated with the gradients.\n            The losses will be passed to base gradient operator. If the base gradient operator doesn't require loss information,\n            you can set this value as None. Defaults to None.\n\n    Raises:\n        NotImplementedError: This method must be implemented in a subclass.\n\n    Returns:\n        None\n    \"\"\"\n    apply_gradient_vector(network, self.calculate_gradient(indexes, grads, losses))\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.SeparateMomentumOperator","title":"conflictfree.momentum_operator.SeparateMomentumOperator","text":"<p>               Bases: <code>MomentumOperator</code></p> <p>In this operator, each gradient has its own second gradient. The gradient operator is applied on the rescaled momentum. NOTE: Please consider using the PseudoMomentumOperator since this operator does not give good performance according to our research. The momentum-based operator, e.g., Adam, is not recommend when using this operator. Please consider using SGD optimizer.</p> <p>Parameters:</p> Name Type Description Default <code>num_vectors</code> <code>int</code> <p>The number of gradient vectors.</p> required <code>beta_1</code> <code>float</code> <p>The moving average constant for the first momentum.</p> <code>0.9</code> <code>beta_2</code> <code>float</code> <p>The moving average constant for the second momentum.</p> <code>0.999</code> <code>gradient_operator</code> <code>GradientOperator</code> <p>The base gradient operator. Defaults to ConFIGOperator().</p> <code>ConFIGOperator()</code> <code>loss_recorder</code> <code>LossRecorder</code> <p>The loss recorder object. If you want to pass loss information to \"update_gradient\" method or \"apply_gradient\" method, you need to specify a loss recorder. Defaults to None.</p> <code>None</code> <p>Methods:</p> Name Description <code>calculate_gradient</code> <p>Calculates the gradient based on the given indexes, gradients, and losses.</p> <code>update_gradient</code> <p>Updates the gradient of the given network with the calculated gradient.</p> Source code in <code>conflictfree/momentum_operator.py</code> <pre><code>class SeparateMomentumOperator(MomentumOperator):\n    \"\"\"\n    In this operator, each gradient has its own second gradient. The gradient operator is applied on the rescaled momentum.\n    NOTE: Please consider using the PseudoMomentumOperator since this operator does not give good performance according to our research.\n    The momentum-based operator, e.g., Adam, is not recommend when using this operator. Please consider using SGD optimizer.\n\n    Args:\n        num_vectors (int): The number of gradient vectors.\n        beta_1 (float): The moving average constant for the first momentum.\n        beta_2 (float): The moving average constant for the second momentum.\n        gradient_operator (GradientOperator, optional): The base gradient operator. Defaults to ConFIGOperator().\n        loss_recorder (LossRecorder, optional): The loss recorder object.\n            If you want to pass loss information to \"update_gradient\" method or \"apply_gradient\" method, you need to specify a loss recorder. Defaults to None.\n\n    Methods:\n        calculate_gradient(indexes, grads, losses=None):\n            Calculates the gradient based on the given indexes, gradients, and losses.\n        update_gradient(network, indexes, grads, losses=None):\n            Updates the gradient of the given network with the calculated gradient.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        num_vectors: int,\n        beta_1: float = 0.9,\n        beta_2: float = 0.999,\n        gradient_operator: GradientOperator = ConFIGOperator(),\n        loss_recorder: Optional[LossRecorder] = None,\n    ) -&gt; None:\n        super().__init__(num_vectors, beta_1, beta_2, gradient_operator, loss_recorder)\n        self.m = None\n        self.s = None\n        self.t_grads = [0] * len(self.num_vectors)\n        self.all_initialized = False\n\n    def _preprocess_gradients_losses(\n        self,\n        indexes: Union[int, Sequence[int]],\n        grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n        losses: Optional[Union[float, Sequence]] = None,\n    ):\n        indexes, grads, losses = super()._preprocess_gradients_losses(\n            indexes, grads, losses\n        )\n        if self.m is None or self.s is None:\n            self.m = [\n                torch.zeros(self.len_vectors, device=self.device)\n                for i in range(self.num_vectors)\n            ]\n            self.s = [\n                torch.zeros(self.len_vectors, device=self.device)\n                for i in range(self.num_vectors)\n            ]\n        return indexes, grads, losses\n\n    def calculate_gradient(\n        self,\n        indexes: Union[int, Sequence[int]],\n        grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n        losses: Optional[Union[float, Sequence]] = None,\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Calculates the gradient based on the given indexes, gradients, and losses.\n\n        Args:\n            indexes (Union[int,Sequence[int]]): The indexes of the gradient vectors and losses to be updated.\n                The momentum with the given indexes will be updated based on the given gradients.\n            grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n                It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n            losses (Optional[Sequence], optional): The losses associated with the gradients.\n                The losses will be passed to base gradient operator. If the base gradient operator doesn't require loss information,\n                you can set this value as None. Defaults to None.\n\n        Raises:\n            NotImplementedError: This method must be implemented in a subclass.\n\n        Returns:\n            torch.Tensor: The calculated gradient.\n        \"\"\"\n        with torch.no_grad():\n            indexes, grads, losses = self._preprocess_gradients_losses(\n                indexes, grads, losses\n            )\n            for i in range(len(indexes)):\n                self.t_grads[indexes[i]] += 1\n                self.m[indexes[i]] = (\n                    self.beta_1 * self.m[indexes[i]] + (1 - self.beta_1) * grads[i]\n                )\n                self.s[indexes[i]] = (\n                    self.beta_2 * self.s[indexes[i]] + (1 - self.beta_2) * grads[i] ** 2\n                )\n            if not self.all_initialized:\n                if has_zero(self.t_grads):\n                    return torch.zeros_like(self.s)\n                else:\n                    self.all_initialized = True\n            m_hats = torch.stack(\n                [\n                    self.m[i] / (1 - self.betas_1 ** self.t_grads[i])\n                    for i in range(self.num_vectors)\n                ],\n                dim=0,\n            )\n            s_hats = torch.stack(\n                [\n                    self.s[i] / (1 - self.betas_2 ** self.t_grads[i])\n                    for i in range(self.num_vectors)\n                ],\n                dim=0,\n            )\n        return self.gradient_operator.calculate_gradient(\n            m_hats / (torch.sqrt(s_hats) + 1e-8),\n            losses,\n        )\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.SeparateMomentumOperator.m","title":"m  <code>instance-attribute</code>","text":"<pre><code>m = None\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.SeparateMomentumOperator.s","title":"s  <code>instance-attribute</code>","text":"<pre><code>s = None\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.SeparateMomentumOperator.t_grads","title":"t_grads  <code>instance-attribute</code>","text":"<pre><code>t_grads = [0] * len(num_vectors)\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.SeparateMomentumOperator.all_initialized","title":"all_initialized  <code>instance-attribute</code>","text":"<pre><code>all_initialized = False\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.SeparateMomentumOperator.len_vectors","title":"len_vectors  <code>instance-attribute</code>","text":"<pre><code>len_vectors = None\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.SeparateMomentumOperator.device","title":"device  <code>instance-attribute</code>","text":"<pre><code>device = None\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.SeparateMomentumOperator.beta_1","title":"beta_1  <code>instance-attribute</code>","text":"<pre><code>beta_1 = beta_1\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.SeparateMomentumOperator.beta_2","title":"beta_2  <code>instance-attribute</code>","text":"<pre><code>beta_2 = beta_2\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.SeparateMomentumOperator.num_vectors","title":"num_vectors  <code>instance-attribute</code>","text":"<pre><code>num_vectors = num_vectors\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.SeparateMomentumOperator.gradient_operator","title":"gradient_operator  <code>instance-attribute</code>","text":"<pre><code>gradient_operator = gradient_operator\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.SeparateMomentumOperator.loss_recorder","title":"loss_recorder  <code>instance-attribute</code>","text":"<pre><code>loss_recorder = loss_recorder\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.SeparateMomentumOperator.__init__","title":"__init__","text":"<pre><code>__init__(\n    num_vectors: int,\n    beta_1: float = 0.9,\n    beta_2: float = 0.999,\n    gradient_operator: GradientOperator = ConFIGOperator(),\n    loss_recorder: Optional[LossRecorder] = None,\n) -&gt; None\n</code></pre> Source code in <code>conflictfree/momentum_operator.py</code> <pre><code>def __init__(\n    self,\n    num_vectors: int,\n    beta_1: float = 0.9,\n    beta_2: float = 0.999,\n    gradient_operator: GradientOperator = ConFIGOperator(),\n    loss_recorder: Optional[LossRecorder] = None,\n) -&gt; None:\n    super().__init__(num_vectors, beta_1, beta_2, gradient_operator, loss_recorder)\n    self.m = None\n    self.s = None\n    self.t_grads = [0] * len(self.num_vectors)\n    self.all_initialized = False\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.SeparateMomentumOperator.calculate_gradient","title":"calculate_gradient","text":"<pre><code>calculate_gradient(\n    indexes: Union[int, Sequence[int]],\n    grads: Union[Tensor, Sequence[Tensor]],\n    losses: Optional[Union[float, Sequence]] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Calculates the gradient based on the given indexes, gradients, and losses.</p> <p>Parameters:</p> Name Type Description Default <code>indexes</code> <code>Union[int, Sequence[int]]</code> <p>The indexes of the gradient vectors and losses to be updated. The momentum with the given indexes will be updated based on the given gradients.</p> required <code>grads</code> <code>Union[Tensor, Sequence[Tensor]]</code> <p>The gradients to update. It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.</p> required <code>losses</code> <code>Optional[Sequence]</code> <p>The losses associated with the gradients. The losses will be passed to base gradient operator. If the base gradient operator doesn't require loss information, you can set this value as None. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This method must be implemented in a subclass.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The calculated gradient.</p> Source code in <code>conflictfree/momentum_operator.py</code> <pre><code>def calculate_gradient(\n    self,\n    indexes: Union[int, Sequence[int]],\n    grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n    losses: Optional[Union[float, Sequence]] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculates the gradient based on the given indexes, gradients, and losses.\n\n    Args:\n        indexes (Union[int,Sequence[int]]): The indexes of the gradient vectors and losses to be updated.\n            The momentum with the given indexes will be updated based on the given gradients.\n        grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n            It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n        losses (Optional[Sequence], optional): The losses associated with the gradients.\n            The losses will be passed to base gradient operator. If the base gradient operator doesn't require loss information,\n            you can set this value as None. Defaults to None.\n\n    Raises:\n        NotImplementedError: This method must be implemented in a subclass.\n\n    Returns:\n        torch.Tensor: The calculated gradient.\n    \"\"\"\n    with torch.no_grad():\n        indexes, grads, losses = self._preprocess_gradients_losses(\n            indexes, grads, losses\n        )\n        for i in range(len(indexes)):\n            self.t_grads[indexes[i]] += 1\n            self.m[indexes[i]] = (\n                self.beta_1 * self.m[indexes[i]] + (1 - self.beta_1) * grads[i]\n            )\n            self.s[indexes[i]] = (\n                self.beta_2 * self.s[indexes[i]] + (1 - self.beta_2) * grads[i] ** 2\n            )\n        if not self.all_initialized:\n            if has_zero(self.t_grads):\n                return torch.zeros_like(self.s)\n            else:\n                self.all_initialized = True\n        m_hats = torch.stack(\n            [\n                self.m[i] / (1 - self.betas_1 ** self.t_grads[i])\n                for i in range(self.num_vectors)\n            ],\n            dim=0,\n        )\n        s_hats = torch.stack(\n            [\n                self.s[i] / (1 - self.betas_2 ** self.t_grads[i])\n                for i in range(self.num_vectors)\n            ],\n            dim=0,\n        )\n    return self.gradient_operator.calculate_gradient(\n        m_hats / (torch.sqrt(s_hats) + 1e-8),\n        losses,\n    )\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.SeparateMomentumOperator.update_gradient","title":"update_gradient","text":"<pre><code>update_gradient(\n    network: Module,\n    indexes: Union[int, Sequence[int]],\n    grads: Union[Tensor, Sequence[Tensor]],\n    losses: Optional[Union[float, Sequence]] = None,\n) -&gt; None\n</code></pre> <p>Updates the gradient of the given network with the calculated gradient.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>Module</code> <p>The network to update the gradient.</p> required <code>indexes</code> <code>Union[int, Sequence[int]]</code> <p>The indexes of the gradient vectors and losses to be updated. The momentum with the given indexes will be updated based on the given gradients.</p> required <code>grads</code> <code>Union[Tensor, Sequence[Tensor]]</code> <p>The gradients to update. It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.</p> required <code>losses</code> <code>Optional[Sequence]</code> <p>The losses associated with the gradients. The losses will be passed to base gradient operator. If the base gradient operator doesn't require loss information, you can set this value as None. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This method must be implemented in a subclass.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>conflictfree/momentum_operator.py</code> <pre><code>def update_gradient(\n    self,\n    network: torch.nn.Module,\n    indexes: Union[int, Sequence[int]],\n    grads: Union[torch.Tensor, Sequence[torch.Tensor]],\n    losses: Optional[Union[float, Sequence]] = None,\n) -&gt; None:\n    \"\"\"\n    Updates the gradient of the given network with the calculated gradient.\n\n    Args:\n        network (torch.nn.Module): The network to update the gradient.\n        indexes (Union[int,Sequence[int]]): The indexes of the gradient vectors and losses to be updated.\n            The momentum with the given indexes will be updated based on the given gradients.\n        grads (Union[torch.Tensor,Sequence[torch.Tensor]]): The gradients to update.\n            It can be a stack of gradient vectors (at dim 0) or a sequence of gradient vectors.\n        losses (Optional[Sequence], optional): The losses associated with the gradients.\n            The losses will be passed to base gradient operator. If the base gradient operator doesn't require loss information,\n            you can set this value as None. Defaults to None.\n\n    Raises:\n        NotImplementedError: This method must be implemented in a subclass.\n\n    Returns:\n        None\n    \"\"\"\n    apply_gradient_vector(network, self.calculate_gradient(indexes, grads, losses))\n</code></pre>"},{"location":"api/momentum_operator/#base-class-of-operators","title":"Base Class of Operators","text":""},{"location":"api/momentum_operator/#conflictfree.momentum_operator.LatestLossRecorder","title":"conflictfree.momentum_operator.LatestLossRecorder","text":"<p>               Bases: <code>LossRecorder</code></p> <p>A loss recorder return the latest losses.</p> <p>Parameters:</p> Name Type Description Default <code>num_losses</code> <code>int</code> <p>The number of losses to record</p> required Source code in <code>conflictfree/loss_recorder.py</code> <pre><code>class LatestLossRecorder(LossRecorder):\n    \"\"\"\n    A loss recorder return the latest losses.\n\n    Args:\n        num_losses (int): The number of losses to record\n    \"\"\"\n\n    def __init__(self, num_losses: int) -&gt; None:\n        super().__init__(num_losses)\n\n    def record_loss(\n        self, losses_indexes: Union[int, Sequence[int]], losses: Union[float, Sequence]\n    ) -&gt; list:\n        \"\"\"\n        Records the given loss and returns the recorded loss.\n\n        Args:\n            losses_indexes: The index of the loss.\n            losses (torch.Tensor): The loss to record.\n\n        Returns:\n            list: The recorded loss.\n\n        \"\"\"\n        losses_indexes, losses = self._preprocess_losses(losses_indexes, losses)\n        for i in losses_indexes:\n            self.current_losses[i] = losses[losses_indexes.index(i)]\n        return self.current_losses\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.LatestLossRecorder.num_losses","title":"num_losses  <code>instance-attribute</code>","text":"<pre><code>num_losses = num_losses\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.LatestLossRecorder.current_losses","title":"current_losses  <code>instance-attribute</code>","text":"<pre><code>current_losses = [0.0 for i in (range(num_losses))]\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.LatestLossRecorder.record_all_losses","title":"record_all_losses","text":"<pre><code>record_all_losses(losses: Sequence) -&gt; list\n</code></pre> <p>Records all the losses and returns the recorded losses.</p> <p>Parameters:</p> Name Type Description Default <code>losses</code> <code>Tensor</code> <p>The losses to record.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>The recorded losses.</p> Source code in <code>conflictfree/loss_recorder.py</code> <pre><code>def record_all_losses(self, losses: Sequence) -&gt; list:\n    \"\"\"\n    Records all the losses and returns the recorded losses.\n\n    Args:\n        losses (torch.Tensor): The losses to record.\n\n    Returns:\n        list: The recorded losses.\n\n    \"\"\"\n    assert len(losses) == self.num_losses, \"The number of losses does not match the number of losses to be recorded.\"\n    return self.record_loss([i for i in range(self.num_losses)], losses)\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.LatestLossRecorder.__init__","title":"__init__","text":"<pre><code>__init__(num_losses: int) -&gt; None\n</code></pre> Source code in <code>conflictfree/loss_recorder.py</code> <pre><code>def __init__(self, num_losses: int) -&gt; None:\n    super().__init__(num_losses)\n</code></pre>"},{"location":"api/momentum_operator/#conflictfree.momentum_operator.LatestLossRecorder.record_loss","title":"record_loss","text":"<pre><code>record_loss(\n    losses_indexes: Union[int, Sequence[int]],\n    losses: Union[float, Sequence],\n) -&gt; list\n</code></pre> <p>Records the given loss and returns the recorded loss.</p> <p>Parameters:</p> Name Type Description Default <code>losses_indexes</code> <code>Union[int, Sequence[int]]</code> <p>The index of the loss.</p> required <code>losses</code> <code>Tensor</code> <p>The loss to record.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>The recorded loss.</p> Source code in <code>conflictfree/loss_recorder.py</code> <pre><code>def record_loss(\n    self, losses_indexes: Union[int, Sequence[int]], losses: Union[float, Sequence]\n) -&gt; list:\n    \"\"\"\n    Records the given loss and returns the recorded loss.\n\n    Args:\n        losses_indexes: The index of the loss.\n        losses (torch.Tensor): The loss to record.\n\n    Returns:\n        list: The recorded loss.\n\n    \"\"\"\n    losses_indexes, losses = self._preprocess_losses(losses_indexes, losses)\n    for i in losses_indexes:\n        self.current_losses[i] = losses[losses_indexes.index(i)]\n    return self.current_losses\n</code></pre>"},{"location":"api/utils/","title":"4.6. Utils","text":"<p>The <code>utils</code> module contains utility functions for the ConFIG algorithm.</p>"},{"location":"api/utils/#network-utility-functions","title":"Network Utility Functions","text":""},{"location":"api/utils/#conflictfree.utils.get_para_vector","title":"conflictfree.utils.get_para_vector","text":"<pre><code>get_para_vector(network: Module) -&gt; torch.Tensor\n</code></pre> <p>Returns the parameter vector of the given network.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>Module</code> <p>The network for which to compute the gradient vector.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The parameter vector of the network.</p> Source code in <code>conflictfree/utils.py</code> <pre><code>def get_para_vector(network: torch.nn.Module) -&gt; torch.Tensor:\n    \"\"\"\n    Returns the parameter vector of the given network.\n\n    Args:\n        network (torch.nn.Module): The network for which to compute the gradient vector.\n\n    Returns:\n        torch.Tensor: The parameter vector of the network.\n    \"\"\"\n    with torch.no_grad():\n        para_vec = None\n        for par in network.parameters():\n            viewed = par.data.view(-1)\n            if para_vec is None:\n                para_vec = viewed\n            else:\n                para_vec = torch.cat((para_vec, viewed))\n        return para_vec\n</code></pre>"},{"location":"api/utils/#conflictfree.utils.apply_para_vector","title":"conflictfree.utils.apply_para_vector","text":"<pre><code>apply_para_vector(\n    network: Module, para_vec: Tensor\n) -&gt; None\n</code></pre> <p>Applies a parameter vector to the network's parameters.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>Module</code> <p>The network to apply the parameter vector to.</p> required <code>para_vec</code> <code>Tensor</code> <p>The parameter vector to apply.</p> required Source code in <code>conflictfree/utils.py</code> <pre><code>def apply_para_vector(network: torch.nn.Module, para_vec: torch.Tensor) -&gt; None:\n    \"\"\"\n    Applies a parameter vector to the network's parameters.\n\n    Args:\n        network (torch.nn.Module): The network to apply the parameter vector to.\n        para_vec (torch.Tensor): The parameter vector to apply.\n    \"\"\"\n    with torch.no_grad():\n        start = 0\n        for par in network.parameters():\n            end = start + par.data.view(-1).shape[0]\n            par.data = para_vec[start:end].view(par.data.shape)\n            start = end\n</code></pre>"},{"location":"api/utils/#conflictfree.utils.get_gradient_vector","title":"conflictfree.utils.get_gradient_vector","text":"<pre><code>get_gradient_vector(\n    network: Module,\n    none_grad_mode: Literal[\n        \"raise\", \"zero\", \"skip\"\n    ] = \"skip\",\n) -&gt; torch.Tensor\n</code></pre> <p>Returns the gradient vector of the given network.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>Module</code> <p>The network for which to compute the gradient vector.</p> required <code>none_grad_mode</code> <code>Literal['raise', 'zero', 'skip']</code> <p>The mode to handle None gradients. default: 'skip' - 'raise': Raise an error when the gradient of a parameter is None. - 'zero': Replace the None gradient with a zero tensor. - 'skip': Skip the None gradient.             The None gradient usually occurs when part of the network is not trainable (e.g., fine-tuning) or the weight is not used to calculate the current loss (e.g., different parts of the network calculate different losses). If all of your losses are calculated using the same part of the network, you should set none_grad_mode to 'skip'. If your losses are calculated using different parts of the network, you should set none_grad_mode to 'zero' to ensure the gradients have the same shape.</p> <code>'skip'</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The gradient vector of the network.</p> Source code in <code>conflictfree/utils.py</code> <pre><code>def get_gradient_vector(\n    network: torch.nn.Module, none_grad_mode: Literal[\"raise\", \"zero\", \"skip\"] = \"skip\"\n) -&gt; torch.Tensor:\n    \"\"\"\n    Returns the gradient vector of the given network.\n\n    Args:\n        network (torch.nn.Module): The network for which to compute the gradient vector.\n        none_grad_mode (Literal['raise', 'zero', 'skip']): The mode to handle None gradients. default: 'skip'\n            - 'raise': Raise an error when the gradient of a parameter is None.\n            - 'zero': Replace the None gradient with a zero tensor.\n            - 'skip': Skip the None gradient.\n                        The None gradient usually occurs when part of the network is not trainable (e.g., fine-tuning)\n            or the weight is not used to calculate the current loss (e.g., different parts of the network calculate different losses).\n            If all of your losses are calculated using the same part of the network, you should set none_grad_mode to 'skip'.\n            If your losses are calculated using different parts of the network, you should set none_grad_mode to 'zero' to ensure the gradients have the same shape.\n\n    Returns:\n        torch.Tensor: The gradient vector of the network.\n    \"\"\"\n    with torch.no_grad():\n        grad_vec = None\n        for par in network.parameters():\n            if par.grad is None:\n                if none_grad_mode == \"raise\":\n                    raise RuntimeError(\"None gradient detected.\")\n                elif none_grad_mode == \"zero\":\n                    viewed = torch.zeros_like(par.data.view(-1))\n                elif none_grad_mode == \"skip\":\n                    continue\n                else:\n                    raise ValueError(f\"Invalid none_grad_mode '{none_grad_mode}'.\")\n            else:\n                viewed = par.grad.data.view(-1)\n            if grad_vec is None:\n                grad_vec = viewed\n            else:\n                grad_vec = torch.cat((grad_vec, viewed))\n        return grad_vec\n</code></pre>"},{"location":"api/utils/#conflictfree.utils.apply_gradient_vector","title":"conflictfree.utils.apply_gradient_vector","text":"<pre><code>apply_gradient_vector(\n    network: Module,\n    grad_vec: Tensor,\n    none_grad_mode: Literal[\"zero\", \"skip\"] = \"skip\",\n    zero_grad_mode: Literal[\n        \"skip\", \"pad_zero\", \"pad_value\"\n    ] = \"pad_value\",\n) -&gt; None\n</code></pre> <p>Applies a gradient vector to the network's parameters. This function requires the network contains the some gradient information in order to apply the gradient vector. If your network does not contain the gradient information, you should consider using <code>apply_gradient_vector_para_based</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>Module</code> <p>The network to apply the gradient vector to.</p> required <code>grad_vec</code> <code>Tensor</code> <p>The gradient vector to apply.</p> required <code>none_grad_mode</code> <code>Literal['zero', 'skip']</code> <p>The mode to handle None gradients. You should set this parameter to the same value as the one used in <code>get_gradient_vector</code> method.</p> <code>'skip'</code> <code>zero_grad_mode</code> <code>Literal['padding', 'skip']</code> <p>How to set the value of the gradient if your <code>none_grad_mode</code> is \"zero\". default: 'skip' - 'skip': Skip the None gradient. - 'padding': Replace the None gradient with a zero tensor. - 'pad_value': Replace the None gradient using the value in the gradient. If you set <code>none_grad_mode</code> to 'zero', that means you padded zero to your <code>grad_vec</code> if the gradient of the parameter is None when getting the gradient vector. When you apply the gradient vector back to the network, the value in the <code>grad_vec</code> corresponding to the previous None gradient may not be zero due to the applied gradient operation.             Thus, you need to determine whether to recover the original None value, set it to zero, or set the value according to the value in <code>grad_vec</code>. If you are not sure what you are doing, it is safer to set it to 'pad_value'.</p> <code>'pad_value'</code> Source code in <code>conflictfree/utils.py</code> <pre><code>def apply_gradient_vector(\n    network: torch.nn.Module,\n    grad_vec: torch.Tensor,\n    none_grad_mode: Literal[\"zero\", \"skip\"] = \"skip\",\n    zero_grad_mode: Literal[\"skip\", \"pad_zero\", \"pad_value\"] = \"pad_value\",\n) -&gt; None:\n    \"\"\"\n    Applies a gradient vector to the network's parameters.\n    This function requires the network contains the some gradient information in order to apply the gradient vector.\n    If your network does not contain the gradient information, you should consider using `apply_gradient_vector_para_based` function.\n\n    Args:\n        network (torch.nn.Module): The network to apply the gradient vector to.\n        grad_vec (torch.Tensor): The gradient vector to apply.\n        none_grad_mode (Literal['zero', 'skip']): The mode to handle None gradients.\n            You should set this parameter to the same value as the one used in `get_gradient_vector` method.\n        zero_grad_mode (Literal['padding', 'skip']): How to set the value of the gradient if your `none_grad_mode` is \"zero\". default: 'skip'\n            - 'skip': Skip the None gradient.\n            - 'padding': Replace the None gradient with a zero tensor.\n            - 'pad_value': Replace the None gradient using the value in the gradient.\n            If you set `none_grad_mode` to 'zero', that means you padded zero to your `grad_vec` if the gradient of the parameter is None when getting the gradient vector.\n            When you apply the gradient vector back to the network, the value in the `grad_vec` corresponding to the previous None gradient may not be zero due to the applied gradient operation.\n                        Thus, you need to determine whether to recover the original None value, set it to zero, or set the value according to the value in `grad_vec`.\n            If you are not sure what you are doing, it is safer to set it to 'pad_value'.\n\n    \"\"\"\n    if none_grad_mode == \"zero\" and zero_grad_mode == \"pad_value\":\n        apply_gradient_vector_para_based(network, grad_vec)\n    with torch.no_grad():\n        start = 0\n        for par in network.parameters():\n            if par.grad is None:\n                if none_grad_mode == \"skip\":\n                    continue\n                elif none_grad_mode == \"zero\":\n                    start = start + par.data.view(-1).shape[0]\n                    if zero_grad_mode == \"pad_zero\":\n                        par.grad = torch.zeros_like(par.data)\n                    elif zero_grad_mode == \"skip\":\n                        continue\n                    else:\n                        raise ValueError(f\"Invalid zero_grad_mode '{zero_grad_mode}'.\")\n                else:\n                    raise ValueError(f\"Invalid none_grad_mode '{none_grad_mode}'.\")\n            else:\n                end = start + par.data.view(-1).shape[0]\n                par.grad.data = grad_vec[start:end].view(par.data.shape)\n                start = end\n</code></pre>"},{"location":"api/utils/#conflictfree.utils.apply_gradient_vector_para_based","title":"conflictfree.utils.apply_gradient_vector_para_based","text":"<pre><code>apply_gradient_vector_para_based(\n    network: Module, grad_vec: Tensor\n) -&gt; None\n</code></pre> <p>Applies a gradient vector to the network's parameters. Please only use this function when you are sure that the length of <code>grad_vec</code> is the same of your network's parameters. This happens when you use <code>get_gradient_vector</code> with <code>none_grad_mode</code> set to 'zero'. Or, the 'none_grad_mode' is 'skip' but all of the parameters in your network is involved in the loss calculation.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>Module</code> <p>The network to apply the gradient vector to.</p> required <code>grad_vec</code> <code>Tensor</code> <p>The gradient vector to apply.</p> required Source code in <code>conflictfree/utils.py</code> <pre><code>def apply_gradient_vector_para_based(\n    network: torch.nn.Module,\n    grad_vec: torch.Tensor,\n) -&gt; None:\n    \"\"\"\n    Applies a gradient vector to the network's parameters.\n    Please only use this function when you are sure that the length of `grad_vec` is the same of your network's parameters.\n    This happens when you use `get_gradient_vector` with `none_grad_mode` set to 'zero'.\n    Or, the 'none_grad_mode' is 'skip' but all of the parameters in your network is involved in the loss calculation.\n\n    Args:\n        network (torch.nn.Module): The network to apply the gradient vector to.\n        grad_vec (torch.Tensor): The gradient vector to apply.\n    \"\"\"\n    with torch.no_grad():\n        start = 0\n        for par in network.parameters():\n            end = start + par.data.view(-1).shape[0]\n            par.grad = grad_vec[start:end].view(par.data.shape)\n            start = end\n</code></pre>"},{"location":"api/utils/#math-utility-functions","title":"Math Utility Functions","text":""},{"location":"api/utils/#conflictfree.utils.get_cos_similarity","title":"conflictfree.utils.get_cos_similarity","text":"<pre><code>get_cos_similarity(\n    vector1: Tensor, vector2: Tensor\n) -&gt; torch.Tensor\n</code></pre> <p>Calculates the cosine angle between two vectors.</p> <p>Parameters:</p> Name Type Description Default <code>vector1</code> <code>Tensor</code> <p>The first vector.</p> required <code>vector2</code> <code>Tensor</code> <p>The second vector.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The cosine angle between the two vectors.</p> Source code in <code>conflictfree/utils.py</code> <pre><code>def get_cos_similarity(vector1: torch.Tensor, vector2: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Calculates the cosine angle between two vectors.\n\n    Args:\n        vector1 (torch.Tensor): The first vector.\n        vector2 (torch.Tensor): The second vector.\n\n    Returns:\n        torch.Tensor: The cosine angle between the two vectors.\n    \"\"\"\n    with torch.no_grad():\n        return torch.dot(vector1, vector2) / vector1.norm() / vector2.norm()\n</code></pre>"},{"location":"api/utils/#conflictfree.utils.unit_vector","title":"conflictfree.utils.unit_vector","text":"<pre><code>unit_vector(\n    vector: Tensor, warn_zero: bool = False\n) -&gt; torch.Tensor\n</code></pre> <p>Compute the unit vector of a given tensor.</p> <p>Parameters:</p> Name Type Description Default <code>vector</code> <code>Tensor</code> <p>The input tensor.</p> required <code>warn_zero</code> <code>bool</code> <p>Whether to print a warning when the input tensor is zero. default: False</p> <code>False</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The unit vector of the input tensor.</p> Source code in <code>conflictfree/utils.py</code> <pre><code>def unit_vector(vector: torch.Tensor, warn_zero: bool = False) -&gt; torch.Tensor:\n    \"\"\"\n    Compute the unit vector of a given tensor.\n\n    Parameters:\n        vector (torch.Tensor): The input tensor.\n        warn_zero (bool): Whether to print a warning when the input tensor is zero. default: False\n\n    Returns:\n        torch.Tensor: The unit vector of the input tensor.\n    \"\"\"\n    with torch.no_grad():\n        if vector.norm() == 0:\n            if warn_zero:\n                print(\"Detected zero vector when doing normalization.\")\n            return torch.zeros_like(vector)\n        else:\n            return vector / vector.norm()\n</code></pre>"},{"location":"api/utils/#conflict-utility-functions","title":"Conflict Utility Functions","text":""},{"location":"api/utils/#conflictfree.utils.estimate_conflict","title":"conflictfree.utils.estimate_conflict","text":"<pre><code>estimate_conflict(gradients: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Estimates the degree of conflict of gradients.</p> <p>Parameters:</p> Name Type Description Default <code>gradients</code> <code>Tensor</code> <p>A tensor containing gradients.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: A tensor consistent of the dot products between the sum of gradients and each sub-gradient.</p> Source code in <code>conflictfree/utils.py</code> <pre><code>def estimate_conflict(gradients: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Estimates the degree of conflict of gradients.\n\n    Args:\n        gradients (torch.Tensor): A tensor containing gradients.\n\n    Returns:\n        torch.Tensor: A tensor consistent of the dot products between the sum of gradients and each sub-gradient.\n    \"\"\"\n    direct_sum = unit_vector(gradients.sum(dim=0))\n    unit_grads = gradients / torch.norm(gradients, dim=1).view(-1, 1)\n    return unit_grads @ direct_sum\n</code></pre>"},{"location":"api/utils/#slice-selector-classes","title":"Slice Selector Classes","text":""},{"location":"api/utils/#conflictfree.utils.OrderedSliceSelector","title":"conflictfree.utils.OrderedSliceSelector","text":"<p>Selects a slice of the source sequence in order. Usually used for selecting loss functions/gradients/losses in momentum-based method if you want to update more tha one gradient in a single iteration.</p> Source code in <code>conflictfree/utils.py</code> <pre><code>class OrderedSliceSelector:\n    \"\"\"\n    Selects a slice of the source sequence in order.\n    Usually used for selecting loss functions/gradients/losses in momentum-based method if you want to update more tha one gradient in a single iteration.\n\n    \"\"\"\n\n    def __init__(self):\n        self.start_index = 0\n\n    def select(\n        self, n: int, source_sequence: Sequence\n    ) -&gt; Tuple[Sequence, Union[float, Sequence]]:\n        \"\"\"\n        Selects a slice of the source sequence in order.\n\n        Args:\n            n (int): The length of the target slice.\n            source_sequence (Sequence): The source sequence to select from.\n\n        Returns:\n            Tuple[Sequence,Union[float,Sequence]]: A tuple containing the indexes of the selected slice and the selected slice.\n        \"\"\"\n        if n &gt; len(source_sequence):\n            raise ValueError(\n                \"n must be less than or equal to the length of the source sequence\"\n            )\n        end_index = self.start_index + n\n        if end_index &gt; len(source_sequence) - 1:\n            new_start = end_index - len(source_sequence)\n            indexes = list(range(self.start_index, len(source_sequence))) + list(\n                range(0, new_start)\n            )\n            self.start_index = new_start\n        else:\n            indexes = list(range(self.start_index, end_index))\n            self.start_index = end_index\n        if len(indexes) == 1:\n            return indexes, source_sequence[indexes[0]]\n        else:\n            return indexes, [source_sequence[i] for i in indexes]\n</code></pre>"},{"location":"api/utils/#conflictfree.utils.OrderedSliceSelector.start_index","title":"start_index  <code>instance-attribute</code>","text":"<pre><code>start_index = 0\n</code></pre>"},{"location":"api/utils/#conflictfree.utils.OrderedSliceSelector.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> Source code in <code>conflictfree/utils.py</code> <pre><code>def __init__(self):\n    self.start_index = 0\n</code></pre>"},{"location":"api/utils/#conflictfree.utils.OrderedSliceSelector.select","title":"select","text":"<pre><code>select(\n    n: int, source_sequence: Sequence\n) -&gt; Tuple[Sequence, Union[float, Sequence]]\n</code></pre> <p>Selects a slice of the source sequence in order.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>The length of the target slice.</p> required <code>source_sequence</code> <code>Sequence</code> <p>The source sequence to select from.</p> required <p>Returns:</p> Type Description <code>Tuple[Sequence, Union[float, Sequence]]</code> <p>Tuple[Sequence,Union[float,Sequence]]: A tuple containing the indexes of the selected slice and the selected slice.</p> Source code in <code>conflictfree/utils.py</code> <pre><code>def select(\n    self, n: int, source_sequence: Sequence\n) -&gt; Tuple[Sequence, Union[float, Sequence]]:\n    \"\"\"\n    Selects a slice of the source sequence in order.\n\n    Args:\n        n (int): The length of the target slice.\n        source_sequence (Sequence): The source sequence to select from.\n\n    Returns:\n        Tuple[Sequence,Union[float,Sequence]]: A tuple containing the indexes of the selected slice and the selected slice.\n    \"\"\"\n    if n &gt; len(source_sequence):\n        raise ValueError(\n            \"n must be less than or equal to the length of the source sequence\"\n        )\n    end_index = self.start_index + n\n    if end_index &gt; len(source_sequence) - 1:\n        new_start = end_index - len(source_sequence)\n        indexes = list(range(self.start_index, len(source_sequence))) + list(\n            range(0, new_start)\n        )\n        self.start_index = new_start\n    else:\n        indexes = list(range(self.start_index, end_index))\n        self.start_index = end_index\n    if len(indexes) == 1:\n        return indexes, source_sequence[indexes[0]]\n    else:\n        return indexes, [source_sequence[i] for i in indexes]\n</code></pre>"},{"location":"api/utils/#conflictfree.utils.RandomSliceSelector","title":"conflictfree.utils.RandomSliceSelector","text":"<p>Selects a slice of the source sequence randomly. Usually used for selecting loss functions/gradients/losses in momentum-based method if you want to update more tha one gradient in a single iteration.</p> Source code in <code>conflictfree/utils.py</code> <pre><code>class RandomSliceSelector:\n    \"\"\"\n    Selects a slice of the source sequence randomly.\n    Usually used for selecting loss functions/gradients/losses in momentum-based method if you want to update more tha one gradient in a single iteration.\n    \"\"\"\n\n    def select(\n        self, n: int, source_sequence: Sequence\n    ) -&gt; Tuple[Sequence, Union[float, Sequence]]:\n        \"\"\"\n        Selects a slice of the source sequence randomly.\n\n        Args:\n            n (int): The length of the target slice.\n            source_sequence (Sequence): The source sequence to select from.\n\n        Returns:\n            Tuple[Sequence,Union[float,Sequence]]: A tuple containing the indexes of the selected slice and the selected slice.\n        \"\"\"\n        assert n &lt;= len(\n            source_sequence\n        ), \"n can not be larger than or equal to the length of the source sequence\"\n        indexes = np.random.choice(len(source_sequence), n, replace=False)\n        if len(indexes) == 1:\n            return indexes, source_sequence[indexes[0]]\n        else:\n            return indexes, [source_sequence[i] for i in indexes]\n</code></pre>"},{"location":"api/utils/#conflictfree.utils.RandomSliceSelector.select","title":"select","text":"<pre><code>select(\n    n: int, source_sequence: Sequence\n) -&gt; Tuple[Sequence, Union[float, Sequence]]\n</code></pre> <p>Selects a slice of the source sequence randomly.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>The length of the target slice.</p> required <code>source_sequence</code> <code>Sequence</code> <p>The source sequence to select from.</p> required <p>Returns:</p> Type Description <code>Tuple[Sequence, Union[float, Sequence]]</code> <p>Tuple[Sequence,Union[float,Sequence]]: A tuple containing the indexes of the selected slice and the selected slice.</p> Source code in <code>conflictfree/utils.py</code> <pre><code>def select(\n    self, n: int, source_sequence: Sequence\n) -&gt; Tuple[Sequence, Union[float, Sequence]]:\n    \"\"\"\n    Selects a slice of the source sequence randomly.\n\n    Args:\n        n (int): The length of the target slice.\n        source_sequence (Sequence): The source sequence to select from.\n\n    Returns:\n        Tuple[Sequence,Union[float,Sequence]]: A tuple containing the indexes of the selected slice and the selected slice.\n    \"\"\"\n    assert n &lt;= len(\n        source_sequence\n    ), \"n can not be larger than or equal to the length of the source sequence\"\n    indexes = np.random.choice(len(source_sequence), n, replace=False)\n    if len(indexes) == 1:\n        return indexes, source_sequence[indexes[0]]\n    else:\n        return indexes, [source_sequence[i] for i in indexes]\n</code></pre>"},{"location":"api/utils/#others","title":"Others","text":""},{"location":"api/utils/#conflictfree.utils.has_zero","title":"conflictfree.utils.has_zero","text":"<pre><code>has_zero(lists: Sequence) -&gt; bool\n</code></pre> <p>Check if any element in the list is zero.</p> <p>Parameters:</p> Name Type Description Default <code>lists</code> <code>Sequence</code> <p>A list of elements.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if any element is zero, False otherwise.</p> Source code in <code>conflictfree/utils.py</code> <pre><code>def has_zero(lists: Sequence) -&gt; bool:\n    \"\"\"\n    Check if any element in the list is zero.\n\n    Args:\n        lists (Sequence): A list of elements.\n\n    Returns:\n        bool: True if any element is zero, False otherwise.\n    \"\"\"\n    for i in lists:\n        if i == 0:\n            return True\n    return False\n</code></pre>"},{"location":"api/weight_model/","title":"4.3. Weight Model","text":"<p>The <code>weight_model</code> module contains classes for calculating the direction weight of the final gradient vector. The <code>EqualWeight</code> class is the default weight model for the ConFIG algorithm. You can create a custom weight model by inheriting from the <code>WeightModel</code> class.</p>"},{"location":"api/weight_model/#weight-model","title":"Weight Model","text":""},{"location":"api/weight_model/#conflictfree.weight_model.EqualWeight","title":"conflictfree.weight_model.EqualWeight","text":"<p>               Bases: <code>WeightModel</code></p> <p>A weight model that assigns equal weights to all gradients.</p> Source code in <code>conflictfree/weight_model.py</code> <pre><code>class EqualWeight(WeightModel):\n    \"\"\"\n    A weight model that assigns equal weights to all gradients.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def get_weights(\n        self,\n        gradients: torch.Tensor,\n        losses: Optional[Sequence] = None,\n        device: Optional[Union[torch.device, str]] = None,\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Calculate the weights for the given gradients.\n\n        Args:\n            gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n            losses (Optional[Sequence]): The losses. Not used in this model.\n\n        Returns:\n            torch.Tensor: A tensor of equal weights for all gradients.\n\n        Raises:\n            ValueError: If gradients is None.\n        \"\"\"\n        assert gradients is not None, \"The EqualWeight model requires gradients\"\n        return torch.ones(gradients.shape[0], device=device)\n</code></pre>"},{"location":"api/weight_model/#conflictfree.weight_model.EqualWeight.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> Source code in <code>conflictfree/weight_model.py</code> <pre><code>def __init__(self):\n    super().__init__()\n</code></pre>"},{"location":"api/weight_model/#conflictfree.weight_model.EqualWeight.get_weights","title":"get_weights","text":"<pre><code>get_weights(\n    gradients: Tensor,\n    losses: Optional[Sequence] = None,\n    device: Optional[Union[device, str]] = None,\n) -&gt; torch.Tensor\n</code></pre> <p>Calculate the weights for the given gradients.</p> <p>Parameters:</p> Name Type Description Default <code>gradients</code> <code>Optional[Tensor]</code> <p>The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.</p> required <code>losses</code> <code>Optional[Sequence]</code> <p>The losses. Not used in this model.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: A tensor of equal weights for all gradients.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If gradients is None.</p> Source code in <code>conflictfree/weight_model.py</code> <pre><code>def get_weights(\n    self,\n    gradients: torch.Tensor,\n    losses: Optional[Sequence] = None,\n    device: Optional[Union[torch.device, str]] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculate the weights for the given gradients.\n\n    Args:\n        gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n        losses (Optional[Sequence]): The losses. Not used in this model.\n\n    Returns:\n        torch.Tensor: A tensor of equal weights for all gradients.\n\n    Raises:\n        ValueError: If gradients is None.\n    \"\"\"\n    assert gradients is not None, \"The EqualWeight model requires gradients\"\n    return torch.ones(gradients.shape[0], device=device)\n</code></pre>"},{"location":"api/weight_model/#base-class-of-weight-model","title":"Base Class of Weight Model","text":""},{"location":"api/weight_model/#conflictfree.weight_model.WeightModel","title":"conflictfree.weight_model.WeightModel","text":"<p>Base class for weight models.</p> Source code in <code>conflictfree/weight_model.py</code> <pre><code>class WeightModel:\n    \"\"\"\n    Base class for weight models.\n    \"\"\"\n\n    def __init__(self):\n        pass\n\n    def get_weights(\n        self,\n        gradients: Optional[torch.Tensor] = None,\n        losses: Optional[Sequence] = None,\n    ):\n        \"\"\"_summary_\n\n        Args:\n            gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n            losses (Optional[Sequence]): The losses.\n\n        Raises:\n            NotImplementedError: _description_\n        \"\"\"\n        raise NotImplementedError(\"This method must be implemented by the subclass.\")\n</code></pre>"},{"location":"api/weight_model/#conflictfree.weight_model.WeightModel.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> Source code in <code>conflictfree/weight_model.py</code> <pre><code>def __init__(self):\n    pass\n</code></pre>"},{"location":"api/weight_model/#conflictfree.weight_model.WeightModel.get_weights","title":"get_weights","text":"<pre><code>get_weights(\n    gradients: Optional[Tensor] = None,\n    losses: Optional[Sequence] = None,\n)\n</code></pre> <p>summary</p> <p>Parameters:</p> Name Type Description Default <code>gradients</code> <code>Optional[Tensor]</code> <p>The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.</p> <code>None</code> <code>losses</code> <code>Optional[Sequence]</code> <p>The losses.</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>description</p> Source code in <code>conflictfree/weight_model.py</code> <pre><code>def get_weights(\n    self,\n    gradients: Optional[torch.Tensor] = None,\n    losses: Optional[Sequence] = None,\n):\n    \"\"\"_summary_\n\n    Args:\n        gradients (Optional[torch.Tensor]): The loss-specific gradients matrix. The shape of this tensor should be (m,N) where m is the number of gradients and N is the number of elements of each gradients.\n        losses (Optional[Sequence]): The losses.\n\n    Raises:\n        NotImplementedError: _description_\n    \"\"\"\n    raise NotImplementedError(\"This method must be implemented by the subclass.\")\n</code></pre>"},{"location":"examples/mtl_toy/","title":"2.1. Toy Example of Muti-task Learning","text":"In\u00a0[1]: Copied! <pre>import torch\n\nLOWER = 0.000005\ndef landscape(x,y):\n    l1 = torch.clamp((0.5 * (-x - 7) - torch.tanh(-y)).abs(), LOWER).log() + 6\n    l1_sq = ((-x+ 7).pow(2) + 0.1 * (-y - 8).pow(2)) / 10 - 20\n    l2 = torch.clamp((0.5 * (-x+ 3) + torch.tanh(-y) + 2).abs(), LOWER).log() + 6\n    l2_sq = ((-x- 7).pow(2) + 0.1 * (-y - 8).pow(2)) / 10 - 20\n    c1 = torch.clamp(torch.tanh(y * 0.5), 0)\n    c2 = torch.clamp(torch.tanh(-y * 0.5), 0)\n    l1 = l1 * c1 + l1_sq * c2\n    l2 = l2 * c1 + l2_sq * c2\n    return l1,l2 \n</pre> import torch  LOWER = 0.000005 def landscape(x,y):     l1 = torch.clamp((0.5 * (-x - 7) - torch.tanh(-y)).abs(), LOWER).log() + 6     l1_sq = ((-x+ 7).pow(2) + 0.1 * (-y - 8).pow(2)) / 10 - 20     l2 = torch.clamp((0.5 * (-x+ 3) + torch.tanh(-y) + 2).abs(), LOWER).log() + 6     l2_sq = ((-x- 7).pow(2) + 0.1 * (-y - 8).pow(2)) / 10 - 20     c1 = torch.clamp(torch.tanh(y * 0.5), 0)     c2 = torch.clamp(torch.tanh(-y * 0.5), 0)     l1 = l1 * c1 + l1_sq * c2     l2 = l2 * c1 + l2_sq * c2     return l1,l2  <p>We can visualize the loss function below:</p> In\u00a0[2]: Copied! <pre>import matplotlib.pyplot as plt\n\nMARKERS=['o','s','^','x','*', 'D', 'v', '&lt;', '&gt;', 'p', 'h']\ndef plot_landscape(trajectories=None,\n                   field=\"all\",\n                   scale=[1,1],\n                   ax=None,\n                   c_bar=True):\n    x,y=torch.meshgrid(torch.linspace(-10,10,100),torch.linspace(-10,10,100))\n    l1,l2=landscape(x,y)\n    l1=l1*scale[0]\n    l2=l2*scale[1]\n    if field == \"l1\":\n        value = l1\n    elif field == \"l2\":\n        value = l2\n    elif field == \"all\":\n        value = l1+l2\n    if ax is None:\n        ax = plt.gca()\n    im=ax.imshow(value.T, extent=(-10, 10, -10, 10),origin='lower')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    if c_bar:\n        plt.colorbar(im,ax=ax)\n    if trajectories is not None:\n        for i,trajectory in enumerate(trajectories):\n            ax.scatter([t[0] for t in trajectory], [t[1] for t in trajectory],\n                       c=[i for i in range(len(trajectory))],cmap='autumn_r',marker=MARKERS[i])\n            ax.scatter([trajectory[0][0]], [trajectory[0][1]],\n                       c=\"black\",marker=MARKERS[i])\n    if ax is None:\n        plt.show()\n        \nfig,axs=plt.subplots(1,2,figsize=(10,5))\nplot_landscape(field=\"l1\",ax=axs[0])\naxs[0].scatter([7],[-8.43],marker='*',color='white',s=200)\nplot_landscape(field=\"l2\",ax=axs[1])\naxs[1].scatter([-7],[-8.43],marker='*',color='white',s=200)\nplt.show()\n</pre> import matplotlib.pyplot as plt  MARKERS=['o','s','^','x','*', 'D', 'v', '&lt;', '&gt;', 'p', 'h'] def plot_landscape(trajectories=None,                    field=\"all\",                    scale=[1,1],                    ax=None,                    c_bar=True):     x,y=torch.meshgrid(torch.linspace(-10,10,100),torch.linspace(-10,10,100))     l1,l2=landscape(x,y)     l1=l1*scale[0]     l2=l2*scale[1]     if field == \"l1\":         value = l1     elif field == \"l2\":         value = l2     elif field == \"all\":         value = l1+l2     if ax is None:         ax = plt.gca()     im=ax.imshow(value.T, extent=(-10, 10, -10, 10),origin='lower')     ax.set_xlabel('x')     ax.set_ylabel('y')     if c_bar:         plt.colorbar(im,ax=ax)     if trajectories is not None:         for i,trajectory in enumerate(trajectories):             ax.scatter([t[0] for t in trajectory], [t[1] for t in trajectory],                        c=[i for i in range(len(trajectory))],cmap='autumn_r',marker=MARKERS[i])             ax.scatter([trajectory[0][0]], [trajectory[0][1]],                        c=\"black\",marker=MARKERS[i])     if ax is None:         plt.show()          fig,axs=plt.subplots(1,2,figsize=(10,5)) plot_landscape(field=\"l1\",ax=axs[0]) axs[0].scatter([7],[-8.43],marker='*',color='white',s=200) plot_landscape(field=\"l2\",ax=axs[1]) axs[1].scatter([-7],[-8.43],marker='*',color='white',s=200) plt.show() <pre>/home/liu/anaconda3/envs/deeplearning/lib/python3.10/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n</pre> <p>The two loss landscapes are mirror images of each other. The minimum point of two loss function are $(7,-8.43)$ and $(-7,-8.43)$ respectively. To further increase the challenge to the optimization, we will rescale <code>l1</code> with 0.1. Then, the optimization becomes unbalanced where the gradient of <code>l1</code> is much smaller than <code>l2</code>. The final loss landscape looks like this:</p> In\u00a0[3]: Copied! <pre>inits = [\n    torch.Tensor([-8.5, 7.5]),\n    torch.Tensor([0.0, 0.0]),\n    torch.Tensor([9.0, 9.0]),\n    torch.Tensor([-7.5, -0.5]),\n    torch.Tensor([9, -1.0]),\n]\n\nplot_landscape(field=\"all\",trajectories=[[point] for point in inits],scale=[0.1,1])\n</pre> inits = [     torch.Tensor([-8.5, 7.5]),     torch.Tensor([0.0, 0.0]),     torch.Tensor([9.0, 9.0]),     torch.Tensor([-7.5, -0.5]),     torch.Tensor([9, -1.0]), ]  plot_landscape(field=\"all\",trajectories=[[point] for point in inits],scale=[0.1,1]) <p>The five <code>init</code> points represent the five initial points for our optimization.</p> <p>In MTL, the final target is not to reach a point with minimal total loss but to reach the Pareto_frontier. The Pareto frontier is the set of all Pareto efficient points. A point is Pareto efficient if there is no other point that is better in all objectives. In our case, this means the point where any attempt to decrease one loss will increase the other loss. We can easily visualize the Pareto frontier in the loss landscape by plotting the losses at each point in a 2D plane:</p> In\u00a0[4]: Copied! <pre>plt.figure(figsize=(5,5))\nx,y=torch.meshgrid(torch.linspace(-10,10,100),torch.linspace(-10,10,100))\nl1,l2=landscape(x,y)\nl1=0.1*l1\nplt.scatter(l1.view(-1),l2.view(-1),c=(l1+l2).view(-1),cmap='rainbow')\n\nx=torch.linspace(10,-10,100)\ny=torch.ones(100)*-8.43\nl1,l2=landscape(x,y)\nplt.plot(0.1*l1,l2,c=\"Gray\",linewidth=10,label=\"Pareto frontier\")\n\nfor i,init in enumerate(inits):\n    l1,l2=landscape(init[0],init[1])\n    plt.scatter(0.1*l1,l2,marker=MARKERS[i],c=\"black\")\n    \n\nplt.xlabel(\"l1\")\nplt.ylabel(\"l2\")\nplt.legend()\nplt.show()\n</pre> plt.figure(figsize=(5,5)) x,y=torch.meshgrid(torch.linspace(-10,10,100),torch.linspace(-10,10,100)) l1,l2=landscape(x,y) l1=0.1*l1 plt.scatter(l1.view(-1),l2.view(-1),c=(l1+l2).view(-1),cmap='rainbow')  x=torch.linspace(10,-10,100) y=torch.ones(100)*-8.43 l1,l2=landscape(x,y) plt.plot(0.1*l1,l2,c=\"Gray\",linewidth=10,label=\"Pareto frontier\")  for i,init in enumerate(inits):     l1,l2=landscape(init[0],init[1])     plt.scatter(0.1*l1,l2,marker=MARKERS[i],c=\"black\")       plt.xlabel(\"l1\") plt.ylabel(\"l2\") plt.legend() plt.show() <p>Now, lets first use the 'Adam' optimizer to solve this problem:</p> In\u00a0[5]: Copied! <pre>def plot_pareto_front(loss_trajectories=None,ax=None,scale=[1,1]):\n    x=torch.linspace(10,-10,100)\n    y=torch.ones(100)*-8.43\n    l1,l2=landscape(x,y)\n    if ax is None:\n        fig=plt.figure(figsize=(5,5))\n        ax = plt.gca()\n    ax.plot(scale[0]*l1,scale[1]*l2,c=\"Gray\",linewidth=5)\n    if loss_trajectories is not None:\n        for i,trajectory in enumerate(loss_trajectories):\n            ax.scatter([t[0] for t in trajectory], [t[1] for t in trajectory],\n                       c=[i for i in range(len(trajectory))],cmap='autumn_r',marker=MARKERS[i])\n            ax.scatter([trajectory[0][0]], [trajectory[0][1]],\n                       c=\"black\",marker=MARKERS[i])\n    if ax is None:\n        plt.show()\n\nfrom tqdm import tqdm\nscale=[0.1,1]\ntrajectories = [];losses = []\nfor init in inits:\n    trajectory_i = []\n    loss_i= []\n    x = init[0].clone().requires_grad_(True)\n    y = init[1].clone().requires_grad_(True)\n    optimizer = torch.optim.Adam([x,y], lr=1e-3)\n    for i in tqdm(range(50000)):\n        optimizer.zero_grad()\n        l1,l2 = landscape(x,y)\n        loss = scale[0]*l1 + scale[1]*l2\n        trajectory_i.append((x.item(),y.item()))\n        loss_i.append((scale[0]*l1.item(),scale[1]*l2.item()))\n        loss.backward()\n        optimizer.step()\n    trajectories.append(trajectory_i)\n    losses.append(loss_i)\n  \nfig,axs=plt.subplots(1,2,figsize=(10,5))\nplot_landscape(field=\"all\",trajectories=trajectories,scale=scale,ax=axs[0],c_bar=False)\nplot_pareto_front(losses,scale=scale,ax=axs[1])  \nplt.show()\n</pre> def plot_pareto_front(loss_trajectories=None,ax=None,scale=[1,1]):     x=torch.linspace(10,-10,100)     y=torch.ones(100)*-8.43     l1,l2=landscape(x,y)     if ax is None:         fig=plt.figure(figsize=(5,5))         ax = plt.gca()     ax.plot(scale[0]*l1,scale[1]*l2,c=\"Gray\",linewidth=5)     if loss_trajectories is not None:         for i,trajectory in enumerate(loss_trajectories):             ax.scatter([t[0] for t in trajectory], [t[1] for t in trajectory],                        c=[i for i in range(len(trajectory))],cmap='autumn_r',marker=MARKERS[i])             ax.scatter([trajectory[0][0]], [trajectory[0][1]],                        c=\"black\",marker=MARKERS[i])     if ax is None:         plt.show()  from tqdm import tqdm scale=[0.1,1] trajectories = [];losses = [] for init in inits:     trajectory_i = []     loss_i= []     x = init[0].clone().requires_grad_(True)     y = init[1].clone().requires_grad_(True)     optimizer = torch.optim.Adam([x,y], lr=1e-3)     for i in tqdm(range(50000)):         optimizer.zero_grad()         l1,l2 = landscape(x,y)         loss = scale[0]*l1 + scale[1]*l2         trajectory_i.append((x.item(),y.item()))         loss_i.append((scale[0]*l1.item(),scale[1]*l2.item()))         loss.backward()         optimizer.step()     trajectories.append(trajectory_i)     losses.append(loss_i)    fig,axs=plt.subplots(1,2,figsize=(10,5)) plot_landscape(field=\"all\",trajectories=trajectories,scale=scale,ax=axs[0],c_bar=False) plot_pareto_front(losses,scale=scale,ax=axs[1])   plt.show() <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50000/50000 [00:45&lt;00:00, 1098.59it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50000/50000 [00:45&lt;00:00, 1101.00it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50000/50000 [00:45&lt;00:00, 1096.47it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50000/50000 [00:45&lt;00:00, 1098.83it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50000/50000 [00:45&lt;00:00, 1109.46it/s]\n</pre> <p>The color in the optimization strategy represents the index of the optimization step, where yellow is the start of the optimization and red represents the end. For the Adam optimizer, the optimization starts with initial points of $\\bullet $, $\\Box$, $\\star$, and $\\times$ converges to the Pareto frontier while the trajectory starts with $\\bigtriangleup$ is stuck in a local minimum of l2. This is because the gradient of l1 is much smaller than l2, so the optimization is biased towards l2. This can also be seen from the trajectories of other points. The optimization with the initial point of $\\star$ first goes to the minimum of l2 and then moves to the Pareto frontier. Also, other optimization trajectories are biased towards points on the Pareto frontier where l2 is smaller.</p> <p>Now, let's try on our ConFIG method:</p> In\u00a0[6]: Copied! <pre>from tqdm import tqdm\nfrom conflictfree.grad_operator import ConFIG_update\nscale=[0.1,1]\ntrajectories = [];losses = []\nfor init in inits:\n    trajectory_i = []\n    loss_i= []\n    x = init[0].clone().requires_grad_(True)\n    y = init[1].clone().requires_grad_(True)\n    optimizer = torch.optim.Adam([x,y], lr=1e-3)\n    for i in tqdm(range(50000)):\n        optimizer.zero_grad()\n        l1,l2 = landscape(x,y)\n        trajectory_i.append((x.item(),y.item()))\n        loss_i.append((scale[0]*l1.item(),scale[1]*l2.item()))\n        \n        (scale[0]*l1).backward(retain_graph=True)\n        grad_1 = torch.cat([x.grad.view(-1),y.grad.view(-1)])\n        x.grad.data.zero_()\n        y.grad.data.zero_()\n        (scale[1]*l2).backward()\n        grad_2 = torch.cat([x.grad.view(-1),y.grad.view(-1)])\n        x.grad.data.zero_()\n        y.grad.data.zero_()\n        g_config=ConFIG_update([grad_1,grad_2])\n        x.grad.data = g_config[0].view_as(x)\n        y.grad.data = g_config[1].view_as(y)\n        \n        optimizer.step()\n    trajectories.append(trajectory_i)\n    losses.append(loss_i)\n    \nfig,axs=plt.subplots(1,2,figsize=(10,5))\nplot_landscape(field=\"all\",trajectories=trajectories,scale=scale,ax=axs[0],c_bar=False)\nplot_pareto_front(losses,scale=scale,ax=axs[1])  \n</pre> from tqdm import tqdm from conflictfree.grad_operator import ConFIG_update scale=[0.1,1] trajectories = [];losses = [] for init in inits:     trajectory_i = []     loss_i= []     x = init[0].clone().requires_grad_(True)     y = init[1].clone().requires_grad_(True)     optimizer = torch.optim.Adam([x,y], lr=1e-3)     for i in tqdm(range(50000)):         optimizer.zero_grad()         l1,l2 = landscape(x,y)         trajectory_i.append((x.item(),y.item()))         loss_i.append((scale[0]*l1.item(),scale[1]*l2.item()))                  (scale[0]*l1).backward(retain_graph=True)         grad_1 = torch.cat([x.grad.view(-1),y.grad.view(-1)])         x.grad.data.zero_()         y.grad.data.zero_()         (scale[1]*l2).backward()         grad_2 = torch.cat([x.grad.view(-1),y.grad.view(-1)])         x.grad.data.zero_()         y.grad.data.zero_()         g_config=ConFIG_update([grad_1,grad_2])         x.grad.data = g_config[0].view_as(x)         y.grad.data = g_config[1].view_as(y)                  optimizer.step()     trajectories.append(trajectory_i)     losses.append(loss_i)      fig,axs=plt.subplots(1,2,figsize=(10,5)) plot_landscape(field=\"all\",trajectories=trajectories,scale=scale,ax=axs[0],c_bar=False) plot_pareto_front(losses,scale=scale,ax=axs[1])   <pre>  0%|          | 81/50000 [00:00&lt;01:01, 809.25it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50000/50000 [01:01&lt;00:00, 808.85it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50000/50000 [01:01&lt;00:00, 812.84it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50000/50000 [01:01&lt;00:00, 815.12it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50000/50000 [01:01&lt;00:00, 807.84it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50000/50000 [01:01&lt;00:00, 812.18it/s]\n</pre> <p>All the optimization trajectories here converge to the Pareto frontier. This is because ConFIG tries to find a conflict-free gradient direction for each task. This not only makes the trajectory  $\\bigtriangleup$ jump out of the local minimum of l2 but also makes the optimization trajectory of $\\star$ converge to the Pareto frontier more directly.</p> <p>Now, lets try the momentum version of ConFIG:</p> In\u00a0[7]: Copied! <pre>from tqdm import tqdm\nfrom conflictfree.momentum_operator import PseudoMomentumOperator\n\nscale=[0.1,1]\ntrajectories = [];losses = []\nmomentum_operator = PseudoMomentumOperator(num_vectors=2)\nfor init in inits:\n    trajectory_i = []\n    loss_i= []\n    x = init[0].clone().requires_grad_(True)\n    y = init[1].clone().requires_grad_(True)\n    optimizer = torch.optim.SGD([x,y], lr=1e-3)\n    for i in tqdm(range(60000)):\n        optimizer.zero_grad()\n        l1,l2 = landscape(x,y)\n        trajectory_i.append((x.item(),y.item()))\n        loss_i.append((scale[0]*l1.item(),scale[1]*l2.item()))\n        \n        if i%2==0:\n            (scale[0]*l1).backward()\n            grad_1 = torch.cat([x.grad.view(-1),y.grad.view(-1)])\n            g_config=momentum_operator.calculate_gradient(0,grad_1)\n        else:\n            (scale[1]*l2).backward()\n            grad_2 = torch.cat([x.grad.view(-1),y.grad.view(-1)])\n            g_config=momentum_operator.calculate_gradient(1,grad_2)\n        x.grad.data = g_config[0].view_as(x)\n        y.grad.data = g_config[1].view_as(y)\n        \n        optimizer.step()\n    trajectories.append(trajectory_i)\n    losses.append(loss_i)\n    \nfig,axs=plt.subplots(1,2,figsize=(10,5))\nplot_landscape(field=\"all\",trajectories=trajectories,scale=scale,ax=axs[0],c_bar=False)\nplot_pareto_front(losses,scale=scale,ax=axs[1])  \n</pre> from tqdm import tqdm from conflictfree.momentum_operator import PseudoMomentumOperator  scale=[0.1,1] trajectories = [];losses = [] momentum_operator = PseudoMomentumOperator(num_vectors=2) for init in inits:     trajectory_i = []     loss_i= []     x = init[0].clone().requires_grad_(True)     y = init[1].clone().requires_grad_(True)     optimizer = torch.optim.SGD([x,y], lr=1e-3)     for i in tqdm(range(60000)):         optimizer.zero_grad()         l1,l2 = landscape(x,y)         trajectory_i.append((x.item(),y.item()))         loss_i.append((scale[0]*l1.item(),scale[1]*l2.item()))                  if i%2==0:             (scale[0]*l1).backward()             grad_1 = torch.cat([x.grad.view(-1),y.grad.view(-1)])             g_config=momentum_operator.calculate_gradient(0,grad_1)         else:             (scale[1]*l2).backward()             grad_2 = torch.cat([x.grad.view(-1),y.grad.view(-1)])             g_config=momentum_operator.calculate_gradient(1,grad_2)         x.grad.data = g_config[0].view_as(x)         y.grad.data = g_config[1].view_as(y)                  optimizer.step()     trajectories.append(trajectory_i)     losses.append(loss_i)      fig,axs=plt.subplots(1,2,figsize=(10,5)) plot_landscape(field=\"all\",trajectories=trajectories,scale=scale,ax=axs[0],c_bar=False) plot_pareto_front(losses,scale=scale,ax=axs[1])   <pre>  0%|          | 96/60000 [00:00&lt;01:02, 959.81it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 60000/60000 [01:04&lt;00:00, 937.02it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 60000/60000 [01:03&lt;00:00, 942.73it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 60000/60000 [01:03&lt;00:00, 941.23it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 60000/60000 [01:03&lt;00:00, 940.80it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 60000/60000 [01:03&lt;00:00, 942.65it/s]\n</pre> <p>The results are similar to ConFIG, but it needs more iterations to converge. You may notice that we give an additional 1000 optimization iterations for the momentum version. This is because we only update a single gradient direction every iteration, so it usually requires more iterations to get a similar or better performance than the ConFIG method. You can have a try by yourself to see the optimization trajectory. The acceleration of the momentum version is not so significant in this case since the backpropagation of gradients is not the main bottleneck of the optimization.</p> <p>Click here to have a check in the MTL experiment in our research paper.</p>"},{"location":"examples/mtl_toy/#toy-example-of-muti-task-learning","title":"Toy Example of Muti-task Learning\u00b6","text":"<p>Here, we would like to show a classic and interesting toy example of multi-task learning (MTL).</p> <p></p> <p>In this example, there are two tasks represented by two loss functions, which are</p>"},{"location":"examples/pinn_burgers/","title":"2.2. Solve Burgers' Equation with PINN","text":"In\u00a0[1]: Copied! <pre>import torch\nfrom typing import Callable,Union\nimport numpy as np\nfrom scipy.stats.qmc import LatinHypercube\n\nclass BurgersDataset():\n    \n    def __init__(self,\n                 x_start:float=-1.0,x_end:float=1.0,ini_boundary:Callable=lambda x: -1*torch.sin(np.pi*x),simulation_time:float=1.0,\n                 n_pde:int=2000,n_initial:int=50,n_boundary:int=50,device:Union[str,torch.device]=\"cpu\",\n                 nu=0.01/np.pi,\n                 seed:int=21339,) -&gt; None:\n        self.ini_boundary=ini_boundary\n        self.x_start=x_start\n        self.x_end=x_end\n        self.n_pde=n_pde\n        self.n_boundary=n_boundary\n        self.n_initial=n_initial\n        self.nu=nu\n        self.simulation_time=simulation_time\n        self.device=device\n        self.random_engine_initial_boundary=LatinHypercube(d=1,seed=seed)\n        self.random_engine_pde=LatinHypercube(d=2,seed=seed)\n    \n    def sample_initial(self):\n        with torch.no_grad():\n            x_initial = torch.tensor(self.random_engine_initial_boundary.random(n=self.n_initial)[:,0],device=self.device,dtype=torch.float32)*(self.x_end-self.x_start)+self.x_start\n            t_initial = torch.zeros_like(x_initial)\n            value_initial = self.ini_boundary(x_initial)\n            return (x_initial,t_initial,value_initial)\n    \n    def sample_boundary(self):\n        with torch.no_grad():\n            x_boundary = torch.cat([self.x_start*torch.ones(self.n_boundary//2,device=self.device),self.x_end*torch.ones(self.n_boundary//2,device=self.device)])\n            t_boundary = torch.tensor(self.random_engine_initial_boundary.random(n=self.n_boundary)[:,0],device=self.device,dtype=torch.float32)\n            value_boundary = torch.zeros_like(t_boundary,device=self.device)\n            return (x_boundary,t_boundary,value_boundary)\n    \n    def sample_pde(self):\n        sample = self.random_engine_pde.random(n=self.n_pde)\n        x=torch.tensor(sample[:,0],device=self.device,dtype=torch.float32)*(self.x_end-self.x_start)+self.x_start\n        x.requires_grad=True\n        t=torch.tensor(sample[:,1],device=self.device,dtype=torch.float32)*self.simulation_time\n        t.requires_grad=True\n        return (x,t,self.nu)\n</pre> import torch from typing import Callable,Union import numpy as np from scipy.stats.qmc import LatinHypercube  class BurgersDataset():          def __init__(self,                  x_start:float=-1.0,x_end:float=1.0,ini_boundary:Callable=lambda x: -1*torch.sin(np.pi*x),simulation_time:float=1.0,                  n_pde:int=2000,n_initial:int=50,n_boundary:int=50,device:Union[str,torch.device]=\"cpu\",                  nu=0.01/np.pi,                  seed:int=21339,) -&gt; None:         self.ini_boundary=ini_boundary         self.x_start=x_start         self.x_end=x_end         self.n_pde=n_pde         self.n_boundary=n_boundary         self.n_initial=n_initial         self.nu=nu         self.simulation_time=simulation_time         self.device=device         self.random_engine_initial_boundary=LatinHypercube(d=1,seed=seed)         self.random_engine_pde=LatinHypercube(d=2,seed=seed)          def sample_initial(self):         with torch.no_grad():             x_initial = torch.tensor(self.random_engine_initial_boundary.random(n=self.n_initial)[:,0],device=self.device,dtype=torch.float32)*(self.x_end-self.x_start)+self.x_start             t_initial = torch.zeros_like(x_initial)             value_initial = self.ini_boundary(x_initial)             return (x_initial,t_initial,value_initial)          def sample_boundary(self):         with torch.no_grad():             x_boundary = torch.cat([self.x_start*torch.ones(self.n_boundary//2,device=self.device),self.x_end*torch.ones(self.n_boundary//2,device=self.device)])             t_boundary = torch.tensor(self.random_engine_initial_boundary.random(n=self.n_boundary)[:,0],device=self.device,dtype=torch.float32)             value_boundary = torch.zeros_like(t_boundary,device=self.device)             return (x_boundary,t_boundary,value_boundary)          def sample_pde(self):         sample = self.random_engine_pde.random(n=self.n_pde)         x=torch.tensor(sample[:,0],device=self.device,dtype=torch.float32)*(self.x_end-self.x_start)+self.x_start         x.requires_grad=True         t=torch.tensor(sample[:,1],device=self.device,dtype=torch.float32)*self.simulation_time         t.requires_grad=True         return (x,t,self.nu) <p>Then, we can define a neural network with a simple MLP architecture:</p> In\u00a0[2]: Copied! <pre>import torch.nn as nn\n\nclass BurgersNet(nn.Module):\n    \n    def __init__(self,channel_basics=50,n_layers=4, *args, **kwargs) -&gt; None:\n        super().__init__(*args, **kwargs)\n        self.ini_net=nn.Sequential(nn.Linear(2, channel_basics), nn.Tanh())\n        self.net=[]\n        for i in range(n_layers):\n            self.net.append(nn.Sequential(nn.Linear(channel_basics, channel_basics), nn.Tanh()))\n        self.net=nn.Sequential(*self.net)\n        self.out_net=nn.Linear(channel_basics, 1)\n        \n    \n    def forward(self, x, t):\n        ini_shape=x.shape\n        y = torch.stack([x.view(-1), t.view(-1)], dim=-1)        \n        y = torch.stack([x, t], dim=-1)\n        y = self.ini_net(y)\n        y = self.net(y)\n        y = self.out_net(y)\n        return y.view(ini_shape)\n</pre> import torch.nn as nn  class BurgersNet(nn.Module):          def __init__(self,channel_basics=50,n_layers=4, *args, **kwargs) -&gt; None:         super().__init__(*args, **kwargs)         self.ini_net=nn.Sequential(nn.Linear(2, channel_basics), nn.Tanh())         self.net=[]         for i in range(n_layers):             self.net.append(nn.Sequential(nn.Linear(channel_basics, channel_basics), nn.Tanh()))         self.net=nn.Sequential(*self.net)         self.out_net=nn.Linear(channel_basics, 1)                   def forward(self, x, t):         ini_shape=x.shape         y = torch.stack([x.view(-1), t.view(-1)], dim=-1)                 y = torch.stack([x, t], dim=-1)         y = self.ini_net(y)         y = self.net(y)         y = self.out_net(y)         return y.view(ini_shape) <p>We can also a initialization function for the weights and biases. Here we use the Xavier initialization, which is a common initialization method for training PINNs:</p> In\u00a0[3]: Copied! <pre>def xavier_init_weights(m):\n    if type(m) == nn.Linear:\n        torch.nn.init.xavier_normal_(m.weight, 1)\n        m.bias.data.fill_(0.001)\n</pre> def xavier_init_weights(m):     if type(m) == nn.Linear:         torch.nn.init.xavier_normal_(m.weight, 1)         m.bias.data.fill_(0.001) <p>Then, lets define the loss functions where we can calculate the loss for the initial/boundary conditions and the PDE separately:</p> In\u00a0[4]: Copied! <pre>class BurgersLoss(nn.Module):\n\n    def _derivative(self, y: torch.Tensor, x: torch.Tensor, order: int = 1) -&gt; torch.Tensor:\n        for i in range(order):\n            y = torch.autograd.grad(\n                y, x, grad_outputs = torch.ones_like(y), create_graph=True, retain_graph=True\n            )[0]\n        return y\n\n    def pde_loss(self,network,inputs):\n        x,t,nu = inputs\n        u=network(x,t)\n        x.grad=None\n        t.grad=None\n        \"\"\" Physics-based loss function with Burgers equation \"\"\"\n        u_t = self._derivative(u, t, order=1)\n        u_x = self._derivative(u, x, order=1)\n        u_xx = self._derivative(u_x, x, order=1)\n        return (u_t + u*u_x - nu * u_xx).pow(2).mean()\n    \n    def boundary_loss(self,network,inputs): \n        x_b,t_b,value_b=inputs\n        boundary_loss=torch.mean((network(x_b,t_b)-value_b)**2)\n        return boundary_loss\n    \n    def initial_loss(self,network,inputs):      \n        x_i,t_i,value_i= inputs\n        initial_loss=torch.mean((network(x_i,t_i)-value_i)**2)\n        return initial_loss\n</pre>  class BurgersLoss(nn.Module):      def _derivative(self, y: torch.Tensor, x: torch.Tensor, order: int = 1) -&gt; torch.Tensor:         for i in range(order):             y = torch.autograd.grad(                 y, x, grad_outputs = torch.ones_like(y), create_graph=True, retain_graph=True             )[0]         return y      def pde_loss(self,network,inputs):         x,t,nu = inputs         u=network(x,t)         x.grad=None         t.grad=None         \"\"\" Physics-based loss function with Burgers equation \"\"\"         u_t = self._derivative(u, t, order=1)         u_x = self._derivative(u, x, order=1)         u_xx = self._derivative(u_x, x, order=1)         return (u_t + u*u_x - nu * u_xx).pow(2).mean()          def boundary_loss(self,network,inputs):          x_b,t_b,value_b=inputs         boundary_loss=torch.mean((network(x_b,t_b)-value_b)**2)         return boundary_loss          def initial_loss(self,network,inputs):               x_i,t_i,value_i= inputs         initial_loss=torch.mean((network(x_i,t_i)-value_i)**2)         return initial_loss  <p>Finally, we can define a tester class to record the best performance of the model during the training process:</p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nfrom conflictfree.utils import get_para_vector,apply_para_vector\n\nclass Tester():\n    \n    def __init__(self,\n                 data_path=\"../../experiments/PINN/data/burgers/simulation_data.npy\") -&gt; None:\n        self.simulation_data=torch.from_numpy(np.load(data_path)).to(dtype=torch.float32)\n        self.x=torch.linspace(-1.0+1/256,1.0-1/256,256).unsqueeze(0).repeat(self.simulation_data.shape[0],1)\n        self.t=torch.linspace(0,1.0,100).unsqueeze(1).repeat(1,self.simulation_data.shape[1])\n        self.best_weight=None\n        self.best_mse=100\n    \n    def _get_se(self,network):\n        with torch.no_grad():\n            device=network.parameters().__next__().device\n            self.x=self.x.to(device)\n            self.t=self.t.to(device)\n            self.simulation_data=self.simulation_data.to(device)\n            prediction=network(self.x,self.t)\n            return (prediction-self.simulation_data).pow(2),prediction\n    \n    def test(self,network):\n        with torch.no_grad():\n            mse=self._get_se(network)[0].mean().item()\n            if mse &lt; self.best_mse:\n                self.best_mse=mse\n                self.best_weight=get_para_vector(network)\n            return mse\n    \n    def plot_best(self,network):\n        apply_para_vector(network,self.best_weight)\n        se,prediction=self._get_se(network)\n        fig,ax=plt.subplots(1,3,figsize=(10,5))\n        ax[0].imshow(self.simulation_data.cpu().detach().numpy().T)\n        ax[0].set_title(\"simulation data\")\n        ax[1].imshow(prediction.cpu().detach().numpy().T)\n        ax[1].set_title(\"prediction\")\n        im=ax[2].imshow(se.cpu().detach().numpy().T)\n        ax[2].set_title(\"squared error\")\n        plt.colorbar(im,ax=ax)\n        plt.show()\n        print(f\"best mse: {self.best_mse}\")\n</pre> import matplotlib.pyplot as plt from conflictfree.utils import get_para_vector,apply_para_vector  class Tester():          def __init__(self,                  data_path=\"../../experiments/PINN/data/burgers/simulation_data.npy\") -&gt; None:         self.simulation_data=torch.from_numpy(np.load(data_path)).to(dtype=torch.float32)         self.x=torch.linspace(-1.0+1/256,1.0-1/256,256).unsqueeze(0).repeat(self.simulation_data.shape[0],1)         self.t=torch.linspace(0,1.0,100).unsqueeze(1).repeat(1,self.simulation_data.shape[1])         self.best_weight=None         self.best_mse=100          def _get_se(self,network):         with torch.no_grad():             device=network.parameters().__next__().device             self.x=self.x.to(device)             self.t=self.t.to(device)             self.simulation_data=self.simulation_data.to(device)             prediction=network(self.x,self.t)             return (prediction-self.simulation_data).pow(2),prediction          def test(self,network):         with torch.no_grad():             mse=self._get_se(network)[0].mean().item()             if mse &lt; self.best_mse:                 self.best_mse=mse                 self.best_weight=get_para_vector(network)             return mse          def plot_best(self,network):         apply_para_vector(network,self.best_weight)         se,prediction=self._get_se(network)         fig,ax=plt.subplots(1,3,figsize=(10,5))         ax[0].imshow(self.simulation_data.cpu().detach().numpy().T)         ax[0].set_title(\"simulation data\")         ax[1].imshow(prediction.cpu().detach().numpy().T)         ax[1].set_title(\"prediction\")         im=ax[2].imshow(se.cpu().detach().numpy().T)         ax[2].set_title(\"squared error\")         plt.colorbar(im,ax=ax)         plt.show()         print(f\"best mse: {self.best_mse}\") <p>Now, let's train the network! we can first try with the classic Adam optimizer:</p> In\u00a0[6]: Copied! <pre>from torch.optim import Adam,SGD\nfrom tqdm import tqdm\n\nseed=19018\ndevice=\"cuda:0\"\n\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nnet = BurgersNet()\nnet.apply(xavier_init_weights)\nnet.to(device)\noptimizer=Adam(net.parameters(),lr=1e-4)\ndataset=BurgersDataset(device=device,seed=seed)\nloss=BurgersLoss()\ntester=Tester()\n\np_bar=tqdm(range(5000))   \nfor i in p_bar:\n    optimizer.zero_grad()\n    loss_i=loss.initial_loss(net,dataset.sample_initial())\n    loss_b=loss.boundary_loss(net,dataset.sample_boundary())\n    loss_pde=loss.pde_loss(net,dataset.sample_pde())\n    loss_total=loss_i+loss_b+loss_pde\n    loss_total.backward()\n    optimizer.step()\n    p_bar.set_postfix({\"current_mse\":tester.test(net),\"best_mse\":tester.best_mse})\ntester.plot_best(net)\n</pre> from torch.optim import Adam,SGD from tqdm import tqdm  seed=19018 device=\"cuda:0\"  torch.manual_seed(seed) np.random.seed(seed) net = BurgersNet() net.apply(xavier_init_weights) net.to(device) optimizer=Adam(net.parameters(),lr=1e-4) dataset=BurgersDataset(device=device,seed=seed) loss=BurgersLoss() tester=Tester()  p_bar=tqdm(range(5000))    for i in p_bar:     optimizer.zero_grad()     loss_i=loss.initial_loss(net,dataset.sample_initial())     loss_b=loss.boundary_loss(net,dataset.sample_boundary())     loss_pde=loss.pde_loss(net,dataset.sample_pde())     loss_total=loss_i+loss_b+loss_pde     loss_total.backward()     optimizer.step()     p_bar.set_postfix({\"current_mse\":tester.test(net),\"best_mse\":tester.best_mse}) tester.plot_best(net) <pre>  0%|          | 0/5000 [00:00&lt;?, ?it/s]/home/liu/anaconda3/envs/deeplearning/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:40&lt;00:00, 123.87it/s, current_mse=0.0319, best_mse=0.031] \n</pre> <pre>best mse: 0.03095494769513607\n</pre> <p>Then, let's try to train the network with our ConFIG method:</p> In\u00a0[7]: Copied! <pre>from conflictfree.grad_operator import ConFIG_update\nfrom conflictfree.utils import get_gradient_vector,apply_gradient_vector\n\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nnet = BurgersNet()\nnet.apply(xavier_init_weights)\nnet.to(device)\noptimizer=Adam(net.parameters(),lr=1e-4)\ndataset=BurgersDataset(device=device,seed=seed)\nloss=BurgersLoss()\ntester=Tester()\n\np_bar=tqdm(range(5000))   \nfor i in p_bar:\n    grads=[]\n    losses=[]\n    for input_fn,loss_fn in zip([dataset.sample_initial,dataset.sample_boundary,dataset.sample_pde],\n                                [loss.initial_loss,loss.boundary_loss,loss.pde_loss]):\n        optimizer.zero_grad()\n        loss_i=loss_fn(net,input_fn())\n        loss_i.backward()\n        grads.append(get_gradient_vector(net))\n        losses.append(loss_i.item())\n    apply_gradient_vector(net,ConFIG_update(grads))\n    optimizer.step()\n    p_bar.set_postfix({\"current_mse\":tester.test(net),\"best_mse\":tester.best_mse})\ntester.plot_best(net)\n</pre> from conflictfree.grad_operator import ConFIG_update from conflictfree.utils import get_gradient_vector,apply_gradient_vector  torch.manual_seed(seed) np.random.seed(seed) net = BurgersNet() net.apply(xavier_init_weights) net.to(device) optimizer=Adam(net.parameters(),lr=1e-4) dataset=BurgersDataset(device=device,seed=seed) loss=BurgersLoss() tester=Tester()  p_bar=tqdm(range(5000))    for i in p_bar:     grads=[]     losses=[]     for input_fn,loss_fn in zip([dataset.sample_initial,dataset.sample_boundary,dataset.sample_pde],                                 [loss.initial_loss,loss.boundary_loss,loss.pde_loss]):         optimizer.zero_grad()         loss_i=loss_fn(net,input_fn())         loss_i.backward()         grads.append(get_gradient_vector(net))         losses.append(loss_i.item())     apply_gradient_vector(net,ConFIG_update(grads))     optimizer.step()     p_bar.set_postfix({\"current_mse\":tester.test(net),\"best_mse\":tester.best_mse}) tester.plot_best(net) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:50&lt;00:00, 98.34it/s, current_mse=0.00665, best_mse=0.00638] \n</pre> <pre>best mse: 0.006381959654390812\n</pre> <p>As the results show, the ConFIG method can significantly improve the training accuracy of the PINN model. Now, lets try the momentum version of the ConFIG method:</p> In\u00a0[8]: Copied! <pre>from conflictfree.utils import OrderedSliceSelector\nfrom conflictfree.momentum_operator import PseudoMomentumOperator\n\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nnet = BurgersNet()\nnet.apply(xavier_init_weights)\nnet.to(device)\noptimizer=SGD(net.parameters(),lr=5e-4)\ndataset=BurgersDataset(device=device,seed=seed)\nloss=BurgersLoss()\ntester=Tester()\n\nmomentum_operator=PseudoMomentumOperator(num_vectors=3)\nloss_selector=OrderedSliceSelector()\ninput_loss_fns=[(input_fn,loss_fn) for input_fn,loss_fn in zip(\n    [dataset.sample_initial,dataset.sample_boundary,dataset.sample_pde],\n    [loss.initial_loss,loss.boundary_loss,loss.pde_loss])]\n\np_bar=tqdm(range(5000))   \nfor i in p_bar:\n    index,input_loss_fn=loss_selector.select(1,input_loss_fns)\n    optimizer.zero_grad()\n    loss=input_loss_fn[1](net,input_loss_fn[0]())\n    loss.backward()    \n    momentum_operator.update_gradient(net,index,grads=get_gradient_vector(net))\n    optimizer.step()\n    p_bar.set_postfix({\"current_mse\":tester.test(net),\"best_mse\":tester.best_mse})\ntester.plot_best(net)\n</pre> from conflictfree.utils import OrderedSliceSelector from conflictfree.momentum_operator import PseudoMomentumOperator  torch.manual_seed(seed) np.random.seed(seed) net = BurgersNet() net.apply(xavier_init_weights) net.to(device) optimizer=SGD(net.parameters(),lr=5e-4) dataset=BurgersDataset(device=device,seed=seed) loss=BurgersLoss() tester=Tester()  momentum_operator=PseudoMomentumOperator(num_vectors=3) loss_selector=OrderedSliceSelector() input_loss_fns=[(input_fn,loss_fn) for input_fn,loss_fn in zip(     [dataset.sample_initial,dataset.sample_boundary,dataset.sample_pde],     [loss.initial_loss,loss.boundary_loss,loss.pde_loss])]  p_bar=tqdm(range(5000))    for i in p_bar:     index,input_loss_fn=loss_selector.select(1,input_loss_fns)     optimizer.zero_grad()     loss=input_loss_fn[1](net,input_loss_fn[0]())     loss.backward()         momentum_operator.update_gradient(net,index,grads=get_gradient_vector(net))     optimizer.step()     p_bar.set_postfix({\"current_mse\":tester.test(net),\"best_mse\":tester.best_mse}) tester.plot_best(net) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:24&lt;00:00, 202.58it/s, current_mse=0.00187, best_mse=0.00186]\n</pre> <pre>best mse: 0.0018616181332617998\n</pre> <p>As the result shows, both the training speed and test accuracy are improved by using the momentum version of the ConFIG method. Please note that the momentum version does not always guarantee a better performance than the non-momentum version. The main feature of the momentum version is the acceleration, as it only requires a single gradient update in each iteration. We usually will just give the momentum version more training epochs to improve the performance further.</p> <p>Click here to have a check in the PINN experiment in our research paper.</p>"},{"location":"examples/pinn_burgers/#solve-burgers-equation-with-pinn","title":"Solve Burgers' Equation with PINN\u00b6","text":"<p>In this example, we would like to show you another example of how to use ConFIG method to train a physics informed neural network (PINN) for solving a PDE.</p> <p></p> <p>In this example, we will solve the 1D Burgers' equation:</p> <p>$$     \\frac{\\partial u}{\\partial t}+u \\frac{\\partial u}{\\partial x}=\\nu \\frac{\\partial^{2} u}{\\partial x^{2}} $$</p> <p>where $\\nu$ is the viscosity and set as $\\nu=0.01/\\pi$ in the current study. The spatial-temporal domain is $t \\in [0,1]$ and $x \\in [-1.0,1.0]$ with the corresponding initial and boundary conditions of</p> <p>$$ \\begin{cases} u(x,0) = -\\sin({\\pi x})\\\\ u(+1.0,t) = u(-1.0,t) = 0 \\\\ \\end{cases} $$</p> <p>Let's start by defining a dataset where we can sample points for the initial/boundary conditions and the internal domain:</p>"},{"location":"start/start/","title":"Quick Start","text":""},{"location":"start/start/#installation","title":"Installation","text":"<ul> <li>Install through <code>pip</code>: <code>pip install conflictfree</code></li> <li>Install from repository online: <code>pip install git+https://github.com/tum-pbs/ConFIG</code></li> <li>Install from repository offline: Download the repository and run <code>pip install .</code> or <code>install.sh</code> in terminal.</li> <li>Install from released wheel: Download the wheel and run <code>pip install conflictfree-x.x.x-py3-none-any.whl</code> in terminal.</li> </ul>"},{"location":"start/start/#use-config-method","title":"Use ConFIG method","text":"<p>Suppose you have a muti-loss training mission where each loss can be calculated with a loss function <code>loss_fn</code>. All the loss functions are then stored in a <code>loss_fns</code> list. Your code would probably looks like this</p> <pre><code>optimizer=torch.Adam(network.parameters(),lr=1e-3)\nfor input_i in dataset:\n    losses=[]\n    optimizer.zero_grad()\n    for loss_fn in loss_fns:\n        losses.append(loss_fn(network,input_i))\n    torch.cat(losses).sum().backward()\n    optimizer.step()\n</code></pre> <p>To use our ConFIG method, you can simply modify the code as</p> <pre><code>from conflictfree.grad_operator import ConFIG_update\nfrom conflictfree.utils import get_gradient_vector,apply_gradient_vector\noptimizer=torch.Adam(network.parameters(),lr=1e-3)\nfor input_i in dataset:\n    grads=[] # we record gradients rather than losses\n    for loss_fn in loss_fns:\n        optimizer.zero_grad()\n        loss_i=loss_fn(input_i)\n        loss_i.backward()\n        grads.append(get_gradient_vector(network)) #get loss-specfic gradient\n    g_config=ConFIG_update(grads) # calculate the conflict-free direction\n    apply_gradient_vector(network,g_config) # set the conflict-free direction to the network\n    optimizer.step()\n</code></pre> <p>Or, you can use our <code>ConFIGOperator</code> class:</p> <pre><code>from conflictfree.grad_operator import ConFIGOperator\nfrom conflictfree.utils import get_gradient_vector,apply_gradient_vector\noptimizer=torch.Adam(network.parameters(),lr=1e-3)\noperator=ConFIGOperator() # initialize operator\nfor input_i in dataset:\n    grads=[]\n    for loss_fn in loss_fns:\n        optimizer.zero_grad()\n        loss_i=loss_fn(input_i)\n        loss_i.backward()\n        grads.append(get_gradient_vector(network))\n    g_config=operator.calculate_gradient(grads) # calculate the conflict-free direction\n    apply_gradient_vector(network,g_config) # or simply use `operator.update_gradient(network,grads)` to calculate and set the conflict-free direction to the network\n    optimizer.step()\n</code></pre> <p>The <code>ConFIGOperator</code> class and <code>ConFIG_update</code> is basically the same, you can choose any one as you like. Besides our ConFIG method, we also provide <code>PCGradOperator</code> and <code>IMTLGOperator</code> from Gradient Surgery for Multi-Task Learning and Towards Impartial Multi-task Learning , respectively. The usage of these two operators are the same with <code>ConFIGOperator</code>.</p>"},{"location":"start/start/#use-m-config-method","title":"Use M-ConFIG method","text":"<p>The basic usage of <code>M-ConFIG</code> method in our code is similar to <code>ConFIGOperator</code> :</p> <pre><code>from conflictfree.momentum_operator import PseudoMomentumOperator\nfrom conflictfree.utils import get_gradient_vector,apply_gradient_vector\noptimizer=torch.Adam(network.parameters(),lr=1e-3)\noperator=PseudoMomentumOperator(num_vector=len(loss_fns)) # initialize operator, the only difference here is we need to specify the number of gradient vectors.\nglobal_step=0\nfor input_i in dataset:\n    optimizer.zero_grad()\n    index=global_step % len(loss_fns)\n    loss=loss_fns[index](input_i)\n    loss.backward()\n    g_config=operator.calculate_gradient(index,get_gradient_vector(network)) # calculate the conflict-free direction\n    apply_gradient_vector(network,g_config) # or simply use `operator.update_gradient(network,grads)` to calculate and set the conflict-free direction to the network\n    optimizer.step()\n    global_step+=1\n</code></pre> <p>You can also specify an instance of <code>PCGradOperator</code> or <code>IMTLGOperator</code> to the <code>gradient_operator</code> parameter of <code>PseudoMomentumOperator</code> to build momentum-based version of these two methods.</p>"},{"location":"start/theory/","title":"Theory Introduction","text":"<p>Our ConFIG method aims to eliminate conflicts among multiple loss terms in gradient descent optimizations.</p>"},{"location":"start/theory/#config","title":"ConFIG","text":"<p>Generically, we consider an optimization procedure with a set of \\(m\\) individual loss functions, i.e., \\(\\{\\mathcal{L}_1,\\mathcal{L}_2,\\cdots,\\mathcal{L}_m\\}\\). Let \\(\\{\\mathbf{g}_1,\\mathbf{g}_2, \\cdots, \\mathbf{g}_m\\}\\) denote the individual gradients corresponding to each of the loss functions. A gradient-descent step with gradient \\(\\mathbf{g}_c\\) will conflict with the decrease of \\(\\mathcal{L}_i\\) if \\(\\mathbf{g}_i^\\top \\mathbf{g}_c\\) is negative. Thus, to ensure that all losses are decreasing simultaneously along \\(\\mathbf{g}_c\\), all \\(m\\) components of  \\([\\mathbf{g}_1,\\mathbf{g}_2,\\cdots, \\mathbf{g}_m]^\\top\\mathbf{g}_c\\) should be positive. This condition is fulfilled by setting \\(\\mathbf{g}_c = [\\mathbf{g}_1,\\mathbf{g}_2,\\cdots, \\mathbf{g}_m]^{-\\top} \\mathbf{w}\\),  where \\(\\mathbf{w}=[w_1,w_2,\\cdots,w_m]\\) is a vector with \\(m\\) positive components and \\(M^{-\\top}\\) is the pseudoinverse of the transposed matrix \\(M^{\\top}\\)\u200b. </p> <p>Although a positive \\(\\mathbf{w}\\) vector guarantees a conflict-free update direction for all losses, the specific value of \\(w_i\\) further influences the exact direction of \\(\\mathbf{g}_c\\). To facilitate determining \\(\\mathbf{w}\\), we reformulate \\(\\mathbf{g}_c\\) as \\(\\mathbf{g}_c=k[\\mathcal{U}(\\mathbf{g}_1),\\mathcal{U}(\\mathbf{g}_2),\\cdots, \\mathcal{U}(\\mathbf{g}_m)]^{-\\top} \\mathbf{\\hat{w}}\\), where \\(\\mathcal{U}(\\mathbf{g}_i)=\\mathbf{g}_i/(|\\mathbf{g}_i|+\\varepsilon)\\) is a normalization operator and \\(k&gt;0\\). Now, \\(k\\) controls the length of \\(\\mathbf{g}_c\\) and the ratio of \\(\\mathbf{\\hat{w}}\\)'s components corresponds to the ratio of \\(\\mathbf{g}_c\\)'s projections onto each loss-specific \\(\\mathbf{g}_i\\), i.e., \\(|\\mathbf{g}_c|\\mathcal{S}_c(\\mathbf{g},\\mathbf{g}_i)\\), where \\(\\mathcal{S}_c(\\mathbf{g}_i,\\mathbf{g}_j)=\\mathbf{g}_i^\\top\\mathbf{g}_j/(|\\mathbf{g}_i||\\mathbf{g}_j|+\\varepsilon)\\) is the operator for cosine similarity:</p> \\[ \\frac{ |\\mathbf{g}_c|\\mathcal{S}_c(\\mathbf{g}_c,\\mathbf{g}_i) }{ |\\mathbf{g}_c|\\mathcal{S}_c(\\mathbf{g}_c,\\mathbf{g}_j) } = \\frac{ \\mathcal{S}_c(\\mathbf{g}_c,\\mathbf{g}_i) }{ \\mathcal{S}_c(\\mathbf{g}_c,\\mathbf{g}_j) } = \\frac{ \\mathcal{S}_c(\\mathbf{g}_c,k\\mathcal{U}(\\mathbf{g}_i)) }{ \\mathcal{S}_c(\\mathbf{g}_c,k\\mathcal{U}(\\mathbf{g}_j)) } = \\frac{ [k\\mathcal{U}(\\mathbf{g}_i)]^\\top \\mathbf{g}_c }{ [k\\mathcal{U}(\\mathbf{g}_j)]^\\top \\mathbf{g}_c } = \\frac{\\hat{w}_i }{ \\hat{w}_j } \\quad \\forall i,j \\in [1,m]. \\] <p>We call \\(\\mathbf{\\hat{w}}\\) the direction weight. The projection length of \\(\\mathbf{g}_c\\) on each loss-specific gradient serves as an effective \u201clearning rate'' for each loss. Here, we choose \\(\\hat{w}_i=\\hat{w}_j \\ \\forall i,j \\in [1,m]\\) to ensure a uniform decrease rate of all losses, as it was shown to yield a weak form of Pareto optimality for multi-task learning. </p> <p>Meanwhile, we introduce an adaptive strategy for the length of \\(\\mathbf{g}_c\\) rather than directly setting a fixed value of \\(k\\). We notice that the length of \\(\\mathbf{g}_c\\) should increase when all loss-specific gradients point nearly in the same direction since it indicates a favorable direction for optimization. Conversely, when loss-specific gradients are close to opposing each other, the magnitude of \\(\\mathbf{g}_c\\) should decrease. We realize this by rescaling the length of \\(\\mathbf{g}_c\\) to the sum of the projection lengths of each loss-specific gradient on it, i.e., \\(|\\mathbf{g}_c|=\\sum_{i=1}^m|\\mathbf{g}_i|\\mathcal{S}_c(\\mathbf{g}_i,\\mathbf{g}_c)\\). </p> <p>The procedures above are summarized in the Conflict-Free Inverse Gradients (ConFIG) operator \\(G\\) and we correspondingly denote the final update gradient \\(\\mathbf{g}_c\\) with \\(\\mathbf{g}_{\\text{ConFIG}}\\):</p> \\[ \\mathbf{g}_{\\text{ConFIG}}=\\mathcal{G}(\\mathbf{g}_1,\\mathbf{g}_1,\\cdots,\\mathbf{g}_m):=\\left(\\sum_{i=1}^m \\mathbf{g}_i^\\top\\mathbf{g}_u\\right)\\mathbf{g}_u, \\] \\[ \\mathbf{g}_u = \\mathcal{U}\\left[ [\\mathcal{U}(\\mathbf{g}_1),\\mathcal{U}(\\mathbf{g}_2),\\cdots, \\mathcal{U}(\\mathbf{g}_m)]^{-\\top} \\mathbf{1}_m\\right]. \\] <p>Here, \\(\\mathbf{1}_m\\) is a unit vector with \\(m\\) components. These two equations are implemented as conflictfree.grad_operator.ConFIG_update() and conflictfree.grad_operator.ConFIGOperator.calculate_gradient(). Meanwhile, we also provide weight_model to allow you implement different direction weights (\\(\\hat{\\mathbf{w}}=\\mathbf{1}_m\\) as default) and length_model to allow you design different length projection (the above adaptive strategy as default). We encourage you to design and try different weight/length models and compare the result with default configurations.</p>"},{"location":"start/theory/#config-in-two-loss-scenario","title":"ConFIG in two-loss scenario","text":"<p>For the special case of only two loss terms, there is an equivalent form of ConFIG that does not require a pseudoinverse:</p> \\[ \\begin{align} \\mathcal{G}(\\mathbf{g}_1,\\mathbf{g}_2)=(\\mathbf{g}_1^\\top\\mathbf{g}_{v}+\\mathbf{g}_2^\\top\\mathbf{g}_{v}) \\mathbf{g}_{v}  \\\\ \\mathbf{g}_{v}=\\mathcal{U}\\left[\\mathcal{U}(\\mathcal{O}(\\mathbf{g}_1,\\mathbf{g}_2))+\\mathcal{U}(\\mathcal{O}(\\mathbf{g}_2,\\mathbf{g}_1))\\right] \\end{align} \\] <p>where \\(\\mathcal{O}(\\mathbf{g}_1,\\mathbf{g}_2)=\\mathbf{g}_2-\\frac{\\mathbf{g}_1^\\top\\mathbf{g}_2}{|\\mathbf{g}1|^2}\\mathbf{g}_1\\) is the orthogonality operator. It returns a vector orthogonal to \\(\\mathbf{g}_1\\) from the plane spanned by \\(\\mathbf{g}_{1}\\) and \\(\\mathbf{g}_{2}\\). </p> <p>This equivlance is implemented as conflictfree.grad_operator.ConFIG_update_double(). You can also set <code>allow_simplified_model</code> to true in conflictfree.grad_operator.ConFIGOperator to enable using this form in two-loss scenario.</p>"},{"location":"start/theory/#m-config","title":"M-ConFIG","text":"<p>Gradient-based methods like the proposed ConFIG method require separate backpropagation steps to compute the gradient for each loss term, which could be computationally expensive.  To address this issue, we introduce an accelerated momentum-based variant of ConFIG: M-ConFIG. Our core idea is to leverage the momentum of the gradient for the ConFIG operation and update momentum variables in an alternating fashion to avoid backpropagating all losses in a single step. In each iteration, only a single momentum is updated with its corresponding gradient, while the others are carried over from previous steps.  Algorithm 1 details the entire procedure of M-ConFIG.</p> <p></p> <p>The M-ConFIG method is implemented as conflictfree.momentum_operator.PseudoMomentumOperator. This momentum method can also be used for other gradient-based methods. In conflictfree.momentum_operator.PseudoMomentumOperator, you can modify the <code>gradient_operator</code> parameter to enable momentum acceleration for other methods.</p> <p>For detailed discussion of the background theory, please check our research paper.</p>"},{"location":"start/troubleshooting/","title":"3. Troubleshooting","text":"In\u00a0[23]: Copied! <pre>from conflictfree.length_model import *\nimport matplotlib.pyplot as plt\n\nlength_models=[\n    ProjectionLength(),\n    TrackMinimum(),\n    TrackMaximum(),\n    TrackArithmeticAverage(),\n    TrackGeometricAverage(),\n    TrackHarmonicAverage(),\n    TrackSpecific(0),\n    TrackSpecific(1),\n]\n\ngrad_1=torch.tensor([0,1.0])\ngrad_2=torch.tensor([0,1.0])\ngrad_1=grad_1/torch.norm(grad_1)\ngrad_2=grad_2/torch.norm(grad_2)\ndirection_final=grad_1+grad_2\ngrad_1=grad_1*10\ngradients=torch.stack([grad_1,grad_2],dim=0)\n\nlengths=[grad_1.norm().item(),grad_2.norm().item()]\nfor model in length_models:\n    lengths.append(model.get_length(target_vector=direction_final,gradients=gradients).item())\nlabels=['$|g_1|$',\n        '$|g_2|$',\n        'ProjectionLength (default)', \n        'TrackMinimum', 'TrackMaximum', \n        'TrackArithmeticAverage', \n        'TrackGeometricAverage', \n        'TrackHarmonicAverage', \n        'TrackSpecific_0', \n        'TrackSpecific_1']\n\nplt.bar(labels,lengths)\nplt.xticks(rotation=90)\nplt.show()\n</pre> from conflictfree.length_model import * import matplotlib.pyplot as plt  length_models=[     ProjectionLength(),     TrackMinimum(),     TrackMaximum(),     TrackArithmeticAverage(),     TrackGeometricAverage(),     TrackHarmonicAverage(),     TrackSpecific(0),     TrackSpecific(1), ]  grad_1=torch.tensor([0,1.0]) grad_2=torch.tensor([0,1.0]) grad_1=grad_1/torch.norm(grad_1) grad_2=grad_2/torch.norm(grad_2) direction_final=grad_1+grad_2 grad_1=grad_1*10 gradients=torch.stack([grad_1,grad_2],dim=0)  lengths=[grad_1.norm().item(),grad_2.norm().item()] for model in length_models:     lengths.append(model.get_length(target_vector=direction_final,gradients=gradients).item()) labels=['$|g_1|$',         '$|g_2|$',         'ProjectionLength (default)',          'TrackMinimum', 'TrackMaximum',          'TrackArithmeticAverage',          'TrackGeometricAverage',          'TrackHarmonicAverage',          'TrackSpecific_0',          'TrackSpecific_1']  plt.bar(labels,lengths) plt.xticks(rotation=90) plt.show() <p>If your training result is not promising and you know that one of your loss-specific gradients has a much larger magnitude than other gradients, The <code>TrackMinimum</code> or <code>TrackHarmonicMean</code> might be a good choice worth trying.</p> In\u00a0[27]: Copied! <pre>import math\ndef get_cosine_lambda(initial_lr:float,\n                      final_lr:float,\n                      epochs:int,\n                      warmup_epoch:int):\n    \"\"\"\n    Returns a lambda function that calculates the learning rate based on the cosine schedule.\n\n    Args:\n        initial_lr (float): The initial learning rate.\n        final_lr (float): The final learning rate.\n        epochs (int): The total number of epochs.\n        warmup_epoch (int): The number of warm-up epochs.\n\n    Returns:\n        function: The lambda function that calculates the learning rate.\n    \"\"\"\n    def cosine_lambda(idx_epoch):\n        if idx_epoch &lt; warmup_epoch:\n            return idx_epoch / warmup_epoch\n        else:\n            return 1-(1-(math.cos((idx_epoch-warmup_epoch)/(epochs-warmup_epoch)*math.pi)+1)/2)*(1-final_lr/initial_lr)\n    return cosine_lambda\n# from torch.optim.lr_scheduler import LambdaLR\n# scheduler = LambdaLR(optimizer, lr_lambda=get_cosine_lambda(initial_lr=1e-3,final_lr=1e-4,epochs=100,warmup_epoch=10))\n\ncos_lambda=get_cosine_lambda(initial_lr=1e-3,final_lr=1e-4,epochs=100,warmup_epoch=10)\nlrs=[cos_lambda(i) for i in range(100)]\nplt.plot(lrs)\nplt.grid()\nplt.ylabel(\"Relative Learning Rate\")\nplt.xlabel(\"Epochs\")\nplt.show()\n</pre> import math def get_cosine_lambda(initial_lr:float,                       final_lr:float,                       epochs:int,                       warmup_epoch:int):     \"\"\"     Returns a lambda function that calculates the learning rate based on the cosine schedule.      Args:         initial_lr (float): The initial learning rate.         final_lr (float): The final learning rate.         epochs (int): The total number of epochs.         warmup_epoch (int): The number of warm-up epochs.      Returns:         function: The lambda function that calculates the learning rate.     \"\"\"     def cosine_lambda(idx_epoch):         if idx_epoch &lt; warmup_epoch:             return idx_epoch / warmup_epoch         else:             return 1-(1-(math.cos((idx_epoch-warmup_epoch)/(epochs-warmup_epoch)*math.pi)+1)/2)*(1-final_lr/initial_lr)     return cosine_lambda # from torch.optim.lr_scheduler import LambdaLR # scheduler = LambdaLR(optimizer, lr_lambda=get_cosine_lambda(initial_lr=1e-3,final_lr=1e-4,epochs=100,warmup_epoch=10))  cos_lambda=get_cosine_lambda(initial_lr=1e-3,final_lr=1e-4,epochs=100,warmup_epoch=10) lrs=[cos_lambda(i) for i in range(100)] plt.plot(lrs) plt.grid() plt.ylabel(\"Relative Learning Rate\") plt.xlabel(\"Epochs\") plt.show()"},{"location":"start/troubleshooting/#troubleshooting","title":"Troubleshooting\u00b6","text":"<p>Since we released the ConFIG method, we have received a lot of feedback from our users. Among many interesting discussions, we have found many useful tricks that may be helpful for the community. So, if you don't get a good result using ConFIG, please have a check on the following list:</p>"},{"location":"start/troubleshooting/#are-you-using-different-weight-models","title":"Are you using different weight models?\u00b6","text":"<p>Introducing new direction weight models may raise some issues. For example, if you set your weights to $[1,2]$ for a two-loss scenario, the following two scenarios will both satisfy your weight condition:</p> <p> </p> <p>Although in both situations the $\\mathbf{g}_c$ is a conflict-free direction, as $g_c$ has a positive dot product to both $\\mathbf{g}_1$ and $\\mathbf{g}_2$\u200b. However, the situation in figure b) might not be the optimal direction. This situation will not occur when you are using the default equal weight models. Thus, we would recommend using the default weighting configuration as much as possible.</p>"},{"location":"start/troubleshooting/#are-you-using-momentum-based-optimizers","title":"Are you using momentum-based optimizers?\u00b6","text":"<p>Momentum-based optimizers (here, we only refer to the optimizer that involves both the first and second momentum, e.g., Adam) might face some issues when you are using the default length model. In the default length model, the magnitude of the update gradient is calculated based on the sum of the projection length of each loss-specific direction, i.e.,</p> <p>$$ |\\mathbf{g}_{\\text{ConFIG}}|=\\sum_{i=1}^m \\mathbf{g}_i^\\top\\mathbf{g}_u=\\sum_{i=1}^m |\\mathbf{g}_i|\\mathcal{S}_c(\\mathbf{g}_i,\\mathbf{g}_u). $$</p> <p>This means that the final magnitude of the update gradient relies on the \"angle\" between $\\mathbf{g}_i$s and the magnitude of each $\\mathbf{g_i}$. So, if one of your loss-specific gradients has a much larger magnitude than other gradients, then it will cover the magnitude distribution of other gradients.</p> <p>If you are using a momentum-based optimizer, the absolute value of $\\mathbf{g}_{\\text{ConFIG}}$ actually doesn't matter too much as momentum-based optimizers will adjust the learning rate (length of the update gradient) according to how the gradient changes. If the gradient changes rapidly, then the learning rate will be very small. Thus, if you have a very large loss-specific gradient, the momentum-based optimizers will just change the learning rate according to how the magnitude of this largest gradient changes and ignore the contribution from other gradients (the learning rate also depends on how the angle between loss-specific gradients, $\\mathcal{S}_c(\\mathbf{g}_i,\\mathbf{g}_u)$ changes, of course.).</p> <p>In our <code>conflictfree</code> package, we provide several following length_model which can help you to decide which gradients' magnitude you want to track to adjust the learning rate in momentum-based optimizers. Here, we can use a simple example to illustrate the differences btween these length models:</p>"},{"location":"start/troubleshooting/#have-you-tried-to-warm-up-the-learning-rate","title":"Have you tried to warm up the learning rate?\u00b6","text":"<p>Usually, the direction of gradients at the start of the training may change rapidly due to the random initialization of the network. This may make it hard for the ConFIG method to find the optimal direction. Thus, we recommend you warm up the learning rate for a few epochs before applying the ConFIG method. This can be easily done by using the <code>torch.optim.lr_scheduler.LambdaLR</code> module. Here is an example of a cosine decay learning rate scheduler with warmup:</p>"}]}